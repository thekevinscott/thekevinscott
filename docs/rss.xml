<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[Kevin Scott]]></title><description><![CDATA[Design & AI]]></description><link>https://thekevinscott.com</link><generator>RSS for Node</generator><lastBuildDate>Mon, 12 Mar 2018 14:22:19 GMT</lastBuildDate><item><title><![CDATA[Common Patterns for Analyzing Data]]></title><description><![CDATA[Data is often messy, and a key step to building an accurate model is a thorough understanding of the data you're working with. Before I…]]></description><link>https://thekevinscott.com/common-patterns-for-analyzing-data/</link><guid isPermaLink="false">https://thekevinscott.com/common-patterns-for-analyzing-data/</guid><pubDate>Mon, 12 Mar 2018 07:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Data is often messy, and a key step to building an accurate model is a thorough understanding of the data you&apos;re working with.&lt;/p&gt;
&lt;p&gt;Before I started teaching myself machine learning a few months ago, I hadn&apos;t thought much about how to understand data. I&apos;d assumed data came in a nice organized package with a bow on top, or at least a clear set of steps to follow.&lt;/p&gt;
&lt;p&gt;Looking through others&apos; code, I&apos;ve been struck by the amount of variation in how people understand, visualize, and analyze identical datasets. I decided to read through several different data analyses in an attempt to find similarities and differences, and see if I can &lt;strong&gt;distill a set of best practices or strategies for understanding datasets to best leverage them for analysis&lt;/strong&gt;.&lt;/p&gt;
&lt;figcaption style=&quot;grid-row-start: 2;&quot;&gt;&lt;div class=&quot;caption&quot;&gt;&lt;a href=&quot;https://www.kaggle.com/tentotheminus9/r-eda/notebook&quot;&gt;An example EDA in the wild&lt;/a&gt;&lt;/div&gt;
  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/example_eda-583d6a43821c57fa9095b4fdab57608c-ae4fa.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 485px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 254.8453608247423%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAzCAYAAACXICiDAAAACXBIWXMAAAsSAAALEgHS3X78AAAEw0lEQVRYw7VXyyt9XxT/TikGUkJ5T+VvUEqZSWRkLiYGJl6hRFJkZqSUPIrEwMA7krzfeb/vxXXf7nU9Lut7Puta93c45/hdP36rVnvvc/b57LXX/qy19vnz4vcT5OXFT1arjRwOR1A9Ho/yzMrP3W433d1ZVe+d5HQ6yeVyk81mo9fXVwXjhf4IoN//yi8xCerxeOnh4YHsdrvy3MV9gKMvikWg6L+9vSkY/n8Af0NgpcpCP3m9Aat8Ph89Pj5yX8bq5+qxWj8AYv/whcViUXx1x/2A/wL6/PxMT09PPA8txqIy1lgIf9zf37MPxTfiJ3knffUc/ztGEBAOxQAvfqoMiG3AZJwo1PlOBbPdTBanhSwOC49hkbSf/Sf+DW5ZrPyJgnofDkV89plj8Bc+CJk2suWfajBShOXwj/jxzmpn+oAysJBpZA+0Lvc92ZwOtt7Qh0IdIfN/UVipCT34bWNjgw4PD2l1dZWOjo7o4uKCLi8vyWw20/n5ObdQzJmfn6eZmRk6OTlhUF3A/f19Ojs7o+PjYwYwmUx0e3vLIGivr69Zscj6+jqtrKzwO0PAnZ0d2t3dpeXlZV4ZoLASi1xdXTHozc0NHRwc0MTEBM3NzdHp6akWEKeEA8EEgE1PT9PW1hZbDMVH2CYUC8E1/f391NPTw0boWoiT6+rqot7eXuro6KDBwUEaGxtjP2Frs7Oz3Ifv+vr6qL6+nqqqqnhxQ8CysjIqKSmhoqIiKi8vp+rqatampiZqaGig5uZmamxs5Pc5OTmUmZlJbW1tHwHBRXAO6T0jI4NSU1MpLS2NUlJSKDk5mRITEykhIYH7UDyPjY3lZ2jz8/O1gDg5gMbExFB4eDhFRkZSWFjYlxoVFUURERGUlZWlBQQxYWF6ejpbl5SUxAor4uPjuR8XF8ctLI6OjmZrYUBubq6xD4uLi6m0tJQKCwupoqKCKisrqaamhlpbW9mPtbW13C8oKKC8vDzKzs6mlpYWY8DOzk6mQnt7O01OTtL4+DhNTU3RwsICLS4u8gmD0GBDXV0dHxROXp+HypZBE4QdSLu9vU17e3tBgoPc6CNKlpaWqLu7m6mFEDWMFBAWYQdSI0LUsQxFKOIAMQf8g9V4Zggo1mBVfCgxLCGHFtURi2xubnKUYJ4hoGwR20XsioqFAoztr62tsXsCycGnBZTaIoKaK6S/VEBhORYVQVLVvTn8L1cRdRFHUQeF0ILsUugdXh9ZvE+sNt8zud4vBlL5PlQ9XN9+xUKp+gD9qTKgXBal4knVC/SdvHW5mX2lmqr3q4diJLAOBEfaD1S9My4FJpP53wHxALwzEqS3b1n4onxwrUSAkaASfgtQriN6gmhBIvgeoPJrgfuMnuDuMjIy8uUtTLtlhTo3BltGtCDvYU7IgHK/1hOc8MDAAJ96yIDnSjq6UHKcnuDmAECksZAAMQDb8QelJ7g1ABC5MmQLwUHkOz1BEQIg7jwhA4IaehkHMTo8PMyAo6OjhietS2wUm88fYJtDQ0MMiBap/zOQJh+KwI8gN6yVuyL4pwbEGLGN95gn2UY3luWXVsolrBFF2ZQ+ihiShNxyNT+PutGhgIObIihUIsiPXu+Divj27xUpAKAWQ7865b9b6a/cnifvEwAAAABJRU5ErkJggg==&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;Example of an EDA&quot; title=&quot;&quot; src=&quot;/static/example_eda-583d6a43821c57fa9095b4fdab57608c-ae4fa.png&quot; srcset=&quot;/static/example_eda-583d6a43821c57fa9095b4fdab57608c-47579.png 160w,
/static/example_eda-583d6a43821c57fa9095b4fdab57608c-7f91e.png 320w,
/static/example_eda-583d6a43821c57fa9095b4fdab57608c-ae4fa.png 485w&quot; sizes=&quot;(max-width: 485px) 100vw, 485px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/figcaption&gt;
&lt;blockquote&gt;
&lt;p&gt;Data Scientists spend [the] vast majority of their time by [doing] data preparation, not model optimization. - &lt;a href=&quot;https://www.kaggle.com/lorinc/feature-extraction-from-images&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;&lt;span class=&quot;name&quot;&gt;lorinc&lt;/span&gt;&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In this article, I chose a number of &lt;a href=&quot;https://www.kaggle.com/general/12796&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;&lt;strong&gt;Exploratory Data Analyses&lt;/strong&gt; (or EDAs)&lt;/a&gt; that were made publicly available on &lt;a href=&quot;https://www.kaggle.com/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Kaggle&lt;/a&gt;, a website for data science. These analyses mix interactive code snippets alongside prose, and can help offer a birds-eye view of the data or tease out patterns in the data.&lt;/p&gt;
&lt;p&gt;I simultaneously looked at &lt;a href=&quot;https://www.quora.com/Does-deep-learning-reduce-the-importance-of-feature-engineering&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;feature engineering&lt;/a&gt;, a technique for taking existing data and transforming it in such a way as to impart additional meaning (for example, taking a timestamp and pulling out a &lt;code&gt;DAY_OF_WEEK&lt;/code&gt; column, which might come in handy for predicting sales in a store).&lt;/p&gt;
&lt;p&gt;I wanted to look at a variety of different kinds of datasets, so I chose:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#structured-data&quot;&gt;Structured Data&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#nlp&quot;&gt;NLP (Natural Language)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;#images&quot;&gt;Image&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Feel free to &lt;a href=&quot;#conclusions&quot;&gt;jump ahead to the conclusions below&lt;/a&gt;, or read on to dive into the datasets.&lt;/p&gt;
&lt;aside style=&quot;grid-row-start: 6;&quot; class=&quot;center&quot;&gt;&lt;h3&gt;Criteria&lt;/h3&gt;For each category I chose two competitions where the submission date had passed, and sorted (roughly) by how many teams had submitted.&lt;br /&gt;&lt;br /&gt;For each competition I searched for EDA tags, and chose three kernels that were highly rated or well commented. Final scores did not factor in (some EDAs didn&apos;t even submit a score).&lt;/aside&gt;
&lt;p&gt;&lt;a name=&quot;structured-data&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;structured-data&quot;&gt;&lt;a href=&quot;#structured-data&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Structured Data&lt;/h1&gt;
&lt;p&gt;A structured data dataset is characterized by spreadsheets containing training and test data. The spreadsheets may contain categorical variables (colors, like &lt;code&gt;green&lt;/code&gt;, &lt;code&gt;red&lt;/code&gt;, and &lt;code&gt;blue&lt;/code&gt;), continuous variables (ages, like &lt;code&gt;4&lt;/code&gt;, &lt;code&gt;15&lt;/code&gt;, and &lt;code&gt;67&lt;/code&gt;) and ordinal variables (educational level, like &lt;code&gt;elementary&lt;/code&gt;, &lt;code&gt;high school&lt;/code&gt;, &lt;code&gt;college&lt;/code&gt;).&lt;/p&gt;
&lt;aside style=&quot;grid-row-start: 13;&quot; class=&quot;center&quot;&gt;
&lt;h3&gt;Terms&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Imputation&lt;/strong&gt; &amp;mdash; Filling in missing values in the data&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Binning&lt;/strong&gt; &amp;mdash; Combining continuous data into buckets, a form of feature engineering&lt;/p&gt;
&lt;/aside&gt;
&lt;p&gt;The training spreadsheet has a target column that you&apos;re trying to solve for, which will be missing in the test data. The majority of the EDAs I examined focused on teasing out potential correlations between the target variable and the other columns.&lt;/p&gt;
&lt;p&gt;Because you&apos;re mostly looking for correlations between different variables, there&apos;s only so many ways you can slice and dice the data. For visualizations, there&apos;s more options, but even so, &lt;a href=&quot;https://towardsdatascience.com/5-quick-and-easy-data-visualizations-in-python-with-code-a2284bae952f&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;some techniques seem better suited for a task at hand than others&lt;/a&gt;, resulting in a lot of similar-looking notebooks.&lt;/p&gt;
&lt;p&gt;Where you can really let your imagination run wild is with feature engineering. Each of the authors I looked at had different approaches to feature engineering, whether it was choosing how to bin a feature or combining categorical features into new ones.&lt;/p&gt;
&lt;p&gt;Let&apos;s take a deeper look at two competitions, the &lt;a href=&quot;https://www.kaggle.com/c/titanic&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Titanic competition&lt;/a&gt;, followed by the &lt;a href=&quot;https://www.kaggle.com/c/house-prices-advanced-regression-techniques&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;House Prices competition&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;titanic&quot;&gt;&lt;a href=&quot;#titanic&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href=&quot;https://www.kaggle.com/c/titanic&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Titanic&lt;/a&gt;&lt;/h2&gt;
&lt;figcaption class=&quot;left&quot; style=&quot;grid-row-start: 18;&quot;&gt;
  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/titanic-c05a010e3e5abe3a6338fd019287d9c6-08fa6.jpg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 56.25%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEBf/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAXRrpNgzA//EABoQAAMBAAMAAAAAAAAAAAAAAAECAxEAEjH/2gAIAQEAAQUCs+E0pZ+ad6gOnn//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAEDAQE/AT//xAAUEQEAAAAAAAAAAAAAAAAAAAAQ/9oACAECAQE/AT//xAAaEAACAgMAAAAAAAAAAAAAAAABEQAQEjFR/9oACAEBAAY/AmtQN48Fmv/EABoQAQADAQEBAAAAAAAAAAAAAAEAESFxMVH/2gAIAQEAAT8hWor8dgSKGVwAl58gLDCaXZ//2gAMAwEAAgADAAAAEGMP/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPxA//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPxA//8QAHBABAAIDAQEBAAAAAAAAAAAAAQARITFRcWGB/9oACAEBAAE/EA6zCwvq/Ks/Y8YGxSz7OCwMYhgYnNsO3UE+aDkTaXDDyf/Z&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;Titanic&quot; title=&quot;&quot; src=&quot;/static/titanic-c05a010e3e5abe3a6338fd019287d9c6-08fa6.jpg&quot; srcset=&quot;/static/titanic-c05a010e3e5abe3a6338fd019287d9c6-f2c3a.jpg 160w,
/static/titanic-c05a010e3e5abe3a6338fd019287d9c6-3ed17.jpg 320w,
/static/titanic-c05a010e3e5abe3a6338fd019287d9c6-08fa6.jpg 640w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
     &lt;div class=&quot;caption&quot;&gt;by &lt;a href=&quot;https://www.flickr.com/photos/viaggioroutard/32746842734/in/photolist-RTJ8sN-7reGoc-7rdfgb-7reqrP-7rhfiJ-b4aUUF-bv64XJ-91NeZE-q2mfUz-eFvcpv-VMircS-pzVRNe-dF1MGZ-WCozhj-95TEWr-gkyMjV-75JPMM-7r8VAM-7r8K54-7ricVq-7rcJaC-7r8WZP-7rcUuc-7rgRJC-7rgFnC-oktnFk-7rdZK1-7rhNjL-adsXVC-7rcKPj-4YLEGK-7rhHQs-7r8TaB-7r8SoZ-e5wPAJ-8xv5oh-bvPFMY-7r8V3n-4YTM15-axQxWs-d1iAyQ-918Vc6-2gmvHf-8RCNJR-4YLEBM-b4aUXr-usDiD-c8Yp5o-22nLofY-okatX&quot;&gt;Viaggio Routard&lt;/a&gt;&lt;/div&gt;&lt;/figcaption&gt;
&lt;p&gt;The Titanic competition is a popular beginners&apos; competition, and lots of folks on Kaggle cycle through it. As a result the EDAs tend to be well written and thoroughly documented, and were amongst the clearest I saw. The dataset includes a training spreadsheet with a column &lt;code&gt;Survived&lt;/code&gt; indicating whether a passenger survived or not, along with other supplementary data like their age, gender, ticket fare price, and more.&lt;/p&gt;
&lt;aside style=&quot;grid-row-start: 18;&quot;&gt;
The EDAs I chose for analysis were &lt;a href=&quot;https://www.kaggle.com/ash316/eda-to-prediction-dietanic&quot;&gt;EDA to Prediction Dietanic&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt;, &lt;a href=&quot;https://www.kaggle.com/dejavu23/titanic-survival-for-beginners-eda-to-ml&quot;&gt;Titanic Survival for Beginners EDA to ML&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;deja vu&lt;/span&gt;, and &lt;a href=&quot;https://www.kaggle.com/jkokatjuhha/in-depth-visualisations-simple-methods&quot;&gt;In Depth Visualisations Simple Methods&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Jekaterina Kokatjuhha&lt;/span&gt;.
&lt;/aside&gt;
&lt;p&gt;All three of the EDAs start with raw metrics, viewing a few sample rows and printing descriptive information about the CSV file like types of the columns and means and medians.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/ash316_describe-e54380bb601bd1bfaf39f0dd20bac61b-b8f96.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 38.967136150234744%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAICAYAAAD5nd/tAAAACXBIWXMAAAsSAAALEgHS3X78AAAA3UlEQVQoz3WSjQ6DIAyEff8nNcYB/oKKdnzdasx0JBdaWq53YtW2rTjvxTknPviCINM0SUxRQhcUfd9/4lLzpZd4HEftH4ZBc2K4qn3f5TgOyTkrWJB3XScppRPrumqdXnKIuMvwZVkU5JU1kRjhqxDWda2KuDDPs5Js26Z9kHMG1E2MeqaEkF3Bwg7Npv4XnEOeH+o3hcQowzJTUQZ5/CqkTsxnwfbNsqm4Wqa5aRpVih2zbAPNMjuE1E7CJ8v2mjT+s/0Pp2V2s6TKym/DGZNNgT5KqROjkB3bV8tvESNxtwtSiroAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;I, Coder describes the dataset&quot;
        title=&quot;&quot;
        src=&quot;/static/ash316_describe-e54380bb601bd1bfaf39f0dd20bac61b-17dec.png&quot;
        srcset=&quot;/static/ash316_describe-e54380bb601bd1bfaf39f0dd20bac61b-ae2e5.png 160w,
/static/ash316_describe-e54380bb601bd1bfaf39f0dd20bac61b-8227e.png 320w,
/static/ash316_describe-e54380bb601bd1bfaf39f0dd20bac61b-17dec.png 640w,
/static/ash316_describe-e54380bb601bd1bfaf39f0dd20bac61b-b8f96.png 852w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt; describes the dataset&lt;/div&gt;
&lt;p&gt;Handling null or missing values is a crucial step in data preparation. One EDA handles this right upfront, while the other two tackle missing values during the feature engineering stages.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt; argues against assigning a random number to fill in missing ages:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;As we had seen earlier, the Age feature has 177 null values. To replace these NaN values, we can assign them the mean age of the dataset. But the problem is, there were many people with many different ages. We just cant assign a 4 year kid with the mean age that is 29 years. Is there any way to find out what age-band does the passenger lie?? Bingo!!!!, we can check the Name feature. Looking upon the feature, we can see that the names have a salutation like Mr or Mrs. Thus we can assign the mean values of Mr and Mrs to the respective groups.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/ash316_age_imputation-5feb2a0130a119f41efe003b07da170d-16765.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 35.93539703903096%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAHCAYAAAAIy204AAAACXBIWXMAAAsSAAALEgHS3X78AAAAzElEQVQoz6WQXQqCQBSFXUv/YFmpWWhYZkUELdex2kYZ0SY0HV9EOd2m9L0c+DjnzoWPYaQ8z5FlGaIoIp4IwxAp9Tc8jsFpDqknSSLgnFeUc5qmVUpFUQgZY0d43hsf/hfGTmCUHu2YfxL4FefP/juXKYSXawBlaGCgTNBoymh3FLTafdF/RQKdILjBmrtCKPc1mNYKo/GsnlDVLHExUAwSOhirZn1htzeiF+owprb4gr+F9/sD7nqPpbPDYrHFZnuATbly99D0+U+8AEGBOwmBS0SLAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;I, Coder imputing ages&quot;
        title=&quot;&quot;
        src=&quot;/static/ash316_age_imputation-5feb2a0130a119f41efe003b07da170d-17dec.png&quot;
        srcset=&quot;/static/ash316_age_imputation-5feb2a0130a119f41efe003b07da170d-ae2e5.png 160w,
/static/ash316_age_imputation-5feb2a0130a119f41efe003b07da170d-8227e.png 320w,
/static/ash316_age_imputation-5feb2a0130a119f41efe003b07da170d-17dec.png 640w,
/static/ash316_age_imputation-5feb2a0130a119f41efe003b07da170d-16765.png 743w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt; imputing ages&lt;/div&gt;
&lt;p&gt;Whereas &lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt; combines feature engineering as part of the pure data analysis, the other two authors consider it as a discrete step.&lt;/p&gt;
&lt;p&gt;All three kernel authors rely heavily on charts and visualizations to get a high level understanding of the data and find potential correlations. Charts used include factorplots, crosstabs, bar and pie charts, violin plots, and more.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/dejavu_survival_by_gender-3b36b0a679bbc5beedbb7e1b048817a3-616e4.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 587px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 48.21124361158432%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABo0lEQVQoz5WSS0vDQBSF8yN1oQs3unIhuFBciCCIIL5ArAGLj4K1UhQXWkFQq1jFqAhdaG21VFS0tWltHjN5NTlOBinGF3rhMGHuyZdzMyN4nod63eUyTQvV6isqlVfoOoFtO42e73NdD47jMtVBCEW5LKNWU2BZdsMn+M3JyAH6JhLoGd2AGDtCLl+CLGt4eVFRKinsJcrgdfYRE8Wiwvd/kqCqGnrHNtDSs4Tm7ggGQ9vI3BRZSr1hqtUINE1ne7/DOFBnxt+AfkJFoSwd/RvQthz0jm8GgFe5Z1QCIxP+n1TVCIzs9x6fZBQei7h71z9GJoGEclnngNlkDK3hTrTNd3EJ/sl+Bn6X0PdVqho/MF/5QhmZ/APCn4GUGgHgkLiDLUlCeD+KkcQMhjencZy9ADwgdX6LjoE4mpivvT+OqeU9LKbiXxOubqchrqQQWj5EYj8DKXuJ2Mk6QrsLmEkuIn1/Bb9yhRIW1k8xHT3E/JqEXekaR7kziMkIxL0I5lIxCHgvy7LYXbP5apomXyml7BI7+Fiu6wa8hmHwZ0II778BaJS2rPk24zIAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;deja vu plots survival by gender&quot;
        title=&quot;&quot;
        src=&quot;/static/dejavu_survival_by_gender-3b36b0a679bbc5beedbb7e1b048817a3-616e4.png&quot;
        srcset=&quot;/static/dejavu_survival_by_gender-3b36b0a679bbc5beedbb7e1b048817a3-2f6a7.png 160w,
/static/dejavu_survival_by_gender-3b36b0a679bbc5beedbb7e1b048817a3-20775.png 320w,
/static/dejavu_survival_by_gender-3b36b0a679bbc5beedbb7e1b048817a3-616e4.png 587w&quot;
        sizes=&quot;(max-width: 587px) 100vw, 587px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;deja vu&lt;/span&gt; plots survival by gender&lt;/div&gt;
&lt;p&gt;You&apos;re probably familiar with the phrase &quot;women and children first&quot; in regards to the Titanic disaster, and for each author, age and gender feature heavily in their initial data analyses. Income background (as indicated by the price of the ticket) also comes in for some detailed inspection.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The number of men on the ship is lot more than the number of women. Still the number of women saved is almost twice the number of males saved. The survival rates for a women on the ship is around 75% while that for men in around 18-19%. - &lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Both &lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; and &lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt; draw conclusions based on visual inspection of the charts and data, with &lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; writing:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Sex: Survival chances of women are higher.&lt;/li&gt;
&lt;li&gt;Pclass: Having a first class ticket is beneficial for the survival.&lt;/li&gt;
&lt;li&gt;SibSp and Parch: middle size families had higher survival rate than the people who travelled alone or big families. The reasoning might be that alone people would want to sacrifice themselves to help others. Regarding the big families I would explain that it is hard to manage the whole family and therefore people would search for the family members insetad of getting on the boat.&lt;/li&gt;
&lt;li&gt;Embarked C has a higher survival rate. It would be interesting to see if, for instance, the majority of Pclass 1 went on board in embarked C.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/jkok_stacked-4c9a6b58c22cf69777fa521218fafe12-14f46.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 380px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 68.94736842105263%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAACv0lEQVQ4y6WUy09TQRSH+3+40Oha484lQRfGjcZoXPhIfC4UFxqgKqIsoC0WWBAoCpLwipAIFDE+ahMTETZGgpZCwbaUtrSlrYDQ3t572wKfcy9R0RBC4iQn9+bM5Dffmd+cMayuriLLMpIk6ZFOp3//b85tld88p0Uul8OgKApLS4tEI3FqHwzy4GYP9ZWvmPHNkUov4xkP0GB6zf3rz2ipe4fvW5i0tMyEa4aa8hfYqt/SN/iBcbcbRZExrK+vk82quqC5tB/jlS5q7r/QBaVMiklXgLqHgxRf7KDR/AbfdFjPu7/MUFXSh7WsnzZrj9jIhyp0DCsrKyQS8Q1BYz93rnXpO/u9f0jqKgYpudSBzfIG73RIz7u/+DGV9lFbPsBAk0Ns5ENRlf8jNBvtlBf10Ns+QiKe1HV0wuTCd2KhKLYzlVgKimm+UE1g0i9IVpj4ujXh+Jif6rt2jFc7eVLjYD6W2BDUCNV8jvnZME2HzvJo1xGeFlwi6JpCkrcntNyxU3q5k8dWB/F5QZgTgqqqIkspQiJxtHGIA2YnJ56MMDEbI5MRhK7ZfwRDSIrEt6FR2gpvUL/vFL3nK0hEYmTz2rURgqnlHwQF8jEheNDi5GTzMO5AVNwtzZTAXyX7PEFSchq/Ywj73kI6DftwHD5PIjSnV6qXnBPuhGI7I/RPiTNUMxuCuwuE4B4cBWdJhiNCMK+ZkmJJmLJTQq8QlIRZn0enKLrdzOlzViqquolG4+Sy2e0JNVM8Y14abrVTdryGlrJuUfIssjBl2BPmmO0j+01OrnR9Ipr4Tl6/NilBuLhAcvEH1neT3LOPUf9+mlB8QfR4huDMHM9bX9Jk6uBlt5NIOIYiS0zNJal1ejD2jdI67GVhaZm81suIoVFqY21tDc31zTmt6d2iT7UIBoP6Q/JrXlufF+f2a632/QlsKZ+5duArDwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Jekaterina builds a stacked chart illustrating Pclass and Embarked&quot;
        title=&quot;&quot;
        src=&quot;/static/jkok_stacked-4c9a6b58c22cf69777fa521218fafe12-14f46.png&quot;
        srcset=&quot;/static/jkok_stacked-4c9a6b58c22cf69777fa521218fafe12-56338.png 160w,
/static/jkok_stacked-4c9a6b58c22cf69777fa521218fafe12-e4ec8.png 320w,
/static/jkok_stacked-4c9a6b58c22cf69777fa521218fafe12-14f46.png 380w&quot;
        sizes=&quot;(max-width: 380px) 100vw, 380px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; builds a stacked chart illustrating Pclass and Embarked&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Deja Vu&lt;/span&gt;&apos;s EDA records an accuracy number at each step of his analysis, providing a nice bit of feedback as to how important each feature is to the final prediction.&lt;/p&gt;
&lt;h3 id=&quot;feature-engineering&quot;&gt;&lt;a href=&quot;#feature-engineering&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Feature Engineering&lt;/h3&gt;
&lt;figcaption class=&quot;left&quot; style=&quot;grid-row-start: 41;&quot;&gt;
&lt;div class=&quot;left&quot;&gt;
  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/jkok_cabin_feature-a44a25d80bb66c2443c995e71cca89d0-60fc7.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 150px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 188.66666666666669%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAmCAYAAADEO7urAAAACXBIWXMAAAsSAAALEgHS3X78AAADWklEQVRIx41WaU8aURT1V7RVWVTWYRkGZF8VUDZFREFBEqwpNTUkTRPTpkn90j9+O+eSZwZ4rzMf7jyYd+e+c+76dg6PIiTkyBd9X4X8b08mO1aD3oMwy8GhxuumIUcG8cgXTqhSbdJxukTlSpOSqQJpkRT5/DEyknkWHCAzsHkIG+z3R3RzO6XX19/09vaXptNHms2eKJOtUKncoGrtnFzuAB9gRStDzpT39n207/Lzuru3+g3aQBzWkuT2BNeMYA8iNYhHMlUkXc8yAn8gziveey0fiQ8DQZ0MI8/o8RuG1yj7/FGm2+4M3v0kizRWfByNpanTHdD18J4i0eMt3zJCoAqGErZRxD504QYtklzz6ZrBdKZMCSPn2GDcdA/8u6IsMQjK3d61MjWEYB8HX1ze0OD6zqScklOOxTPsDycIgQoIkafSPMQL+ENPZG0NIijQxeEIDuhvGYRjL/u3VCzVt1JgUzzesOm7Mrto/rhgEB5vaJuynsgxFWeU41yKyjzEIxQ2HDUA7CG9IDCmrOV2+4parb5tlIXUG10a383Yj9Io5/I1R3kIekhq5G2heMpItyiLYleVnaoEZf3yPcrDmwk1ml1TSbMNSjCkU6vdp9EYlBW1XK2dUTZXtU0bQfm03qFms2cGU0EZKGWFbtedlVFGO6qZXdkJwrie4SC2O1fyKANZg+EbjqKMhoCx0DJTTdocxLSzo2yNKMoNohwBJ6dtqp20bClbpXl2wfSlUYY/nBoEGkT6ajDmYthqDlD48PGAp53TxMb6afdIWgyMEE52kodWwyi/sGbIu023NzR90uNN6xjdRIUJKfYaZoNAp5f6EIbcnlXk9l0BZRTFPga/qhjYh2iwoI1JhrJC80wdF7luRSXBGN4jI6CLO5C02+Bxdn5Jo9EDV8zX5yV9WbxwWgh6WF3uIGcC7jy9iyHrKqceuoamrYaPkSxQNltlZStlIEGXRrkhbeBr5dSDoD5Fa7deiCAoSxjCgQgEPsRcwXsp5eFwQsvlDx7goPvz1x/69vKd6xUtCimF/5+fnul+MqfJdE7z+YJ9L516oIwyggLmRb3R4REJRPAfUKMqMOChC5SxeFodZTgWJ4k7Hzo30gircIlIJXFtVo4A2QXdyV1a1WD/AdZZcbZpvUShAAAAAElFTkSuQmCC&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;At the beginning of her EDA, Jekaterina engineers a feature to pull out cabin letter.&quot; title=&quot;&quot; src=&quot;/static/jkok_cabin_feature-a44a25d80bb66c2443c995e71cca89d0-60fc7.png&quot; srcset=&quot;/static/jkok_cabin_feature-a44a25d80bb66c2443c995e71cca89d0-60fc7.png 150w&quot; sizes=&quot;(max-width: 150px) 100vw, 150px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; pulls out cabin letter.&lt;/div&gt;
&lt;/div&gt;&lt;/figcaption&gt;
&lt;p&gt;When it comes to feature engineering, there&apos;s more variability amongst the three kernel authors.&lt;/p&gt;
&lt;p&gt;Each author chooses different numbers of buckets for continuous variables like age and fare. Meanwhile, each approaches family relationships differently, with &lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt; building a &lt;code&gt;SibSip&lt;/code&gt; - whether an individual is alone or with family (either spouse or siblings) - along with &lt;code&gt;family_size&lt;/code&gt; and &lt;code&gt;alone&lt;/code&gt;, while &lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; pulls out a cabin bin and suggests a feature for &lt;code&gt;child&lt;/code&gt; or &lt;code&gt;adult&lt;/code&gt;. &lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt; in particular is aggressive in his culling of irrelevant columns:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Name--&gt; We don&apos;t need name feature as it cannot be converted into any categorical value.&lt;/p&gt;
&lt;p&gt;Age--&gt; We have the Age_band feature, so no need of this.&lt;/p&gt;
&lt;p&gt;Ticket--&gt; It is any random string that cannot be categorised.&lt;/p&gt;
&lt;p&gt;Fare--&gt; We have the Fare_cat feature, so unneeded&lt;/p&gt;
&lt;p&gt;Cabin--&gt; A lot of NaN values and also many passengers have multiple cabins. So this is a useless feature.&lt;/p&gt;
&lt;p&gt;Fare&lt;em&gt;Range--&gt; We have the fare&lt;/em&gt;cat feature.&lt;/p&gt;
&lt;p&gt;PassengerId--&gt; Cannot be categorised.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;For the imputation step, &lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; writes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Embarked: fill embarked with a major class&lt;/li&gt;
&lt;li&gt;Pclass: because there is only one missing value in Fare we will fill it with a median of the corresponding Pclass&lt;/li&gt;
&lt;li&gt;Age: There are several imputing techniques, we will use the random number from the range mean +- std&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;She concludes her kernel by ensuring the new imputed data did not disrupt the mean:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/jkok_disrupting_the_mean-b0903977c391c37d52903171d62273b4-782d3.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 396px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 62.62626262626263%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABxklEQVQ4y4VSa6/aMAzt//9PfAFpEtodcHl1fVHahKa0SVseEk/pzA4rG4+7RbJiJfbxObad9XqNuq6x3W5fbLMhe/N++9tYe353TqeT/aiqClprGGOs32wajAdzDAYuVnlh39iUVHDHPzH6MUKn00G/30e320Wv10OapnCEEGCWDFaWpb0rAk0ocektMO1/YuHHDwU5TimFJEnA+VEUIY5jZFkGh9k1TfOQUDc1/IkHmUhkYYyIAFfFrRDHcYz5y7ckfitwWDc/PDCsKwQEKOKUggyCeYjAjaz/HPvsv5dMgIuZj9UytWxDAvRnAUxl7oy+BDyfzy9DYRDhhlCpJPAaOlOIiGEYCbsR/5TM7NoK7W3oQ7oBVCKgOZEYLz0CpOlW/2MopXyQzLIEJWdLgbIo/0yWLCSW3nBuC3wJCDq73e5Gnyz3Qkx6H3bCnNhK44HwPnrzCOnMs39vJfMyFkVhwdyPKaZeglDmWJf6XrU1Q5YR6GTs2/00unxl2DJYBQt8fp9CZfm96Rxo2/Dka6ORUEuG30aIhjMIYpyn1G9qkcNyr9crK8d+v7/7x+PRtoK3oG0L7yyfw+Fg2fC5XC7I8xzt+QXMccqENxfRzgAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Jekaterina checking if the imputation disrupted the mean&quot;
        title=&quot;&quot;
        src=&quot;/static/jkok_disrupting_the_mean-b0903977c391c37d52903171d62273b4-782d3.png&quot;
        srcset=&quot;/static/jkok_disrupting_the_mean-b0903977c391c37d52903171d62273b4-c50e9.png 160w,
/static/jkok_disrupting_the_mean-b0903977c391c37d52903171d62273b4-76f4b.png 320w,
/static/jkok_disrupting_the_mean-b0903977c391c37d52903171d62273b4-782d3.png 396w&quot;
        sizes=&quot;(max-width: 396px) 100vw, 396px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; checking if the imputation disrupted the mean&lt;/div&gt;
&lt;h3 id=&quot;takeaways&quot;&gt;&lt;a href=&quot;#takeaways&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Takeaways&lt;/h3&gt;
&lt;p&gt;All three kernel authors spend time up front examining the data and describing the overall shape.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt; looks at the total null values, whereas &lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; does that near the end.&lt;/p&gt;
&lt;p&gt;Everyone starts with looking at the breakdown of survivors, and then the breakdown of survivors by gender. Cross tabs, factor plots, and violin plots are all popular graphs. &lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; also plots some really fascinating graphs.&lt;/p&gt;
&lt;p&gt;The authors diverge a bit more when it comes to feature engineering. The authors differ on when to engineer new features, with some treating it as a discrete step and others tackling it during their initial analysis of the data. Choices around binning differ, with age, title and fare all receiving different number of buckets, and only &lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; engineering a discrete &lt;code&gt;child&lt;/code&gt; / &lt;code&gt;adult&lt;/code&gt; feature.&lt;/p&gt;
&lt;p&gt;Approaches to imputation differ as well. &lt;span class=&quot;name&quot;&gt;I, Coder&lt;/span&gt; recommends looking at existing data to predict imputation values, whereas &lt;span class=&quot;name&quot;&gt;Jekaterina&lt;/span&gt; ensures her imputed data did not impact the mean.&lt;/p&gt;
&lt;p&gt;There&apos;s some clear similarities in how the authors think about and approach the data, with the main divergences concerning visualizations and feature engineering.&lt;/p&gt;
&lt;h2 id=&quot;house-prices&quot;&gt;&lt;a href=&quot;#house-prices&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href=&quot;https://www.kaggle.com/c/house-prices-advanced-regression-techniques&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;House Prices&lt;/a&gt;&lt;/h2&gt;
&lt;figcaption class=&quot;left&quot; style=&quot;grid-row-start: 56;&quot;&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/house_price-93bfce121a1a6843535bda087a4f1cc6-d3671.jpg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAIDBP/EABcBAAMBAAAAAAAAAAAAAAAAAAABAgP/2gAMAwEAAhADEAAAAatC+V6hBH//xAAaEAEAAwEBAQAAAAAAAAAAAAABAAIDExIi/9oACAEBAAEFAi4hv9dyeCV0oHTKf//EABURAQEAAAAAAAAAAAAAAAAAABAh/9oACAEDAQE/AYf/xAAWEQEBAQAAAAAAAAAAAAAAAAAAARL/2gAIAQIBAT8Btaf/xAAcEAABAwUAAAAAAAAAAAAAAAABAAIhAxARMXH/2gAIAQEABj8CmpeXHgWCxaK//8QAGhAAAwADAQAAAAAAAAAAAAAAAAERITFBYf/aAAgBAQABPyFJeVqtC1LdnT2FtcuYHOnFoo6z/9oADAMBAAIAAwAAABAIz//EABgRAAMBAQAAAAAAAAAAAAAAAAABESFR/9oACAEDAQE/EHCwq4f/xAAZEQACAwEAAAAAAAAAAAAAAAAAATFxkeH/2gAIAQIBAT8QSpLreH//xAAbEAEBAAMAAwAAAAAAAAAAAAABEQAhYUHB8P/aAAgBAQABPxBvSRBYzmLmDSqGClNcHJjqTT19TBwkoB1L5x4Ti+c//9k=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;House Prices&quot; title=&quot;&quot; src=&quot;/static/house_price-93bfce121a1a6843535bda087a4f1cc6-08fa6.jpg&quot; srcset=&quot;/static/house_price-93bfce121a1a6843535bda087a4f1cc6-f2c3a.jpg 160w,
/static/house_price-93bfce121a1a6843535bda087a4f1cc6-3ed17.jpg 320w,
/static/house_price-93bfce121a1a6843535bda087a4f1cc6-08fa6.jpg 640w,
/static/house_price-93bfce121a1a6843535bda087a4f1cc6-c5f03.jpg 960w,
/static/house_price-93bfce121a1a6843535bda087a4f1cc6-0c55a.jpg 1280w,
/static/house_price-93bfce121a1a6843535bda087a4f1cc6-40ed2.jpg 1920w,
/static/house_price-93bfce121a1a6843535bda087a4f1cc6-d3671.jpg 3264w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;div class=&quot;caption&quot;&gt;by &lt;a href=&quot;https://www.flickr.com/photos/120360673@N04/13855784355/in/photolist-n7ovXH-gjrMhS-eDwNQx-fFyccW-eDCzpL-fQDNaP-cA4RYd-cA4MtL-cA4HuL-fKnTsf-cA4LzU-ssvhf2-fKnAV9-daEeEz-gtpvp8-cA4R5o-cA4XQ7-cA4NSA-g2hXow-cA4SQw-eDBSFb-9eW1ng-g2j9Z5-cA4xwN-fFyJkx-9EzH9a-UD524Z-gttD2c-v9HAST-R7GoBF-v9KGVk-irUqRZ-koMrNT-fKv1e1-cA4UCE-ggDSAS-cA4C4A-gi21pE-cA4wdd-qmiDzR-rSUbew-gnDV6V-gjucTQ-fK7FS6-fK7bD6-duD885-fKbUqP-ggrui7-DUB1dh-dsvoVH&quot;&gt;American Advisors Group&lt;/a&gt;&lt;/div&gt;
&lt;/figcaption&gt;
&lt;p&gt;&lt;a href=&quot;https://www.kaggle.com/c/house-prices-advanced-regression-techniques&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;House Prices&lt;/a&gt; is another structured data competition. This one boasts many more variables than the Titanic competition, and includes categorical, ordinal and continuous features.&lt;/p&gt;
&lt;aside style=&quot;grid-row-start: 56;&quot;&gt;The EDAs I chose for analysis were &lt;a href=&quot;https://www.kaggle.com/pmarcelino/comprehensive-data-exploration-with-python&quot;&gt;Comprehensive Data Exploration with Python&lt;/a&gt; by Pedro Marcelino, &lt;a href=&quot;https://www.kaggle.com/xchmiao/detailed-data-exploration-in-python&quot;&gt;Detailed Data Exploration in Python&lt;/a&gt; by Angela, and &lt;a href=&quot;https://www.kaggle.com/caicell/fun-python-eda-step-by-step&quot;&gt;Fun Python EDA Step by Step&lt;/a&gt; by Sang-eon Park.&lt;/aside&gt;
&lt;p&gt;While similar in kind to Titanic, it&apos;s considerably more complicated.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;With 79 explanatory variables describing (almost) every aspect of residential homes in Ames, Iowa, this competition challenges you to predict the final price of each home.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figcaption style=&quot;grid-row-start: 59;&quot; class=&quot;left&quot;&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/pmarcelino_saleprice-735c123c7c023eca3391feb49a9fd2df-182ad.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 406px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 65.51724137931035%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABT0lEQVQ4y2NgQAIPHz6sfP36dT25+P79+9kgcwSAWAmIJb98+fLpPxTcfAFnEg0+f/58DdlAUWQDt19+/v/3379kGcgNxBJALIRs4O6rL/5fefqBLAPZgZgPiDmRDVx49P7/k/fekGUgyDAZIBaGGfjn77//8w7f+7/zynOKwlAcZuC7rz//rzj16P+6s0/+//v3j2wDxWAG3gLG8PKTD/+vPvP4//XnH8mOFAGYgcfvvvm/9MRDMN577QXlkXLw5iu4gcuALr398vP/33/+khwp4GTzC6hx26VncANBGBSWFx69///h2y+SwlDi8tXruav2nSmtm7mmtWnexsbaGavb6metbQHRjbPWtlZMXdnWv3RL89zVW9rnrd3eunDd9raNuw40Ld+4s23J+u1tmzZvKWZAA4xAzATEvEDMg0SDsBoQawCxNJo8F5QGiwEA3O30skw2d98AAAAASUVORK5CYII=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;Pedro plots the sale price&quot; title=&quot;&quot; src=&quot;/static/pmarcelino_saleprice-735c123c7c023eca3391feb49a9fd2df-182ad.png&quot; srcset=&quot;/static/pmarcelino_saleprice-735c123c7c023eca3391feb49a9fd2df-6f61b.png 160w,
/static/pmarcelino_saleprice-735c123c7c023eca3391feb49a9fd2df-66f7d.png 320w,
/static/pmarcelino_saleprice-735c123c7c023eca3391feb49a9fd2df-182ad.png 406w&quot; sizes=&quot;(max-width: 406px) 100vw, 406px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Pedro&lt;/span&gt; plots the sale price&lt;/div&gt;
&lt;/figcaption&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Angela&lt;/span&gt; and &lt;span class=&quot;name&quot;&gt;Pedro&lt;/span&gt; spend some time upfront investigating the initial data like we saw in Titanic. &lt;span class=&quot;name&quot;&gt;Angela&lt;/span&gt; plots the sale price in a histogram and builds a heatmap of the features, while &lt;span class=&quot;name&quot;&gt;Pedro&lt;/span&gt; plots the sale price and draws the following conclusions about the sale price:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;Deviate from the normal distribution.&lt;/li&gt;
&lt;li&gt;Have appreciable positive skewness.&lt;/li&gt;
&lt;li&gt;Show peakedness.&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Pedro&lt;/span&gt; then puts himself in the shoes of a buyer and speculates which features would matter to him, examining the correlations between his picks and the sale price. Later he builds a heatmap to glean a more objective view of feature relationships before zooming in on a couple promising candidates.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/pmarcelino_features-e6cddd59adf6fa58c60c546a8aa8f48e-a70de.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 98.73217115689383%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAADsUlEQVQ4y0VU2W7bRhTlv+cH+gFBkIegQPvQoi7aNEYMBGncxEkd25Is2ZKplRQXcRsON8mwb8+5dNIHQQPOzJ2z3euUZSnb0EiWVfgV+u9tC13ze7wzkuelft8GGdZWNthPkgLrCvsW5xKsa6xLcbIsk7/P17LblVpk7eVy/M9c189/HaBIjr1Cbt2d3LiRXEx8ef/vSuI4lyAsZHATymIdyfgulhe/DcR5fHyU9+dLCXGg6/ayAaoUL7ftQeabVIrCSlV3kmS12KqTbVzqA03TSWlbfK9kv7/Xs8NpIM5+v5eLcSCXkwAXW0XKHy+8/bgACiOFqWW1yfBoKQtcJKqybFWO5TpTAPNVKl+Gvjht24JGoEXadi+jaSRnV55UVSsfvq5Vu28XWHDixipLBbRhZEA3RfFGrvDIyaeFOPf397hUSpoaqetG1hD8ZpEoQiLrKTdaoGn2Ym2j562tVQoiVfplrYY5xhjZ+Lm+lKaFREAxne+w2b9OhHGcKZotTPC2qaIlgDRFQoJC/CBRafjdsdbKz8cT1dEYK58uPXlzOteovPpjhEuVrP1EdZvjgZMzV4a3IR6yKJ7L6DZCsUxef3Dl2fOP4jw8PMguYQ4NNOyds/h13UHcdaKU6T4p03kaR8qkWYOygX48Sx0TIFZTJsjQTHXby8rLdE2DLoE6jEq9SAeLopEgNnK3TFS7XWLFh+YE4YLuFcx1DoeDHkgSqy9RB2pKwa9nkWpYmEZ+fzeDVkY86Ei9iDhJrWrIgndLFgz/d5mtVKubrdIgfQOXuVeDJi+RZpT0iaDLtbrcPLnc9C6zl5krV2nUEsHNO1BmPIiWrhtTKZIIWb2YbPVMUVTfjUk1dlZrKOWjd1O5RtsQCUN+NvDQZq38dDxGZDAgcJi6MthfRj7Ohv3jeGBGuSDL56EnL48GPWVOCR9DgAUpfIQJQso+9KJOlCHL+17O0DVhbPQbWdAYUk4QLw8sNIfjWaz0qqrRMNOxEhoxb7yQ5b2bMdYrL5Ul+roogBCF35y6inaCacQsK0I/YCdkKFjLDoiIimjDqHgyoOkR2laLR1GOIpWipUT9voX7uThd18lrdAbnGQ/NMT3OBr66+OrPa0UYYVzxu4+4fB37+AVqCvdcHRqFSsUhqwP25dFQs8X+5cQ4H22hay4//HiurbdYx0qHGv11On3qe6MMGH72Ms8xHUp5udmhYKI55IwLon7YustI80kDtkGq+aQknhd+zyGHBdvRg2y/nFzLf7lJ1Kf3fST1AAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Plotting features against sale price&quot;
        title=&quot;&quot;
        src=&quot;/static/pmarcelino_features-e6cddd59adf6fa58c60c546a8aa8f48e-17dec.png&quot;
        srcset=&quot;/static/pmarcelino_features-e6cddd59adf6fa58c60c546a8aa8f48e-ae2e5.png 160w,
/static/pmarcelino_features-e6cddd59adf6fa58c60c546a8aa8f48e-8227e.png 320w,
/static/pmarcelino_features-e6cddd59adf6fa58c60c546a8aa8f48e-17dec.png 640w,
/static/pmarcelino_features-e6cddd59adf6fa58c60c546a8aa8f48e-88536.png 960w,
/static/pmarcelino_features-e6cddd59adf6fa58c60c546a8aa8f48e-a70de.png 1262w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;Plotting features against sale price&lt;/div&gt;
&lt;p&gt;By contrast, &lt;span class=&quot;name&quot;&gt;Angela&lt;/span&gt; starts with a more objective approach, listing numerical features by their correlation with &lt;code&gt;SalePrice&lt;/code&gt;. She also plots features against the sale price, looking for patterns in the data.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Sang-eon&lt;/span&gt; starts his kernel with a bang, aggressively culling missing values and outliers (with the exception of &lt;code&gt;LotFrontage&lt;/code&gt; which he imputes using linear regression). Only then does he begin plotting various features against the sale price.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Pedro&lt;/span&gt; waits until looking for correlations among the data to examine the problem of missing data. He asks:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ul&gt;
&lt;li&gt;How prevalent is the missing data?&lt;/li&gt;
&lt;li&gt;Is missing data random or does it have a pattern?&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The answer to these questions is important for practical reasons because missing data can imply a reduction of the sample size. This can prevent us from proceeding with the analysis. Moreover, from a substantive perspective, we need to ensure that the missing data process is not biased and hidding an inconvenient truth.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;To address these, &lt;span class=&quot;name&quot;&gt;Pedro&lt;/span&gt; plots the totals and percents of missing cells, and chooses to delete columns where 15% or more cells contain missing data. He again relies on subjective choices to determine which features to remove:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;...will we miss this data? I don&apos;t think so. None of these variables seem to be very important, since most of them are not aspects in which we think about when buying a house (maybe that&apos;s the reason why data is missing?). Moreover, looking closer at the variables, we could say that variables like &apos;PoolQC&apos;, &apos;MiscFeature&apos; and &apos;FireplaceQu&apos; are strong candidates for outliers, so we&apos;ll be happy to delete them.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Pedro&lt;/span&gt;&apos;s approach to the missing data is to either remove columns (features) entirely if they feature a large number of missing values, or remove rows where there are only a few missing. He does not impute any variables. He also establishes a heuristic for tackling outliers:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The primary concern here is to establish a threshold that defines an observation as an outlier. To do so, we&apos;ll standardize the data. In this context, data standardization means converting data values to have mean of 0 and a standard deviation of 1.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;He concludes that there&apos;s nothing to worry from a stastical standpoint, but after returning to visual inspections of the data, deletes a few single data points he finds questionable.&lt;/p&gt;
&lt;h3 id=&quot;feature-engineering-1&quot;&gt;&lt;a href=&quot;#feature-engineering-1&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Feature Engineering&lt;/h3&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Sang-eon&lt;/span&gt; examines the skewness and kurtosis of the data, and performs a Wilxoc-rank Sum test. He concludes his kernel with a very nice looking plot:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/caicell_3d_plot-eed4cdee22049beffa80c2acae2575d7-078e6.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 600px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 66.66666666666666%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABOklEQVQ4y82STU/CQBCG+789oBd/gAkH/4AnTDx58ODBxESJ8SORtECFln5uW5Z+0WpBX3fWgCVg1MjBw5vOpjPPvDO7ylsZYJtSvkt4LRg8swM2UmX8Z+DWHf5EVTZCEp6jTOzfAedTf+PYMe+gbTa+dkiFpCrz8Jw4eEkdFBMLaThEEgxkTP8X+SzqovlwKHPXgFRAgAVkymkcQ8K438eEPSGNhgL46dRhOhoXLcyF+yWwjG1Ebk8WVJkrzxSr3TO0r3dweXeKbPwBziJjxYTj6tg9PpHrUOrPg745NyU4lk4M3GttPOq3CFlPNLGkc2pYB3qWjv1mS65B2fTuuK+jEMXkksYmAGmWe0L+2s59o4+DvaPVS6ErZ5Yq9jVAPjaXAGpAriiHGgW2JseuAwtuQbu6+ccPu653AQDcdWIw8pYAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Sang-eon with a 3d plot of features&quot;
        title=&quot;&quot;
        src=&quot;/static/caicell_3d_plot-eed4cdee22049beffa80c2acae2575d7-078e6.png&quot;
        srcset=&quot;/static/caicell_3d_plot-eed4cdee22049beffa80c2acae2575d7-c1c1b.png 160w,
/static/caicell_3d_plot-eed4cdee22049beffa80c2acae2575d7-94bd9.png 320w,
/static/caicell_3d_plot-eed4cdee22049beffa80c2acae2575d7-078e6.png 600w&quot;
        sizes=&quot;(max-width: 600px) 100vw, 600px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Sang-eon&lt;/span&gt; with a 3d plot of features&lt;/div&gt;
&lt;p&gt;Meanwhile, &lt;span class=&quot;name&quot;&gt;Pedro&lt;/span&gt; discusses Normality, Homoscedasticity, Linearity, and Absence of correlated errors; he normalizes the data and discovers that the other three are resolved as well. Success!&lt;/p&gt;
&lt;h3 id=&quot;takeaways-1&quot;&gt;&lt;a href=&quot;#takeaways-1&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Takeaways&lt;/h3&gt;
&lt;p&gt;None of the three kernel authors does much feature engineering, possibly because there&apos;s so many features already present in the dataset.&lt;/p&gt;
&lt;p&gt;There&apos;s a wide range of strategies for determining how to approach the data, with some authors adopting a subjective strategy and others jumping straight to more objective measurements. There&apos;s also no clear consensus on when and how to cull missing values or outliers.&lt;/p&gt;
&lt;p&gt;There&apos;s more of a focus on statistical methods and integrity overall than in the Titanic competition, possibly because there&apos;s so many more features to handle; it&apos;s possible that negative statistical effects might have a larger overall effect than in the previous competition.&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;nlp&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;natural-language&quot;&gt;&lt;a href=&quot;#natural-language&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Natural Language&lt;/h1&gt;
&lt;p&gt;Natural Language, or NLP, datasets contain words or sentences. While the core data type is the same as in structured data competitions - text - the tools available for analyzing natural language are specialized, resulting in different strategies for analysis.&lt;/p&gt;
&lt;p&gt;In its original form, language is not easily decipherable by machine learning models. To get it into an appropriate format for a neural net requires transformation. One popular technique is the &lt;a href=&quot;https://en.wikipedia.org/wiki/Bag-of-words_model&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Bag of Words&lt;/a&gt;, whereby a sentence is effectively transformed into a collection of 0s or 1s indicating whether a particular word is present or not.&lt;/p&gt;
&lt;p&gt;Because of this need to transform the data, the first few steps of most notebooks tend to be transforming the text into something machine readable, and that step tends to be similar across notebooks. Once that&apos;s done, coders diverge considerably in their approaches and employ a variety of different visualizations and techniques for feature engineering.&lt;/p&gt;
&lt;h2 id=&quot;toxic-comment-classification&quot;&gt;&lt;a href=&quot;#toxic-comment-classification&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href=&quot;https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Toxic Comment Classification&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;&lt;em&gt;Warning: some of these comments might burn your eyeballs.&lt;/em&gt;&lt;/p&gt;
&lt;figcaption class=&quot;left&quot; style=&quot;grid-row-start: 88;&quot;&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/toxic-167eac9b78764014a3918f85721adc78-8231f.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 76.89393939393939%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAIAAABr+ngCAAAACXBIWXMAAAsSAAALEgHS3X78AAADnklEQVQozwGTA2z8AGSGeV6GcmGBa4+xlrrW0py/t4CjjleCaWuiiYu8rXyqmmOKdI+ymsXcy8jk1XuyhHWxf0p6WxYmGi1MMACTrqdylH53m3SnyLC00sabvbB3oYp3ooxxo4GVwK/Q5uXN5uHT6ODL49W83cx9sHx7qnORs5trfm16fnMAi6WdYoBmTGREtc2/8vn53u3pkbmnXnhwS1ROSlFMV2Bda3Zyk6Kdp8u7cqSNVYNhcJR3u9PIyMe749nWAHGJgWB6alt5YZOznKrFr6PEtEdTUDg2OlJGTW5fZV9SUhcWFRUWFJSkpufy86/LwoOfkYmojoaRftPa1QDT4uGnwb5ninZ4m4t0nYBid22RhIu8qa2rlZyGeoiBcXyPfX1IQT1YX1+ZvLCXuqq91szg7enU5N/I3NQA3efpkqilSmRVhqujbJCDQEFDg29urZal18rTn4eKmYeKkH58iH17c21tpLu2XYFnW4BlxNrVudPJjrCbAGJ+gZKso7XOxcbd2ImmmicjIBcODD4uMI95g5d/hL6rspJ/fkk/PEk5N7KWm2h9aKPDtcHW1lx4amKAbQBRaGJxh3aHoJB+oI9/mY4fHBojFRYOBgYXDg+McXmkjpS7qKyomZiFbGeti4uYoJtKY1A5TkMmNys0TTwAZXpwbn9tpLitjqyVcpx2KjEnLyElGQ8TDgcIbFBXi3N3nomNr56djndwlISDxMLFm7epeqKESWhPQFtIAE5dUmyDc3mXgUlmTlh8XkpQSiofJEsxQycWH1pBRWpTUkk4MzwwK2BSSY6DgLawrr7BwYStloStkX2jhwBthHVLXU0+Tz8tPy4/TUIxMS8vJCY+JCs3IipzVVdjT085LyxMRD1ZTEGIfHSkmpW7trSlq6ovQzQxRTIAn6+qdoeEbHx3XGpmWWVgOTo5d2ZihFhxeldaf2ZqTD4+Qzk0U01IbGJafHFrpZuWta6sraioho+HfaCPAEtXVjlEQy84OS84OEdST0BBQFJEPnpQTp9+iz4yMjcrJkc/OltXUmVhXnJqZ5KJhK6mpK+pp6WgnVx2ZAAnMigcJBwyOTEvODA5QjxBQkA5NjQxKShDODo2KiY5LypKQ0BIRkZiX2FzbWyFfXuuqKi7trazrqyGj4IAISseLjksPkk9LTguMz41QUNAPz48PTs6PTUzOzIuPjg0RkI+UlFSUE5QWFRUh4GCqKOlwry9vbe2nZiVWWui/xBBzVUAAAAASUVORK5CYII=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;Toxic&quot; title=&quot;&quot; src=&quot;/static/toxic-167eac9b78764014a3918f85721adc78-17dec.png&quot; srcset=&quot;/static/toxic-167eac9b78764014a3918f85721adc78-ae2e5.png 160w,
/static/toxic-167eac9b78764014a3918f85721adc78-8227e.png 320w,
/static/toxic-167eac9b78764014a3918f85721adc78-17dec.png 640w,
/static/toxic-167eac9b78764014a3918f85721adc78-88536.png 960w,
/static/toxic-167eac9b78764014a3918f85721adc78-91c1d.png 1280w,
/static/toxic-167eac9b78764014a3918f85721adc78-40219.png 1920w,
/static/toxic-167eac9b78764014a3918f85721adc78-8231f.png 3168w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;div class=&quot;caption&quot;&gt;by &lt;a href=&quot;https://www.flickr.com/photos/navaneethkn/7975953800/in/photolist-d9NRbQ-dEZp2L-dQinfV-8ZqMDd-GyaoHJ-oGKC67-5Kj4pp-8YybhA-8Yva5t-7Xh81B-oEZ6w8-4G19MZ-cm3zDf-3c7z32-GXuYz-oyayD-96qUSC-6UYVbr-bjWoro-duyWt-7jD4Nc-6KNazu-op1rhC-DY1c6F-bYNV7U-byHgQ3-cmFxgG-cm3zEC-8m74XJ-oZEcpA-9Kd3gM-7t1H1q-m9ZbHK-9r7F3j-r3kU-8ZPcAU-8RLfw5-TsHmuW-98S9zG-8Mzx2B-c6ZoZ9-7Bpck-8bnj49-4AJUnS-vag3VE-7Bp97-jeiiRG-bHbYQa-dJQMhT-N7SSSy&quot;&gt;navaneethkn&lt;/a&gt;&lt;/div&gt;
&lt;/figcaption&gt;
&lt;p&gt;The first NLP competition I looked at was the &lt;a href=&quot;https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge%3CPaste%3E&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Toxic Comment Classifcation Competition&lt;/a&gt;, which included a dataset featuring a large number of comments from Wikipedia talk page edits that been scored on a toxicity scale, indicating whether they were an insult, obscene, toxic, and more. The challenge was to predict a given comment&apos;s toxicity labels.&lt;/p&gt;
&lt;aside class=&quot;center&quot; style=&quot;grid-row-start: 88;&quot;&gt;
The EDAs I chose for analysis were &lt;a href=&quot;https://www.kaggle.com/jagangupta/stop-the-s-toxic-comments-eda&quot;&gt;Stop the S@#$ - Toxic Comments EDA&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Jagan&lt;/span&gt;, &lt;a href=&quot;https://www.kaggle.com/rhodiumbeng/classifying-multi-label-comments-0-9741-lb&quot;&gt;Classifying Multi-label Comments&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Rhodium Beng&lt;/span&gt;, and &lt;a href=&quot;https://www.kaggle.com/fcostartistican/don-t-mess-with-my-mothjer&quot;&gt;Don&apos;t Mess With My Mothjer&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Francisco Mendez&lt;/span&gt;.
&lt;/aside&gt;
&lt;p&gt;All three authors begin by describing the dataset and pulling a few comments at random. While there&apos;s no missing values, there is a lot of noise in the comments, but its unclear whether this noise will be useful in the final data analysis.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/jagan_category_distribution-2680943be74e9d2e8e9064a82455e492-abe41.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 519px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 53.75722543352601%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsSAAALEgHS3X78AAABN0lEQVQoz2NggIJ3775xALEILtzV1afR2ztRvba2QQ+b/KVLN0VOnbooAjZMTU1N+tq1e4WvXn36Ty6+uuHs/wuLj/6HGSh1/TplBt5Zevb/rRnH/zOoq6sLU8OFcAOBhkkAMff9+89yqOVCMU1NTS6qGQh0nQgQi169eqeIWgZyA10pQjUDQQAUMafOXS9av+/s/x3HrqIovH378f+HD1+giD169Or/gwcvcBsIAhv3n3cOaV25KLF/09zrl64sPrB9y5Ib164tKFxSvLQAiIGaZu7Zc2jVkyevZ29ccGT+yul7F1+9dGfR1o3blpw5dWHpjUUn556bsGcJAzLQ09Nj0dHRYQIGAwcwoji0tLTYtLW12YBsVl1dXUaguBpQjMnExIQJJAb0GTtQiEtDQ4MTpA8oxwoAZzSAeOaYxOwAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Jagan plots the distribution of images per toxic category&quot;
        title=&quot;&quot;
        src=&quot;/static/jagan_category_distribution-2680943be74e9d2e8e9064a82455e492-abe41.png&quot;
        srcset=&quot;/static/jagan_category_distribution-2680943be74e9d2e8e9064a82455e492-97ef9.png 160w,
/static/jagan_category_distribution-2680943be74e9d2e8e9064a82455e492-897b0.png 320w,
/static/jagan_category_distribution-2680943be74e9d2e8e9064a82455e492-abe41.png 519w&quot;
        sizes=&quot;(max-width: 519px) 100vw, 519px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Jagan&lt;/span&gt; plots the distribution of images per toxic category&lt;/div&gt;
&lt;blockquote&gt;
&lt;p&gt;The toxicity is not evenly spread out across classes. Hence we might face class imbalance problems — &lt;span class=&quot;name&quot;&gt;Jagan&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Francisco&lt;/span&gt; immediately throws away words &quot;lacking meaning&quot; (e.g., &quot;and&quot; or &quot;the&quot;). Using a biplot, he plots out in which category a particular word is most likely to fit.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;From the biplot most of the words are organized as expected, with some exceptions, fat is associated to identity hate, which is surprissing because is the only non-race word on the bottom of the chart, there are some generic offensive words in the middle of the chart, meaning that they can be used for any awful purposes, other ones as die are exclusively associated to threat which make total sense some others as a$$ (sorry I feel uncomfortable writing it as it appear on the data) is associated with threat, on the middle left of the chart there are some unrecognizable words, which are shown using the code — &lt;span class=&quot;name&quot;&gt;Francisco Mendez&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Francisco&lt;/span&gt; then asks whether there&apos;s a correlation between typos and toxicity.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Apparently there is, and surprisingly, mother when is misspelled is never related to hate or threat, but when it is properly spelled there are some hate and threat comments that have the word mother in it ... Is it that people tend to write more carefully when they are threating somebody or when they hate it?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;As &lt;span class=&quot;name&quot;&gt;Francisco&lt;/span&gt; digs further, he finds that in many cases, toxic comments would contain copy-pasted phrases, over and over again. After rerunning his analysis after removing duplicate words, he discovers a new set of correlations.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Here there are some new words the ones that can be highlited are gay used mainly on threat comments and hate. Some general mild words as mother, hell, piece, stupid, idiot and shut are used for any toxic general purpose, meantime any derivative of the f-word is used in toxic and obscene comments. Also from the biplot is possible to realize that toxic and insult are similar and the least aggressive ones, while hate and threat are the most serious ones.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;All three authors utilize visualizations of the data to great effect. (Given the subject matter I &lt;a href=&quot;https://www.kaggleusercontent.com/kf/1999919/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..VNoIJq1HAQhUsgxohTIQbw.PJ_2btsXr_QE8M47LbU_hnDC0EjxjMc2MU78sA3FgRImN8RkF7EHKV3qblwpWNMFxd1euS-fJoKYaH08WmK_WrOThoricdI7DSnR_bPBpbcYd38Ee2nI79hiLFLmfOYqvouAokDBWFJttLZ1hNABug.HeaSlJMn0s2ZxykWFP8wPg/__results__.html#Counting-words-different&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;won&apos;t embed&lt;/a&gt; the images &lt;a href=&quot;https://www.kaggleusercontent.com/kf/2666420/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..-nfZk6vneRueL7x2gvhaTQ.DCk0SonxzFc_r5z4QAPJrjRqu-d_6KgEKOvKmlf4z1zlqQBrZ2qsd1T-r3L_djSWn-W58trDbpNTHFuf8tKiL7Akq-vZwKMkLXv4_1dqiMCIUpa7lhdXW_Ss25eREE8U.HG-fudsk_AA4Iefzv5-n5A/__results__.html#Wordclouds---Frequent-words:&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;but you can find them on each author&apos;s kernel&lt;/a&gt;.)&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Rhodium&lt;/span&gt; builds a histogram of character length as well as a heatmap between categories, finding that some labels are highly correlated; for instance, an insult is 74% likely to also be obscene.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Jagan&lt;/span&gt; plots some word clouds, a heatmap, and a crosstab, observing:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A Severe toxic comment is always toxic&lt;br /&gt;
Other classes seem to be a subset of toxic barring a few exceptions&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;feature-engineering-2&quot;&gt;&lt;a href=&quot;#feature-engineering-2&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Feature Engineering&lt;/h3&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Rhodium&lt;/span&gt; lowercases the text, manually turns contractions into things, and manually cleans punctuation.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Jagan&lt;/span&gt; plots various features against toxicity looking for correlations. Among the discoveries: spammers tend to be more toxic.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/jagan_discussing_feature_engineering-84cb007780579b4a5e6b28c411c9968d-c1d8e.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 99.17647058823529%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAABN0lEQVQ4y61UiaqDQAz0/39PRDxBENE+7/vOY0JTbKHldfctTE233dlJMtFIkoRs26YgCMiyLHIch0zTpGVZSGUZONi2LfV9T13XMRBjT+Lrb8C6ru8JsyyjOI7JdV2Kooh0lzFN00OFKLnGol5Uv6o9juOZEBvXg4i1FOJjGAZK05RJX29UIhzHkaqq4mJv28ZALDjP8++E+75TXuRUFAWVZclqUVdgnmd+fkUI20AhiECAC7RShm08z6MwDNnUt58bkysTogkgkA5/k95bQrENUtbuMjclzxnotOoMPyms65rJ0GlRqtocViiEsA1sApWqqbPC63zqdJgJkSYs4/v+/7xtoAipAkgdFxT37/CoTBCeaBxilEfeSjgPSIYGZrVpGobUTyDjhxj/k/1P8/2oIaBraqxfpHMirCwnNAQAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Jagan discussing feature engineering&quot;
        title=&quot;&quot;
        src=&quot;/static/jagan_discussing_feature_engineering-84cb007780579b4a5e6b28c411c9968d-17dec.png&quot;
        srcset=&quot;/static/jagan_discussing_feature_engineering-84cb007780579b4a5e6b28c411c9968d-ae2e5.png 160w,
/static/jagan_discussing_feature_engineering-84cb007780579b4a5e6b28c411c9968d-8227e.png 320w,
/static/jagan_discussing_feature_engineering-84cb007780579b4a5e6b28c411c9968d-17dec.png 640w,
/static/jagan_discussing_feature_engineering-84cb007780579b4a5e6b28c411c9968d-c1d8e.png 850w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Jagan&lt;/span&gt; discussing feature engineering&lt;/div&gt;
&lt;p&gt;For single words and pairs of words, &lt;span class=&quot;name&quot;&gt;Jagan&lt;/span&gt; and &lt;span class=&quot;name&quot;&gt;Rhodium&lt;/span&gt; both plot the top words using TF-IDF, described as:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;TF stands for term frequency; essentially how often a word appears in the text ... You can understand it as a normalisation of the relativ text frequency by the overall document frequency. This will lead to words standing out that are characteristic for a specific author, which is pretty much what we want to achieve in order build a prediction model. — &lt;a href=&quot;https://www.kaggle.com/headsortails/treemap-house-of-horror-spooky-eda-lda-features&quot;&gt;Heads or Tails&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;takeaways-2&quot;&gt;&lt;a href=&quot;#takeaways-2&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Takeaways&lt;/h3&gt;
&lt;p&gt;There seem to be a few best practices all the authors follow, including things like lower casing text, handling contractions, and cleaning up punctuation were all areas the authors looked at. However, some authors also considered that these could be potential features and not just noise (for instance, Francesco discovering a correlation between typos and toxicity).&lt;/p&gt;
&lt;h2 id=&quot;spooky-author-identification&quot;&gt;&lt;a href=&quot;#spooky-author-identification&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href=&quot;https://www.kaggle.com/c/spooky-author-identification&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Spooky Author Identification&lt;/a&gt;&lt;/h2&gt;
&lt;figcaption class=&quot;left&quot; style=&quot;grid-row-start: 114;&quot;&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/halloween-612616b4a978f1a437985f1e13b46e42-5abf6.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAABuvAAAbrwFeGpEcAAAFIUlEQVQ4yyWUSU9bZxSGvWiwjQHjgcHG2GAGAx7xAMZ2bAiYeQwJZgxucCEDkASFMCQ0CZCkbQZlbJSWSm2qbBqpUSslqlqp2URVd9lk2U0X/QX9AU+P3cWnK92r+37veYejKCzSUF1jQ2copsnjoNHdgKHUgLFEh7FUT7FeS5GuCH2JntIyI2XlBkrkm7a4AJ2ugILCfAoL1BRoVKhUeSiMpUYMBh3+Fh+nz2c4t75E52CSYDSEpaoCc2V5DiwLbJCnUY7BqJN/tBTrCtFqNbmTBdWolSistdXEku1MLcwSORLDYimjs6eD1csXSJ/7hFh3nEZhbmuwY7aaBVSXY5gF1GWZC6hO2GqFaZalIhgOMDaXYio9zeTCHOkzC6RPnWTv4S12bl/j0t4WN58/Y2xxhmh3jKpaGyVlhhygQVhnAbUiW5EwVGdHbg4HGZtNMTYzQefoIKtXNrj58DZv3//BIwHavbvPkxcHtPd30T2aJNoVwdvajKmiVEYuQqf9n51KeQhl3iEUvtYAofaYsJtl89FtHv/4gvTaCm3xCOuf7fHFwWO6xoZo8rpY2TrH9Qc3KTbqMVnLxSS96FeAWrQrFpb5WYaxzjhHZ8ZZ3Fxl8+AhJ7bW+Ob1S9Y+3+PX93/y7q8PdArg+PwUt57ewS8TWawm6t2OXBoCYRcVNrNoX5pjqYh1JXAFfHhCzZzcvcyT315x4foW3759zXe/vOLEmY/pHe7j+9/fsPXgDq5mDzWN9fSM9tCaaKUtEaJIWyhHGGZddskoZ7bXiPT1UGmrYvxUhp6pCbaf3mf/6/ss71wkkUyQWVnA0+zGKOP620Icmz/OwHgfQ1MjeAMu0bRE4qVDMZpJE+sVsQd62by7y9lrV0hfFaYvn3P7px/wtsfJU+YRiLbS5POgyc9ncGKYycU5uo8OEIoEqXfW4w56sFVZUCSG+zkmrAZPztMrzMxVVSxcXqd/OsXCtW10eh3R3g72Dx6wuLqAvaEOm2Q3tTRPTPI6kZnBJ643h/3UOewoPCLy/MUVPpUR++ammd6+RLCrg/pAM8u7m4SCXo6fmmN5b5NTG6dJtLcQzhq5OE/HQBcDEyMSpThhKUW2tgpfpIX+yVG6RgZIHhslnuxgZv08S9KUnuP9qPI1qNRqHH4vmctreEXH5MQYsYFulnbWxZw+PFKObKycnkYU7XJLoD1KOB4ldXaRzPYF3vz9gXf//sNXPz9gcqKNpAT/6qMb+ANOlEoV9koz3miY5NEhYZkUHVtwuJ3Uu4RhVpMWiU5enpLaJgf+SIDZM3MMpkapkjZ0BKsJJCLY6+ykpgYpFFPKDHqGpsdJCFhYwLrHBvG0+IWlE8WR7sOSpyjew9KML++TOH6U5e1l/CJ0/+QQFrsNf7SFyUyK1MIMrvoaCjUa+tJzNAX9tIupkSNxfCKJraYKRbmkPRQP05uexVpXS1lFBR6JgNVipqMngjG3toy5232tQUrF9VDAjcvjFINiHO7pxC+lqLZVSmOsKEzyY3Z2t7xc3d/hxrN7XNrfyK0yU2UFFRYTa7vr7N/bYWS4A42wM8mi9bQEcEprfM1OGp0NVNutWG2SQ50k3yJU+yWsmU1xd2OFucUUE1MDsvf0FGqLWBEJZhcnGRs+TK3syzJZyqHsApYLa6WGlfI0V5goLtaiMItG+vISmvxOca0fd8Aj0WjEUWulTKr00aFD2B01KFVKHE11YopalkAe9T431WKUVUY1mUpzW1ytVvEfiVKyk8hoMhkAAAAASUVORK5CYII=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;A very scary image&quot; title=&quot;&quot; src=&quot;/static/halloween-612616b4a978f1a437985f1e13b46e42-17dec.png&quot; srcset=&quot;/static/halloween-612616b4a978f1a437985f1e13b46e42-ae2e5.png 160w,
/static/halloween-612616b4a978f1a437985f1e13b46e42-8227e.png 320w,
/static/halloween-612616b4a978f1a437985f1e13b46e42-17dec.png 640w,
/static/halloween-612616b4a978f1a437985f1e13b46e42-88536.png 960w,
/static/halloween-612616b4a978f1a437985f1e13b46e42-91c1d.png 1280w,
/static/halloween-612616b4a978f1a437985f1e13b46e42-40219.png 1920w,
/static/halloween-612616b4a978f1a437985f1e13b46e42-5abf6.png 3672w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;div class=&quot;caption&quot;&gt;by &lt;a href=&quot;https://www.flickr.com/photos/gaelvaroquaux/29632530995/in/photolist-M9wt5P-97P7tg-4vzLRF-61r11U-Zt2GHV-cY8aNJ-cY7ZgL-UXxYV9-b4qibP-4tm3wK-7haukg-2JiX6D-cVsp9-cY7XLU-4eeRFT-8PsYcb-cY7X8j-5jUhKv-jVRzRb-97Sb5A-7aBbJH-dZNRw2-smkRf-gxqQt3-aqqb74-gxs9eF-62dAE-FnZJs-62dXh-ZWp8CL-DpiJqc-WuwzSK-FnXvG-Ef1yLk-7omXUv-r5iPPD-pDGN7f-61hnvE-FnZKU-FnXv1-n28gM8-quLHEs-iAsBz-WBEwee-5z3uaW-pEQPCo-efPVZU-YbEZgy-dVfyAo-nHKteU&quot;&gt;Gael Varoquaux&lt;/a&gt;
&lt;/div&gt;&lt;/figcaption&gt;
&lt;p&gt;The &lt;a href=&quot;https://www.kaggle.com/c/spooky-author-identification&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Spooky Author Identification&lt;/a&gt; provided snippets of text from three horror-themed authors - Edgar Allan Poe, HP Lovecraft, or Mary Wollstonecraft Shelley - and asked participants to build a model capable of predicting which writer authored a particular bit of text.&lt;/p&gt;
&lt;aside style=&quot;grid-row-start: 114;&quot;&gt;The EDAs I chose for analysis were &lt;a href=&quot;https://www.kaggle.com/arthurtok/spooky-nlp-and-topic-modelling-tutorial&quot;&gt;Spooky NLP and Topic Modelling Tutorial&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Anisotropic&lt;/span&gt;, &lt;a href=&quot;https://www.kaggle.com/ambarish/tutorial-detailed-spooky-fun-eda-and-modelling&quot;&gt;Tutorial Detailed Spooky Fun EDA and Modelling&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt;, and &lt;a href=&quot;https://www.kaggle.com/headsortails/treemap-house-of-horror-spooky-eda-lda-features&quot;&gt;Treemap House of Horror Spooky EDA LDA Features&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt;.&lt;/aside&gt;
&lt;p&gt;What&apos;s interesting about this dataset is its simplicity; there&apos;s very little unstructured data accompanying the text, other than author. As a result, all the EDAs focused solely on different approaches to parsing and analyzing language.&lt;/p&gt;
&lt;p&gt;Each author begins by examining the dataset, picking out a few rows, and plotting the number of stories per author. &lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt; also looks at word lengths per author, while &lt;span class=&quot;name&quot;&gt;Anisotropic&lt;/span&gt; plots a bar graph of overall word counts:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/arthurtok_word_freq-fee8685cfd4662db8b70c72cfb775980-9ca14.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 64.28571428571428%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABG0lEQVQ4y62TT0sCURTF/VZ9gUDNr9BWopXQEAiCoItaGOgu29QmDFy6GESxjYssMsmFDZRGGxnm/zjDzDR/3sk3oDTgIug9uNx374PDj8c5KTA+qd+DaZrQdR2KokCW5W1XVRWSJMWzYRjQNG37Rvee5+0WZEooTqfsBMMwhMDzIIT8qxKE87sLtoRvVxxs0mZH+HFdxAR5NoRUXVgTvpA8TlUXYcSQcG9hYL8loNKZ47L/Bf5JxOxz7c/VN4Ig+rtt3m+reA045BY6DlozZOvPyJ6PkCkNkSncI33cQ/qoi0NugJPqEOXaA84aj6g3x2jeTLAUraSg4zjwfT/uNA3U/ZZlwbZtuK4bd7rf3DepokWTwywpUZT8hh9omuNzykoIxAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Anisotropic plots a graph of overall word frequency&quot;
        title=&quot;&quot;
        src=&quot;/static/arthurtok_word_freq-fee8685cfd4662db8b70c72cfb775980-17dec.png&quot;
        srcset=&quot;/static/arthurtok_word_freq-fee8685cfd4662db8b70c72cfb775980-ae2e5.png 160w,
/static/arthurtok_word_freq-fee8685cfd4662db8b70c72cfb775980-8227e.png 320w,
/static/arthurtok_word_freq-fee8685cfd4662db8b70c72cfb775980-17dec.png 640w,
/static/arthurtok_word_freq-fee8685cfd4662db8b70c72cfb775980-9ca14.png 700w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Notice anything odd about the words that appear in this word frequency plot? Do these words actually tell us much about the themes and concepts that Mary Shelley wants to portray to the reader in her stories? These words are all so commonly occuring words which you could find just anywhere else. Not just in spooky stories and novels by our three authors but also in newspapers, kid book, religious texts - really almost every other english text. Therefore we must find some way to preprocess our dataset first to strip out all these commonly occurring words which do not bring much to the table. - &lt;span class=&quot;name&quot;&gt;Anisotropic&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Each author builds word clouds showing the most frequent words largest:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/headsortails_wordcloud-5017c6b57646ef3e1e34e0eefe6dfc87-961af.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 64.28571428571428%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABhUlEQVQoz42S/0+CQBTA+///D5vNOVNcaYcgKolgAUqxExCQAyH8AunCRLSrfqoN52e32912n3dv772r01/W63WWZWmaxnEcRdHpLFf/7hRFNZtNgiCuC4WbH8rlMk3TF8mYwPDt3mBYq4VhiF5VixsoAASiiFe235+Tj8eTrYZoEhaLxUrlVmZMmbHel1vYU0PDPR4OufI2Slx96cDFm6rPeX41mSBO8J/EFYQzmn6TpHNpH9Js7b8bInKGitp41Fr9cY2xuxzqCyYgZ0znnBxYK1+buyyL2Mdpq2P1JV3yqPseIDp3lZZnLj+TND9tz7MeHlC3qzQG7vOLThBatWqaJs8LEEJvGkRBlCvjwO6rY9ADudpFgmzU62ajgaMozSe5zoWjUbJY5MrZ4aiTLOJ4XCeHYTyOm3HSVHLmI+i027iEkWHk/xzH30K7vfE8laImAGjjsW3bJElalnXRkGCSJAEAlEolrEFVE1hJESFu5EXyL7vdDu8fm8+Vv4mXH/jw78EXLPjMdTtZkmQAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Heads or Tails builds a word cloud of the 50 most common words&quot;
        title=&quot;&quot;
        src=&quot;/static/headsortails_wordcloud-5017c6b57646ef3e1e34e0eefe6dfc87-17dec.png&quot;
        srcset=&quot;/static/headsortails_wordcloud-5017c6b57646ef3e1e34e0eefe6dfc87-ae2e5.png 160w,
/static/headsortails_wordcloud-5017c6b57646ef3e1e34e0eefe6dfc87-8227e.png 320w,
/static/headsortails_wordcloud-5017c6b57646ef3e1e34e0eefe6dfc87-17dec.png 640w,
/static/headsortails_wordcloud-5017c6b57646ef3e1e34e0eefe6dfc87-88536.png 960w,
/static/headsortails_wordcloud-5017c6b57646ef3e1e34e0eefe6dfc87-91c1d.png 1280w,
/static/headsortails_wordcloud-5017c6b57646ef3e1e34e0eefe6dfc87-961af.png 1344w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; builds a word cloud of the 50 most common words&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; also plots overall sentences, sentence, and word length per author, and discovers subtle but measurable differences between the authors.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Anisotropic&lt;/span&gt; and &lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt; discuss tokenization, and removing stop words:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The work at this stage attempts to reduce as many different variations of similar words into a single term ( different branches all reduced to single word stem). Therefore if we have &quot;running&quot;, &quot;runs&quot; and &quot;run&quot;, you would really want these three distinct words to collapse into just the word &quot;run&quot;. (However of course you lose granularity of the past, present or future tense). — &lt;span class=&quot;name&quot;&gt;Anisotropic&lt;/span&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;After the tokenization, stop word removal and lemmatization, &lt;span class=&quot;name&quot;&gt;Anisotropic&lt;/span&gt; rebuilds the graph of top 50 words:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/arthurtok_word_freq2-dea71eb1db8ec6ec87f67a5317a26a56-9ca14.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 64.28571428571428%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsSAAALEgHS3X78AAABf0lEQVQ4y62Ty0sCURTG+5MG1Aii5ZCKFS6jhxARBbVq0yZSIoKk+geqVbUI7K3SAwpaRLpxoRVoFMg4ojM+xikf49wv7w1Dy4VkHxzOuedefnwc7unCP6urVTOTyUCSJKRSKVan02mW62d6J8sy8vl8e8COHWqaBiEUAiGko/gG6rqOmHsZJOwB+RA6d1ipVPDsXIC+ZUIhMo0kiaBKqn93SPWyssiAYqQfR3BhDUl4S1Womt6ZQwYkLtiIAENCRfdNHHP+V2xevuEiIOIhLEFMvyOnlFEqV1s7pIefDgfwBTTVgH07ERic9+Amr8CN+sHZj8ENetBjP4Rt5BRTMz5Eo3J7Do0MGIZh6TfQVIte2wE44zaCQaF5hrGNVVR2rRCfhuHV1jGuCTAnFFju4rDvP8LsDoCfvwU/ew1+wgfecQ6r4wxDYyfgLXsIhcRmYKFQQC6Xg6IoyGazbDuKxSLLtE+3pLFWVZVl+r5xY9raFDpj+lcbh18X7dOR1fUJcq+vPnXXP44AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Anisotropic replots top 50 words after stop word removal&quot;
        title=&quot;&quot;
        src=&quot;/static/arthurtok_word_freq2-dea71eb1db8ec6ec87f67a5317a26a56-17dec.png&quot;
        srcset=&quot;/static/arthurtok_word_freq2-dea71eb1db8ec6ec87f67a5317a26a56-ae2e5.png 160w,
/static/arthurtok_word_freq2-dea71eb1db8ec6ec87f67a5317a26a56-8227e.png 320w,
/static/arthurtok_word_freq2-dea71eb1db8ec6ec87f67a5317a26a56-17dec.png 640w,
/static/arthurtok_word_freq2-dea71eb1db8ec6ec87f67a5317a26a56-9ca14.png 700w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt; plots his top 10 words overall and by author, finding a different set:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/bukun_top_ten_words-5cede7d471e776984e87bbcef88aa838-40219.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 44.99999999999999%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAAy0lEQVQoz4WSwQuCMBTG/e+LqGNdCqGgDh3DLlHXDnUwiEqIiorEVBCSptvaWy8lI7H2+MY22G/v23vTpJRBEPjblbsxfWthL+fMPjyco1Kcc40xFsexpZdkv6wUmBNYT1NRSjW8ACd30JRGXSmgRAgBSXzgS6+mzmw0gNMv2PO8KIr2nYras71D5gvGNye2W8VWRzqQG5DwJRB5GAcW7NStFicct7PTaeRhjPMveDb8B2OfsWYxIdixVPcwzBbu1cFfwN6BHrFA2fYJrMLSwIP86EEAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Bukun&apos;s top ten words&quot;
        title=&quot;&quot;
        src=&quot;/static/bukun_top_ten_words-5cede7d471e776984e87bbcef88aa838-17dec.png&quot;
        srcset=&quot;/static/bukun_top_ten_words-5cede7d471e776984e87bbcef88aa838-ae2e5.png 160w,
/static/bukun_top_ten_words-5cede7d471e776984e87bbcef88aa838-8227e.png 320w,
/static/bukun_top_ten_words-5cede7d471e776984e87bbcef88aa838-17dec.png 640w,
/static/bukun_top_ten_words-5cede7d471e776984e87bbcef88aa838-88536.png 960w,
/static/bukun_top_ten_words-5cede7d471e776984e87bbcef88aa838-91c1d.png 1280w,
/static/bukun_top_ten_words-5cede7d471e776984e87bbcef88aa838-40219.png 1920w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; does this as well, additionally looking at top words by author, after tokenization and stemming.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt; and &lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; both then use TF-IDF to to find the most &quot;important&quot; words for a particular author.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/headsortails_tfidf-66465cea8aefab2cbc4908fffdb9fb66-961af.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 64.28571428571428%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABfElEQVQoz2P4jw38+fPn2bNnP8+fef725done8/f+/Hg6du/f/+iKWOAq8YCPn789ef3q+/vPn378/MXFnkGiM63YPDmzRtMBlZBILn34mcyNQOZy458YwDq/PTp0zswAEpgMrAK3n78IXPhP4bXr1+TavPzl28n7/wB0vzy5UtSNR+6/KlgyV+QZmCUfPnyhUhnH31yvuHqrILVb6Ca8QTY05dvbzx7fOHJvSc37225enPLoSvF69KF9rmlrXyC0Pz19/fIszU1B4+Gnalas7Ylft/KlM31S2edAUrbbZ3ssHXa1r6tYeu2lS3bX7wsDkUz0NqXH9+oHQ6N27Zb/2jMnEV5/rvnZm1rXbPwXMXKP4F75gbtmb97xu60bXua1h1pWJ+neTi8dOPT2rW/gbIgm4HpDuil9+/ff/z4EeI3IAPIhQh++PAB4me4IIQBVAbS/PPnTyAHGNvAkHv16tULMAAyvn//DgkCoGog+/Pnz8DQBUYtMEQ+gwEAAeuoIVyrUUAAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Heads or Tails plots the most significant words by author in a bit of a different chart&quot;
        title=&quot;&quot;
        src=&quot;/static/headsortails_tfidf-66465cea8aefab2cbc4908fffdb9fb66-17dec.png&quot;
        srcset=&quot;/static/headsortails_tfidf-66465cea8aefab2cbc4908fffdb9fb66-ae2e5.png 160w,
/static/headsortails_tfidf-66465cea8aefab2cbc4908fffdb9fb66-8227e.png 320w,
/static/headsortails_tfidf-66465cea8aefab2cbc4908fffdb9fb66-17dec.png 640w,
/static/headsortails_tfidf-66465cea8aefab2cbc4908fffdb9fb66-88536.png 960w,
/static/headsortails_tfidf-66465cea8aefab2cbc4908fffdb9fb66-91c1d.png 1280w,
/static/headsortails_tfidf-66465cea8aefab2cbc4908fffdb9fb66-961af.png 1344w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; plots the most significant words by author in a bit of a different chart&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt; looks at top bigrams and trigrams (collections of two and three words, respectively).&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/headsortails_wordrelationship-8af18c601d8ffbebcc0e28d5e3dadb36-961af.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 64.28571428571428%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAB2HAAAdhwGP5fFlAAACJklEQVQoz21SW2+bMBTO//8le5j2tIdJU7VpU5K1gXA1BhuMDeZibgFCyJKWdKdSNWldz5Nl+5zvdlbP/9U0TUwkqu2CMOrG4/VpuTwtz+/V6u9pHMeAhpjQ9f1OM+00TXHELNvWTcv2sGGa7TiNp3m53d42t21r4YBx3o2T4zhwPp/PlMUuoV3XwbgHfU+jqGzaom764+m1uSxLP2IBIeowGLaDEDI9X+Y5T2WWZREX+/0eekjENMMUQqSlag794/KCv4LBWZ5bLgKFhBAU0H485mXJOTdxkGaZLCtQ5BPqBiSMogfDkkXphfFLM415UigQ6eIgkZIl6ff1BtACntxut2meSRRrplW1B90wNMNIstynYcjFOJ1WP9ebz1/vclUBSxt5p3mWeYFoNAwDkzljrO4O8zwLmUkpwc40LzJVAXMguKqqCmE/TtJ7bV8otdn+AvCqrikXfd8Lkbh+AAXi4Q/k14/j3rJSKcGIla7rHz5+wjRSVeViPysKkZdJklR1w7ho+8GDJ6WCWKimBf+3Ow0II8peNF8uF8fDXGaE0jgrAIQnCQ5Z0zQW8n5fH+EeQMBXcIeGUShSwAAtrznXdZ2X6l7TWSoRxtPlCiG5AQVAkPrl7hso3+oGhHc8zYbtlnXzz5KAPQh5LkIsK0DSzjCH6WQ7TnUYYpgYEMtxfqw3oPx6vb6znlDLsgAL3/dDFkMePuPz+WyY1jifi6KE1ze7/Qegxbxv+waQmwAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Heads or Tails plots the word relationships for bigrams&quot;
        title=&quot;&quot;
        src=&quot;/static/headsortails_wordrelationship-8af18c601d8ffbebcc0e28d5e3dadb36-17dec.png&quot;
        srcset=&quot;/static/headsortails_wordrelationship-8af18c601d8ffbebcc0e28d5e3dadb36-ae2e5.png 160w,
/static/headsortails_wordrelationship-8af18c601d8ffbebcc0e28d5e3dadb36-8227e.png 320w,
/static/headsortails_wordrelationship-8af18c601d8ffbebcc0e28d5e3dadb36-17dec.png 640w,
/static/headsortails_wordrelationship-8af18c601d8ffbebcc0e28d5e3dadb36-88536.png 960w,
/static/headsortails_wordrelationship-8af18c601d8ffbebcc0e28d5e3dadb36-91c1d.png 1280w,
/static/headsortails_wordrelationship-8af18c601d8ffbebcc0e28d5e3dadb36-961af.png 1344w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; plots the word relationships for bigrams&lt;/div&gt;
&lt;p&gt;Both &lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt; and &lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; perform a sentiment analysis, and look at overall negativity per author.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt; uses something called &quot;NRC Sentiment lexicon&quot; to examine the amount of &quot;Fear&quot;, &quot;Surprise&quot;, and &quot;Joy&quot; in each snippet of text, and visualizes the sentiment of various authors using word clouds, tables, bar charts.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/bukun_wordcloud_joy-1ed666f48f0d1a7428f3432230b93a0a-40219.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 44.99999999999999%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAIAAAC9o5sfAAAACXBIWXMAAB2HAAAdhwGP5fFlAAAAcElEQVQoz7XRSQqAMAwFUO9/LxFcuYuzXVRxxAFtm9QRbxDEv/6PBL5zfYjzCz70QiLXfnCMKxtPdY0V6NSjNjt3YuCnrWL3kaqMJilO3HiX167pRV7KWQ8N7+3sTQiQFCBHQKsYGBGNMdZaIvprqhtAJhMpW3ZDywAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Bukun plots a word cloud for words matching Joy&quot;
        title=&quot;&quot;
        src=&quot;/static/bukun_wordcloud_joy-1ed666f48f0d1a7428f3432230b93a0a-17dec.png&quot;
        srcset=&quot;/static/bukun_wordcloud_joy-1ed666f48f0d1a7428f3432230b93a0a-ae2e5.png 160w,
/static/bukun_wordcloud_joy-1ed666f48f0d1a7428f3432230b93a0a-8227e.png 320w,
/static/bukun_wordcloud_joy-1ed666f48f0d1a7428f3432230b93a0a-17dec.png 640w,
/static/bukun_wordcloud_joy-1ed666f48f0d1a7428f3432230b93a0a-88536.png 960w,
/static/bukun_wordcloud_joy-1ed666f48f0d1a7428f3432230b93a0a-91c1d.png 1280w,
/static/bukun_wordcloud_joy-1ed666f48f0d1a7428f3432230b93a0a-40219.png 1920w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt; plots a word cloud for words matching Joy&lt;/div&gt;
&lt;h3 id=&quot;feature-engineering-3&quot;&gt;&lt;a href=&quot;#feature-engineering-3&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Feature engineering&lt;/h3&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt; suggests a number of possible features to add, including number of commas, semicolons, colons, blanks, words with capitals or beginning with capitals, and graphs each one. There do appear to be some correlations for some authors against some of these features.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; notes that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;We have already noticed that our three authors can be identified by the names of their most prominent characters; with Mary Shelley writing about “Raymond” or Lovecraft about “Herbert West”. But what about names in general? Are some authors more likely to use names under certain circumstances? After sentence or character length this is one of our first feature-engineering ideas on our quest for knowledge&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;From this insight, &lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; relies on the &lt;code&gt;babynames&lt;/code&gt; package, featuring a list of most popular names per a given year, to add an additional feature to the data.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Bukun&lt;/span&gt; and &lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; both look at the gender pronoun breakdown between authors, and &lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; also looks at sentence topics, starting word per author, and last word per author, number of unique words, fraction of distinct words per sentence, dialogue markers and alliteration (which is a cool idea!)&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/headsortails_alliteration-2dae671d9f72ccbcbed91021919d3364-961af.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 64.28571428571428%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAB2HAAAdhwGP5fFlAAABbElEQVQoz2WRCXaDMAxEuf8F27QhYFbjBbK/7PTbIgltJ36KhEb2eJyM43i/34f1Zr1eS9xspgjGiCFW/wnJ9XolU7VnNZ13znk/RfB4POiWTeiWjftDSLTWu93uVUv80ivWssuNMYfDQTai9anThU5XnWKF4ePxeLvdaFhrp2htZw25cZYusl0ELcMv0oSQcOHtdvvr5LLwhfJ1Tcmk6HrfpWl8XQVCkSe05WLn85ldiDjxysWw0+kEgTgMg+S0yKdhxDQRVVVlWVYURdu2fd/LMGy+4A6xLEulFF5QTm4jZ1X5tOz9E4hkWEQVTY/VGF61vtbvCybIEMNMcMpN3gR3QkWXk62TOpgZaTbyTYLU+VMJlKl4qu8uQ7w8lWzK46U6X7ThtT7aZXA7DOOeyv0MIptj9/t9KIO9KvhclW/ZtJHdWztE9hz4KXaG4tmd08Iwf3me4x421hEkuIrtl8sF2ZjMOW2EjuALtB8sINOZlBWQJQAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;heads or tails plots various measurements of alliteration by author&quot;
        title=&quot;&quot;
        src=&quot;/static/headsortails_alliteration-2dae671d9f72ccbcbed91021919d3364-17dec.png&quot;
        srcset=&quot;/static/headsortails_alliteration-2dae671d9f72ccbcbed91021919d3364-ae2e5.png 160w,
/static/headsortails_alliteration-2dae671d9f72ccbcbed91021919d3364-8227e.png 320w,
/static/headsortails_alliteration-2dae671d9f72ccbcbed91021919d3364-17dec.png 640w,
/static/headsortails_alliteration-2dae671d9f72ccbcbed91021919d3364-88536.png 960w,
/static/headsortails_alliteration-2dae671d9f72ccbcbed91021919d3364-91c1d.png 1280w,
/static/headsortails_alliteration-2dae671d9f72ccbcbed91021919d3364-961af.png 1344w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;heads or tails plots various measurements of alliteration by author&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt; ends his kernel with an alluvial plot showcasing feature interaction:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/headsortails_alluvian-9d47983c94d59519ee23cc27ba460d8a-961af.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 64.28571428571428%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAIAAAAmMtkJAAAACXBIWXMAAB2HAAAdhwGP5fFlAAACzElEQVQoz0VSbVMSURTm71Vf+lQfapqpqWTKaaZsKq3AlJHRcoYkkEZUJhR10FB8Y1EhEAF5UWAH8A1jQ5ZlYWFZ2HtBaG8L1nQ+Pefeec55zjmPpNVqXVxeMIhBCDWbqFqtU1SL58UMQZYBtUoLtcR3hkEs2ygWm6gT2Wa20WhIms2mD/q8yLslbE3EPfjxuckXr1A0fV44W3Wf7obOXPGfRAvHUTIJZ2chy6I9tKcCKgihpFarrZRXLIJFgPXIJFYr5r3mBSvjXkuZ9ivuNEjjR4v5RmbZ+hvHoWa8pvDbFYJCW1W3yQAAZ9GujUgPJg1cmikUynSCTG+GC5lDK7QewINPQPHl6PXtHxqcSQ2fmK57FMb4RGlK0yaLsmEoZEuN92XH1myXJAnn5sGBL2L0SPVQH4TBD5fv+6LPpcleD+UZKY2O2mY891WcUkmSZIeMYWWH/Wl6+O7cKpkDL9SJ/n2ZItsbCRhJIkq4Z8Z101bXYKqcCMRMtHLMf/Pd4RvD35kZi4Xu7tebFu6cyElIdqcHuuwvnSEHNJtFUdSIzP/wq2AwwHi8qtelep+cGNZ1w7l/sjGMeCB3XRuazIzGfsU+H78a02Kpx8qSRkPt7GQeyU67nglyORQ3plYzm/OBhMO+XatUKu2FRTeSgVsjqXtyODzAFci8earQMxS4Ic9+1NcCYZv0O72x2NCouFgMWCzVaNiLxRysj+f5zp19UPs205ANtsuTJBgYEIHjtnZ5moyGq7YerL4XiuSO8nk+flakFzdSC99O1zszi92XlgoYJqBI5D9Zp4uHgF4Pg0GYTKKE1hHQrUSOos7NlV1XmNvxJ5XGbDYrqdfrXm8VgLbpBJerQhCijxAAgoCcTj4a5dxuxHEIeTwcjvOrq8L2NhnMOJ2A4zhJoRNXjmVZVsQ0TV+luVyOIAi+Y3TRySKmKOrqq1QqifgPiKhymnXxw0YAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;Heads or Tails&apos; alluvial plot showcasing feature interaction&quot;
        title=&quot;&quot;
        src=&quot;/static/headsortails_alluvian-9d47983c94d59519ee23cc27ba460d8a-17dec.png&quot;
        srcset=&quot;/static/headsortails_alluvian-9d47983c94d59519ee23cc27ba460d8a-ae2e5.png 160w,
/static/headsortails_alluvian-9d47983c94d59519ee23cc27ba460d8a-8227e.png 320w,
/static/headsortails_alluvian-9d47983c94d59519ee23cc27ba460d8a-17dec.png 640w,
/static/headsortails_alluvian-9d47983c94d59519ee23cc27ba460d8a-88536.png 960w,
/static/headsortails_alluvian-9d47983c94d59519ee23cc27ba460d8a-91c1d.png 1280w,
/static/headsortails_alluvian-9d47983c94d59519ee23cc27ba460d8a-961af.png 1344w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Heads or Tails&lt;/span&gt;&apos; alluvial plot showcasing feature interaction&lt;/div&gt;
&lt;h3 id=&quot;takeaways-3&quot;&gt;&lt;a href=&quot;#takeaways-3&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Takeaways&lt;/h3&gt;
&lt;p&gt;This is a fascinating competition to study since the text snippets are longer and there&apos;s no structured data to rely on.&lt;/p&gt;
&lt;p&gt;Kernels tended to leverage NLP best practices, like lowercasing words, stemming, and tokenization. Kernels also tended to use more advanced techniques than were seen in the Toxic kernels, like sentiment analysis and bi- and trigram analysis.&lt;/p&gt;
&lt;p&gt;In both competitions, kernel authors used &lt;a href=&quot;https://www.kaggle.com/headsortails/treemap-house-of-horror-spooky-eda-lda-features&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;TF-IDF&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For feature engineering, authors engineered a variety of new features including average words per sentence, punctuation choices, and whether words were duplicated.&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;images&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;images&quot;&gt;&lt;a href=&quot;#images&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Images&lt;/h1&gt;
&lt;p&gt;So far, the datasets have all been purely text-based (either language, strings or numbers). The last two datasets I chose to look at were image-based.&lt;/p&gt;
&lt;p&gt;The two competitions I examined (&lt;a href=&quot;https://www.kaggle.com/c/data-science-bowl-2017/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;lung cancer&lt;/a&gt; and &lt;a href=&quot;https://www.kaggle.com/c/leaf-classification/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;leaf classification&lt;/a&gt;) were both far more domain-specific than the other ones I looked at. As a result, the analyses tended to assume an advanced audience, and authors skipped over rudimentary analysis in favor of exploring different techniques for image analysis.&lt;/p&gt;
&lt;p&gt;I saw a great variety in terms of the visualization techniques used, along with features that were engineered. In particular, some authors in the lung cancer competition drew upon existing medical knowledge in order to engineer extremely domain-specific features. I can&apos;t speak to how effective those features were, but I can say that the visualizations they produced were stunning.&lt;/p&gt;
&lt;h2 id=&quot;leaf-classification&quot;&gt;&lt;a href=&quot;#leaf-classification&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href=&quot;https://www.kaggle.com/c/leaf-classification/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Leaf Classification&lt;/a&gt;&lt;/h2&gt;
&lt;p&gt;The Leaf Classification competition includes 1,584 masked images of leaves, organized by species. Participants were instructured to build a model capable of classifying new images into one of the categories.&lt;/p&gt;
&lt;aside class=&quot;center&quot; style=&quot;grid-row-start: 162;&quot;&gt;
The EDAs I chose for analysis were &lt;a href=&quot;https://www.kaggle.com/lorinc/feature-extraction-from-images&quot;&gt;Feature Extraction From Images&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;lorinc&lt;/span&gt;, &lt;a href=&quot;https://www.kaggle.com/selfishgene/visualizing-pca-with-leaf-dataset&quot;&gt;Visualizing PCA with Leaf Dataset&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;selfishgene&lt;/span&gt;, and &lt;a href=&quot;https://www.kaggle.com/josealberto/fast-image-exploration&quot;&gt;Fast Image Exploration&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Jose Alberto.&lt;/span&gt;
&lt;/aside&gt;
&lt;p&gt;A good first step is to look at the images of the leaves, which is how two of the EDAs start.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/selfish_overview-e383f1c3046b4a9e3f0bb0146dec97a8-9db5e.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 82.0754716981132%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsSAAALEgHS3X78AAAC20lEQVQ4y32Uyyu1URTGt1uUEpLcCwMlSopjYCADoZwJM5fcbwkRDhEZOMetDHTKP6AMiZR/wf06kPstd/6Dx/c8X+8uffUNdu/7W+/ez9lrrWcdc39/j8HBQXg8HszMzOD5+RnDw8MYGhrC1NQUPj4+9M7vY2Nj+P7+1pNnRkZGxBMTExgYGMDo6CjM8fExAgMDsbKygrS0NFxdXYl9Ph/i4uLw+vqKoKAgLC8vIyUlRQIhISHo7OyEMUYcHh6OjY0NJCUlwdzc3KCrqwv9/f0YHx/H09OTmIs3fX9/13t3dzf6+vok0NPTY/eQGZ+cnBQbprS7u6t1enqKz89P7O3tiY+OjvD19YX9/X3s7OyIKXBwcCA+PDwUM769va24UubV8/LybMoBAQHIyclBQkKCUg4NDUVJSQmio6NtypmZmdrnpMzz1DFnZ2eIjY1FRUWFgiwBa1dWVoasrCwJJiYmora2Frm5uRJgrUpLSxEfHy9OTU2F2+2WjmGAdeJBPh1+e3v7h7n+x9Qw5+fnyM/PR2FhISorK0EbkQsKClBeXq6NDhcXF0uAe10ul2LkoqIiy7aGbW1tv2zT1NSkVPWrf76np6erVhQICwuTA2JiYmwN29vbdc7QyKurq1pbW1u6kcObm5vqusPr6+sSWFtbszEy4w6bx8dHeL1eTE9PY2lpCS8vL5oYst/v16TMzs7K6AsLCxKYn5/XGe4jM86pmpub+5sy29/R0WFTZgoUY/eclBsaGhAZGWltU1NTg+DgYDFdsbi4KCsZClRXV2v19vaCN66vr9escjrYQX6rq6tTXSnA95aWFsXJjY2NaG5uFhtOAkWvr6/x8PAAh7nu7u7E9CaZTwrc3t7i8vLSMvddXFwobrucnJxsUyZzKmhUJ+WoqCjbZaacnZ3968+BtmH3zcnJiTbQSxkZGbopmZ7iRFCQTC86NaRAVVUVIiIixPzx1tZW1fIHujI8SYL4do8AAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;selfishgene examines the leaf specimens&quot;
        title=&quot;&quot;
        src=&quot;/static/selfish_overview-e383f1c3046b4a9e3f0bb0146dec97a8-17dec.png&quot;
        srcset=&quot;/static/selfish_overview-e383f1c3046b4a9e3f0bb0146dec97a8-ae2e5.png 160w,
/static/selfish_overview-e383f1c3046b4a9e3f0bb0146dec97a8-8227e.png 320w,
/static/selfish_overview-e383f1c3046b4a9e3f0bb0146dec97a8-17dec.png 640w,
/static/selfish_overview-e383f1c3046b4a9e3f0bb0146dec97a8-9db5e.png 848w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;selfishgene&lt;/span&gt; examines the leaf specimens&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Jose&lt;/span&gt; plots the various species, and notes that there are 10 images per species. He also looks at the similarity of leaves, within a category, to each other:&lt;/p&gt;
&lt;img alt=&quot;josealberto creates a gif of all the leaves from a category&quot; src=&quot;/static/jose_leaf_morphing.gif&quot; /&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Jose&lt;/span&gt; compares leaves within a category&lt;/div&gt;
&lt;p&gt;Meanwhile, &lt;span class=&quot;name&quot;&gt;lorinc&lt;/span&gt; jumps straight into analysis, locating the center of each leaf and applying edge detection. &lt;span class=&quot;name&quot;&gt;lorinc&lt;/span&gt; also converts the outline of the leaf into polar coordinates, in order to more effectively measure the center of the leaf:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Later we might want to switch to another measure of centrality, based on how efficient this center is, when we generate a time-series from the shape, using the distance between the edge and the center. One way to do that is just measure the (Euclidean) distance between the center and the edge... but there is a better way - we project the Cartesian coordinates into Polar coordinates.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;selfishgene&lt;/span&gt; chooses to look at the variance direction of the images, writing:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Each image can be though of as a different &quot;direction&quot; in the high dimensional image space&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/selfish_variance-d4b37336a386d65e6286d4fa0c4a9c5e-1cbbd.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 74.53271028037383%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsSAAALEgHS3X78AAAD6UlEQVQ4yz2TW0wUZxTHp0kf+ta3PjZ9blLbpg8Gk8aIYhNjmlZ9sJUaSbGmovWCLiC3lGolKFBArqIGCiJRhIKCpiCXSikoCAsI7C4Dex12YZfZXarssLO/fh2aPvzznZzM95v/Od85ktnsIDu7k4yMDkymVmprh3AEFW77emhY+p1brk4eBoZRVTuKJwe3M5NF2YTPW0BAXeH5ah1PlWr6XFUMr9xEunt3gjfeKiEhuZpPdlYTF1fHeNjGN7Eq0uQsUv15pEUbCKqjrAck5lrfw9ryLq9X32FFXaJNT6B6OpGrz47Rqu/eBL75diUHTxdz4GghcdsaDeChWDXnX2STZC7jXLRpE+iVGLnxgdAW1t2bwA5tJ7lPTWT0ZNG1/CmSxeKhsXFM6IVxdnW9xKP6+GNtytDA2iQj4VlRsptQsJGQuqmgeo9V1Y91rduQ5b9T8oTG6Fs5xaBylH53MuOhUhZCi5T7a6nwlVGmlNAUbMEddFOjipy3lAqliHq1QfTQR28ok46ls3Q7j9OzmoG0KKgj8vs8fBzP0N2PGF07wrRwdFLPJ9ds4rL9By5Hy5FDC5yMidyMiTz5PNl6sShZoTO2neuzifw6dIDu19s2gU/DH9P/YCvD3R8yHEk2gOlkU2/fT6n6LfnRa8L1AmnkkOdJ5aJyllz9qgFsI4GHwR00+vfRFktACqheFr0T2FyjWBzP8KxYxId+LD4rU65pJhyTyMsL+NWAyFmYdk9jdpix+Wyih6vi7iSzjufMCS2IWJLDQ/ymJVGjpVMXOU1/5KIo7yU3tHNUalmUaTncixRgCS5xUHvMoUgXXwsd03rxiTlM36glXbvOT1qREUvWtX56V7dyZ/ILmm2fMxBJwRaeoP7vAxS5vueK4wQtr04zE1LYH6tj91g7n/3VymG9Ba+6zCl+5oizkq9e3uSMfhFpPjwoBjKRouUcbqvf0ScczYemqNHPUBjM5cfwFZo3LjEnHO7TH7HX38vh9RaSoj3C4TKpehWXIpc5H67EpJcj+UUfLC47M3aZKdmKc9krxiGA7F7EYrcyI8/i9Lo3+6XY/885lpxGzqnIzNtnscrTOD3zSI/WXGxhiO2BTnbq7SRujDMZnuME+eKPOaSsF5AXrRGuF43yUqN5ZGoXyNJ/EQ+l0MEOY+U6tHjaiUd6LIB7o83s+fMee2ZbOL4xYABNei4XrFkkOSoo2SgwgOmxbJKVUs54L4mxKTSAbeyifWUXjfKX3I+KXR4WzU7RzJwLjJChDVLw2oLt303R7lCr1XHtVTMN6w9wik2p0Jqo1hooXr/Prch9AfQxqKUxoGXyJJJrxP8AoZ+9UYynxRAAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;selfishgene looks at the variance of a leaf image&quot;
        title=&quot;&quot;
        src=&quot;/static/selfish_variance-d4b37336a386d65e6286d4fa0c4a9c5e-17dec.png&quot;
        srcset=&quot;/static/selfish_variance-d4b37336a386d65e6286d4fa0c4a9c5e-ae2e5.png 160w,
/static/selfish_variance-d4b37336a386d65e6286d4fa0c4a9c5e-8227e.png 320w,
/static/selfish_variance-d4b37336a386d65e6286d4fa0c4a9c5e-17dec.png 640w,
/static/selfish_variance-d4b37336a386d65e6286d4fa0c4a9c5e-1cbbd.png 856w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;selfishgene&lt;/span&gt; looks at the variance of a leaf image&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;selfishgene&lt;/span&gt; also spends some time looking into image reconstruction, model variations around the mean image, and eigen vectors; he explains:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;&quot;The upper most row contains the data distributions of each eigenvector (i.e. the histogram along that &quot;direction&quot;) The second row contains what we already saw in a previous plot, what we called the variance directions. The forth row contains the median image of leafs. notice that this row is identical for all eigenvectors The third row holds the 2nd percentile images of each eigenvector. it&apos;s easier to think of this as the median image minus the eigenvector image multiplied by some constant.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/selfish_model_variation-000168df170d0755c73d81b954e758d5-2150f.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 75.02917152858811%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAPCAYAAADkmO9VAAAACXBIWXMAAAsSAAALEgHS3X78AAADr0lEQVQ4yzVTWUijVxT+FYsLPvgkKBgRQbDBBUXBER0f3FBxXEbFF1ccsVYc9KWtGRCEPtQtKm51QYWIrVrH2o51ZlRIFWZMTZjJULdEk2hiYv7EpNaUsYWv957Bh8PlO+fec893vnMEm82GkxMjDAYDzGYzHA4H1Opz6PVGXFxcwG63Y2/PRHGTyUTx8/NzvHtnhNFohNPpxPGxieUw4ezsDAJ/oFS6KXB9fQ3+wcOHd5BI/oPF4oTVakVS0r/o6rqFKDroA1F0Iifnjt5cXV1BofgbOzufcggWiw3d3TdYX3exZNe4vLxEY+Mtqqs9eP7cxZJa8PTpLWpqPNjfd7JkIra3HWhouIFWKxKWy2+wu+tmyR0Q9vcN6Oj4hdlvGBnZxZnbDIXtNRTWV1hzv4XLpcOl5RnMxm/gFL+F6LrEG/sUlNYp7LvmCGvEcWisA3h//T2EmRkVpJ93o0r2HWIfzGPv5hCPXTNoVXXhyUcF3C4lPHsCFD88xj9/fAarW4eX5gf4avsZ1k3pDJ/grUGKlz+l43dNIoQXL/5E7qMVNH79M2pr1/DhrzN03y3hR1svhj7+yirUwGPPhOPNI3jEXFy5jXh914Gxk1l2ygirPV9Ao/0SWvEJBK1Wi8nJSbKFhQUcHBxgfHycbHp6mql3gt7eXvT09KCvr48UHhkZwfDwMJ1c+aGhIQwODtIprK2tITk5mTW9BuXl5dja2kJaWhra2tqQm5vLmr2LoKAgNDU1ITg4GIeHh4iKikJnZyekUikVIJFI0NzcTH5BqVSivr4edXV1kMlkbOb2UFVVxVSuRktLCzQaDbKyslBaWoq8vDycnp6isrKSYvzU6/UoLi6mN0VFRZ8oczrcZmdncXR0RNQ4npiYoGHlmNPmlPjw9/f3E5bL5YQHBgboPvczlWcQGBiIkpISREdHY3V1FX5+fkQ/JCQEnIGPjw8qKioQEBAAXoC3tzfFfX19CXt5eaGsrAz+/v4QVlZWEBcXh+zsbBQWFmJzcxOxsbFsE3KQkZFBLbjHCQkJ1MOYmBjC3H+P+XueR1Cr1RgbG8Po6Cjm5uaoybxqTn9+fp7t6TFR56rzSeCqLi4uki0tLRHm/qmpKTKiHBkZifb2dsTHx2NjYwPh4eHU5MTERLajO0SdVx8WFkZjxMVpbW1Ffn4+VRgaGspmuBYREREQlpeX2fInsd1soAu8Z5mZmWyfG0lZlUpF8YKCAqSkpJDK9xPAk+h0OqSmplJP09PT8T9e1j9uUoGBqAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;selfishgene looks at model variations&quot;
        title=&quot;&quot;
        src=&quot;/static/selfish_model_variation-000168df170d0755c73d81b954e758d5-17dec.png&quot;
        srcset=&quot;/static/selfish_model_variation-000168df170d0755c73d81b954e758d5-ae2e5.png 160w,
/static/selfish_model_variation-000168df170d0755c73d81b954e758d5-8227e.png 320w,
/static/selfish_model_variation-000168df170d0755c73d81b954e758d5-17dec.png 640w,
/static/selfish_model_variation-000168df170d0755c73d81b954e758d5-2150f.png 857w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;selfishgene&lt;/span&gt; looks at model variations&lt;/div&gt;
&lt;h3 id=&quot;feature-detection&quot;&gt;&lt;a href=&quot;#feature-detection&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Feature detection&lt;/h3&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;lorinc&lt;/span&gt; suggests splitting each sample in half and treating them as two samples (though he doesn&apos;t pursue this approach). &lt;span class=&quot;name&quot;&gt;lorinc&lt;/span&gt; finds local maxima and minima from the time series (e.g., the leaf graphed in polar coordinates) and notes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Ok, I surprised myself. This worked out pretty well. I think, I can build an extremely efficient feature from this. But this method is NOT robust yet.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It is not finding the tips, but the points with the greatest distance from center. (look at leaf#19)&lt;/li&gt;
&lt;li&gt;It will miserably fail on a more complex, or unfortunately rotated leaf. (look at leaf#78)&lt;/li&gt;
&lt;/ul&gt;
&lt;/blockquote&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/lorinc_minima_maxima-512e60d4a8ec3c2c5a40a6497c84b19a-e6a98.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 50.63113604488079%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsSAAALEgHS3X78AAABtklEQVQoz32Su07DUAyGIxgQCzM8WqVuLOxIvAsUqUvFRYLyEiyMMBCGcGl6yT0nl5OkpWmMf1elRSAsWcdujj//9qnR6/V2q6rq/+e2HZ4YbEqpo7Ks+r6f9JUq+1Gk5bvW67tGu93eXywWBMuyimazhlam9UxO0zRvmbeV5/kZcsuyyB+PafzxQbHn0cB6J9eN5K7R7Xb36rqWZDKZkOM4Euf5lMZctAHczrKsgzyKMvaI7+QUBAH5vk9hmC6BrVbr4OXlVRLALNOium7o+fmNu7pUFJ9k2zaABoBpmoq6OI6pSBLKGMyrIHc4lEYycsAgjG0+maIqCBJ6uL+nycAGDMoF6HnpKdR4PCaAiuOY/btBUSxH5s7UNI2MPBoMyHx8FLA7dEiFIZV5DuBOkiTntGEhf4NirGdlohC7gEKMyEW04J0CiEbwsixFISs4XRVi71CFh3GccA2EQnTBHlCMGFA4cjRj0C+Fvq9kVNRtmihEMOXC+XxOCb8azpnW3w3+Urg58g9gp9PZ5R+v4Vx4wYquEOPkka7C0eiCH+EYQM4POb7TWl8y7NZ1ldQg5r/RDWq+AF9irOJKXbMJAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;lorinc measures the minima and maxima of a leaf plotted in polar coordinates&quot;
        title=&quot;&quot;
        src=&quot;/static/lorinc_minima_maxima-512e60d4a8ec3c2c5a40a6497c84b19a-17dec.png&quot;
        srcset=&quot;/static/lorinc_minima_maxima-512e60d4a8ec3c2c5a40a6497c84b19a-ae2e5.png 160w,
/static/lorinc_minima_maxima-512e60d4a8ec3c2c5a40a6497c84b19a-8227e.png 320w,
/static/lorinc_minima_maxima-512e60d4a8ec3c2c5a40a6497c84b19a-17dec.png 640w,
/static/lorinc_minima_maxima-512e60d4a8ec3c2c5a40a6497c84b19a-e6a98.png 713w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;lorinc&lt;/span&gt; measures the minima and maxima of a leaf plotted in polar coordinates&lt;/div&gt;
&lt;p&gt;From there, &lt;span class=&quot;name&quot;&gt;lorinc&lt;/span&gt; talks about mathematical morphology, before discovering the presence of noise around each leaf. He spends some time figuring out how to remove noise from the image and concludes with a lovely image showing a distance map superimposed on the leaf:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/lorinc_distance-172c7d7b73f77a96be2b40ee22ef0080-686c8.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 410px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 88.04878048780488%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAASCAYAAABb0P4QAAAACXBIWXMAAAsSAAALEgHS3X78AAACU0lEQVQ4y62TW28SURDHSYy3GB9MjNE3P4QfxFeNTxqfGmPSxgaVBihqgjUtDYQaTKSUBZZLBbosLLBQFlguy0VLG2zRNoXSfgvzdw9SWrCFeplkcs6cM/nlzPznKBSyadRzd3i+Nv6vzqwUxglPEQ6X71UrBxjlYmZ7+H32+48zA8ulNky6xJmA5wMB8cFpSZXyfmct5JswTERQLY8GXnU6og9PS2KD66BMBTjNedg1yf9Qsvyi5aUqYko7HGoOQbqGgHMN0XD973tIyvZM+ZHS2kDpBRn4pdeKk4DXbYvM41Gi0NMcnPrUiaA/fmGx0IJtIgTGu36kutRGOLgxHEhGo1TcA2XIdsqKR7fAhb7C/iaJhIoC6/8FyGV3Qb3mQel4lKQ9FOUJqJT2e8BzoZB0P8k3YJzmMTu2AuaZCxWDGQk1hegLL9YMJuywWnxSeeHWcfAr3ah/nIGot2BujIHxJQ/rgghhdbMDvEbZI4/6BLBI8E764JZf6l/6DI+5gJjOhrLRCFrDwj2bAf0qBvsTH1YTjdE95Ji6/M12+1QmIKeW6xOF8dRAW6Xe2VBRCvkWYpFNLFsrcMkgad6MuHYR7ncCfJYS2MAGJLnfBDYIvDE4NiTBMS8iPOkFpSQlpuFR+UFPMfAYRDifs7A+ZfF+JoW82BxeMoHZPuTgWijC9lbojAw5zwjbHXXJPp9rIhlvdBTOpnd+B/p8wl05aBHPpr+10sJW+zDOpBvt7toXD+6J8/FaS9G1K4oju0TacCy+JfuF7v5iNz60m7JfPnZ3+yevNxcNpjVPiAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;lerinc measures the distance from the center of a leaf&quot;
        title=&quot;&quot;
        src=&quot;/static/lorinc_distance-172c7d7b73f77a96be2b40ee22ef0080-686c8.png&quot;
        srcset=&quot;/static/lorinc_distance-172c7d7b73f77a96be2b40ee22ef0080-c7b35.png 160w,
/static/lorinc_distance-172c7d7b73f77a96be2b40ee22ef0080-aa606.png 320w,
/static/lorinc_distance-172c7d7b73f77a96be2b40ee22ef0080-686c8.png 410w&quot;
        sizes=&quot;(max-width: 410px) 100vw, 410px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;lerinc measures the distance from the center of a leaf&lt;/div&gt;
&lt;h2 id=&quot;lung-cancer&quot;&gt;&lt;a href=&quot;#lung-cancer&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href=&quot;https://www.kaggle.com/c/data-science-bowl-2017/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Lung Cancer&lt;/a&gt;&lt;/h2&gt;
&lt;aside class=&quot;center&quot; style=&quot;grid-row-start: 188;&quot;&gt;
The EDAs I chose for analysis were &lt;a href=&quot;https://www.kaggle.com/gzuidhof/full-preprocessing-tutorial&quot;&gt;Full Preprocessing Tutorial&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Guido Zuidhof&lt;/span&gt;, &lt;a href=&quot;https://www.kaggle.com/anokas/exploratory-data-analysis-4&quot;&gt;Exploratory Data Analysis&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Mikel Bober-Irizar&lt;/span&gt;, and &lt;a href=&quot;https://www.kaggle.com/apapiu/exploratory-analysis-visualization&quot;&gt;Exploratory Analysis Visualization&lt;/a&gt; by &lt;span class=&quot;name&quot;&gt;Alexandru Papiu&lt;/span&gt;.
&lt;/aside&gt;
&lt;figcaption class=&quot;left&quot; style=&quot;grid-row-start: 191;&quot;&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/dicom_info-ef06e4ea97527d4f49daa51d444b2714-2f853.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 119.30618401206637%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAYCAYAAAD6S912AAAACXBIWXMAAAsSAAALEgHS3X78AAACOklEQVQ4y42VaXarMAyFWUunDMyDMQRI2te+7n9HLp+MfYBA0x86DrZ8pasrK0EYVQaLYmWyvJXfadbIeg5L8/Qcih1PuTmdCxMnarG/tkCpwVSj1fpquv7TXLp/RtWDORyzhWOc1BIQH93cxF/2xuBppsezRhIJKtUbrW8ChJ3O+WZkl+FeZj5DKERxZZK0nqJoMSjPHQELo1JK8/wSmZfX2BvfmADmxcUU5UVo9sOnrHnR3kW2tFrTXj7EoN4PX0J/uP6X2gpgWXZGaI8HOJIF2eLw+hZ7QLK3gulxP9mnzGWcyApxklQL4JoyIkGb8tiyNN6yaYWtUIYmqiFKWXUCioLbgMrXmhWbJxUA1LTvQpea8M2lNRUA1620Q1n7CGRKxKLsZG/ueA6Lv7UNymEoTaY0OivAc0dqt9ejK8Bm6q9KagBd25tqkSVgh2MqYnHn7ZDIPZi5+koNOQTA9SKbro4o52gCeDxlIlY4vmUHALDrCvYCIjhA+pFDVV/vWmfeNu7dWpXbyaa3DJBrGbofUA5shtorzlv+bcr4GuYTuhMFhcuqH6mkq2mj/Pgiy1/bJk3tOyVTS1tLg7uC27axg4FgBN8FBIAnZ4fDl1DbcgQc34eUieYEgTJZAr52RCQ3NOYqM77u5iGtgOEA+FbxeSnYwwwt5d5TZozZ56gX0beG7jbgWGQEgOr19i1Dgt8ALGvYiCA095//AqBMZlvUHOVHEycgO2YiSt/ev4U64qzraCmXDyfOD+ks3cATVjfvAAAAAElFTkSuQmCC&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;DICOM meta info&quot; title=&quot;&quot; src=&quot;/static/dicom_info-ef06e4ea97527d4f49daa51d444b2714-17dec.png&quot; srcset=&quot;/static/dicom_info-ef06e4ea97527d4f49daa51d444b2714-ae2e5.png 160w,
/static/dicom_info-ef06e4ea97527d4f49daa51d444b2714-8227e.png 320w,
/static/dicom_info-ef06e4ea97527d4f49daa51d444b2714-17dec.png 640w,
/static/dicom_info-ef06e4ea97527d4f49daa51d444b2714-2f853.png 663w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;div class=&quot;caption&quot;&gt;anokas examines the metadata for a single image. You can see that patient date has been rendered anonymous (1/1/1900)&lt;/div&gt;
&lt;/figcaption&gt;
&lt;p&gt;The final image competition I looked at was the &lt;a href=&quot;https://www.kaggle.com/c/data-science-bowl-2017/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;2017 Data Science Bowl&lt;/a&gt;, which asked participants to examine a list of images and predict whether the patients had cancer or not. While this competition did feature structured data (meta information embedded in the images themselves), some of this data was anonymized, meaning that features that could have otherwise had predictive value (like the age of the patient) were removed. This meant that all the kernels focusing exclusively on image analysis.&lt;/p&gt;
&lt;p&gt;Of the three kernel authors, &lt;span class=&quot;name&quot;&gt;Guido&lt;/span&gt; is the only one to discuss his background working with medical images, and it shows in his domain-specific analysis of the dataset:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Dicom is the de-facto file standard in medical imaging. ... These files contain a lot of metadata (such as the pixel size, so how long one pixel is in every dimension in the real world). This pixel size/coarseness of the scan differs from scan to scan (e.g. the distance between slices may differ), which can hurt performance of CNN approaches. We can deal with this by isomorphic resampling&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The other two authors start their EDAs with more general explorations of the dataset and images themselves.&lt;/p&gt;
&lt;p&gt;apapie begins by examining the shape of the images, while anokas starts by looking at the number of scans per patient, total number of scans, and a histogram of DICOM files per patient, along with a quick sanity check to see if there&apos;s any relationship between row ID and whether a patient has cancer (none is found, implying that the dataset is well sorted).&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Alexandru&lt;/span&gt; takes a distribution of pixels and plots them:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/anapie_pixel_graph-ff7677c65d0a28c9781e5e47e1f2ce8c-6069d.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 92.66304347826087%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAATCAYAAACQjC21AAAACXBIWXMAAB7CAAAewgFu0HU+AAABy0lEQVQ4y71UTUsCQRgeOualP1D0R7qF5UcWQQhFGQadvSxeBC8dgjwoGWg/oG7VoaKCSr1IIoURqetKUq19bIgfSOrO7pszptgWmR/0wsP7zMyzz86zMyxCCA0Hg0F1Mpmcj0ajixzHmeLxuCmRSDQ6y7IUhMdiMTpf1zX1hXA4PIlI8fzzIcaSKMsyEEiSBHWuRPOaQoczmcw1NdzfZw/LZSwCfBX+9DDpyvXP3jAc3Nu7PSqVxEpdLIoiYIwpZFmCl5dCFXnKm9cIJ/rPMRYEofUOSXFchoLUX3bYtaHyG/4amVQo9FRFmvKeRA4E0hQ9i9yuYcvIfj8PPt/j/0Vu62J3FHl39+b4r5HJXKHwDjyfrWpx95GJRhCKcHX1XBu1c8oEpE5O7ilqBiKw7BscHDw0DL9d7FaRt7c52NriKM/linB2loKdnRTdbUeRGSYMFssF5Xd3WVhdjcDGRuL3yJWKVFH+qsgLCMzmEOh055DPF+Hy8hWMxlNYWYmQW9k4+WbDAb1+TuNyrWvsdvuM2+3W2mw2o8fjGXc41gxe76Z6bMw1gtDSaH+/QaNSTegQMhn6+mYnh4amDGbzsp5hmGmn06m1Wq3jH+cUIFRX2BhQAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;anapie plots a distribution of pixels&quot;
        title=&quot;&quot;
        src=&quot;/static/anapie_pixel_graph-ff7677c65d0a28c9781e5e47e1f2ce8c-17dec.png&quot;
        srcset=&quot;/static/anapie_pixel_graph-ff7677c65d0a28c9781e5e47e1f2ce8c-ae2e5.png 160w,
/static/anapie_pixel_graph-ff7677c65d0a28c9781e5e47e1f2ce8c-8227e.png 320w,
/static/anapie_pixel_graph-ff7677c65d0a28c9781e5e47e1f2ce8c-17dec.png 640w,
/static/anapie_pixel_graph-ff7677c65d0a28c9781e5e47e1f2ce8c-88536.png 960w,
/static/anapie_pixel_graph-ff7677c65d0a28c9781e5e47e1f2ce8c-6069d.png 1104w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Interesting - the distribution seems to be roughly bimodal with a bunch of pixels set at - 2000 - probably for missing values.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Guido&lt;/span&gt; sheds some more light in his EDA on why this is, namely being due to what HU units represent (air, tissue and bone):&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/gzuidhof_hu_units-0ab768b8f244346a6a47edaf6f63b156-7d406.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 389px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 70.17994858611824%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAYAAAAvxDzwAAAACXBIWXMAAAsSAAALEgHS3X78AAABFElEQVQ4y2NggAJ3d3fViooKpblz50qRi6dOnSoFM4/h/fv36x59//6fEvDly5c/MPMk3717t/7kx49UMxDsQmoaKExNF/IDMQs1XShDbS/LArE4Nb3MRotI4QO5sP/Ro//f/vxBUfTz79//5z59ItlAdpALpY4e/X/v2zcURTOePv1ffOcOeekQZODUJ09QFJUCDeM+ePD/D6BLSTFQ/Pjx474iM2ZUCa1dm9V/4UJG5+bNNUuuXs3Q27Ejg2HBgoLM48czFl+4kL1y377Ko/fuZVy+fTvn4MGDNc+ePcu4e/duzqFDh6pv3bqVwYAE2IFYAIgZgZgZygYBMSBWAGJFIJYGYg0glgOlXSAWhKqBqWcEACuRVEpzT0mjAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;gzuidhof examines HU units distribution&quot;
        title=&quot;&quot;
        src=&quot;/static/gzuidhof_hu_units-0ab768b8f244346a6a47edaf6f63b156-7d406.png&quot;
        srcset=&quot;/static/gzuidhof_hu_units-0ab768b8f244346a6a47edaf6f63b156-dabfc.png 160w,
/static/gzuidhof_hu_units-0ab768b8f244346a6a47edaf6f63b156-01378.png 320w,
/static/gzuidhof_hu_units-0ab768b8f244346a6a47edaf6f63b156-7d406.png 389w&quot;
        sizes=&quot;(max-width: 389px) 100vw, 389px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;h3 id=&quot;images-1&quot;&gt;&lt;a href=&quot;#images-1&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Images&lt;/h3&gt;
&lt;p&gt;Each author continues by examining the images themselves:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/anokas_images-3cefd05194624c611f054d89fb56bb14-377ca.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 596px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 78.85906040268455%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAAsSAAALEgHS3X78AAAEG0lEQVQ4yz2UT1AadxTHwX/IX0UMAkaECKwiyILyH/n/RxTYqMgKgm5r/G+1pUknqZl2Jp3WmQ45efHErafcMtMZD7nlxvSYY4573eteX98utjvzZvnOe/Nlv599v5VI8JrQGd+7lqJdO+Hrooxh3UmlA92hoRFBB2Qy+Z3BaO3K5SpRY91LJFLht1BeqVR6r52Y6o6MjApaInG6Qmw6vwvBSBHwzvjDeS6arEAkXoJCeZ/eoA65XHEP1koMZAsN2kMmea8vA77lLHi8Ccoxv8xTOyfg82dANPSupNjKzhEskatgc3iYXKnOef1JsBMkPN89ogvlFleuHkF+ownZYoNeTWzxxdIhZPNNIL1Jyu2J8fH0JmDKvuHQ0PB7vX6mq1SNiZG1uqm7zHqtu+gJ/R/ZOufuThnMoh4elt0rleNdhUIjRkYU98TCSlc/Ze5HRgZ/IbMHvD+gzI+P6z9EVqkHcjkl6AROfMB67EsTCoX6o+mp7cFoeib0w1gfBwYGH4QSDd1LcdY86wS9fhbQmEmkq1y1fg1oCpl8nbZY3dz8QgCcixEwGJ7RdsLL5zb2IJWvQTy9RZHeFB+OlTF+qh85Ft9iK88voFQ+BY3mCePxJrm18gEyicHCYoiu0m1uZ/cl0I1XsFE+oW0Okg9G12DW4oRQrEjhA/CZtTo+QKVvKJMpflGptB2t1tBBPn5k9s5BrHR0OlMH2yQieKdW6zpq9URnZEROIuvbWKrSsREeob+I63WL/DpK5VjnP4Z/j46qemjWQ1mSy5WfFtz+3ozFIegc1iec6vVLkkOGn2fMRA93r4eI4gaT9fNqcru36I70REOCCLBYYLG4wGi0MW5vlDs4+xni2S1YCWdpYj7ACTsXjpTBQfjpTfqcP/3+FqqNa1gOZCm69SN/eP4bNJmbfmRiPsi63QlwuVbBbHYyc/YlLl3cQX4BsC+QNDLmStQJ5Ar7QKBhKLbOX7z8E/Zf3ICbjFLJbE38g8bBa3iMPHCMO9XGyO0+k+HzJV+0bTBZBE0MDg6dq9TatmxUIWq1RneFPNvaCUMb2c5h/8o0PdcWZkRDjy/+z9buJZsrNtnpGVsNzb/Y7F7WaJpjcbcquifGL053UOixOF7Bl/h1etrBajSTgs4/nXF8TWZqrHclw4qGLy7fsSfXt9A6fAu15g/M5s4l19h/A/XWG/AHC/Rm/Yw7vv4dKtunQC4n6PXSIS/M1puvBe5UOl/nqeoZ0Huv+pELpRZ7cPpWhBwIrzH1/Z+446s/oPnNDeC5pQPRAvftxa+wXf8OJiYNdCC4wVc2TyGVrsOUwUpZrC5e+LiQvsfF1k2aav5QgcHzyiAfGy5sA08KE4ysMxqNzopr1UBmDO4gg+NWZNwaG59k8AwL2ixo5CnqfwEfrWyE6IQfQAAAAABJRU5ErkJggg==&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;anokas looks across a number of patient images&quot;
        title=&quot;&quot;
        src=&quot;/static/anokas_images-3cefd05194624c611f054d89fb56bb14-377ca.png&quot;
        srcset=&quot;/static/anokas_images-3cefd05194624c611f054d89fb56bb14-0722f.png 160w,
/static/anokas_images-3cefd05194624c611f054d89fb56bb14-e1248.png 320w,
/static/anokas_images-3cefd05194624c611f054d89fb56bb14-377ca.png 596w&quot;
        sizes=&quot;(max-width: 596px) 100vw, 596px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;anokas looks at a set of patient images side by side&lt;/div&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/anapie_x_sweep-cd88de0c918c0722b976ca8ee056c3c3-d77ff.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,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&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;anapie performs a sweep across the X angle&quot;
        title=&quot;&quot;
        src=&quot;/static/anapie_x_sweep-cd88de0c918c0722b976ca8ee056c3c3-17dec.png&quot;
        srcset=&quot;/static/anapie_x_sweep-cd88de0c918c0722b976ca8ee056c3c3-ae2e5.png 160w,
/static/anapie_x_sweep-cd88de0c918c0722b976ca8ee056c3c3-8227e.png 320w,
/static/anapie_x_sweep-cd88de0c918c0722b976ca8ee056c3c3-17dec.png 640w,
/static/anapie_x_sweep-cd88de0c918c0722b976ca8ee056c3c3-88536.png 960w,
/static/anapie_x_sweep-cd88de0c918c0722b976ca8ee056c3c3-91c1d.png 1280w,
/static/anapie_x_sweep-cd88de0c918c0722b976ca8ee056c3c3-d77ff.png 1590w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;&lt;span class=&quot;name&quot;&gt;Alexandru&lt;/span&gt; looks at images from the X angle&lt;/div&gt;
&lt;img alt=&quot;anokas sweeps across a set of patient images&quot; src=&quot;/static/anokas_sweep.gif&quot; /&gt;
&lt;div class=&quot;caption&quot;&gt;anokas builds a gif that moves through a set of patient images&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Alexandru&lt;/span&gt; spent some time exploring whether edge detection could enhance the images.&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/anapie_edges-288b0cf181cfb13f426d023205c79dc5-d77ff.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 100%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAB7CAAAewgFu0HU+AAAEpklEQVQ4yzVUSU8bSRTuCduEHS9gzGZMCGEAERBiX9rd7e6uXt22wWAcMGYRMPEwQoml0mgi5dRSjnOLFCm3ObSUWy65pX9A+pjrXPrsv1BTr0gOpX5d76tX9b73vccJ7fo/coflZ9ttf7NVLIMttdn+VptYgT2wKeZDpl1/CzbsbbRID75W2+fbtCuh3fgstADO+MTpPab/ImUSvdMhSkRqlIYtUojZROjK4nwkRyrjJsnFjKA0hryLWZ2AvziZwcd0H5YzhNyLeaX5+zIiN8tyyCmPLR8C2L0O2W2XG/lojh0Su7PYoQGPRixi9puB0Wd4+0M2OUw++Ipxm+HsuOZaA2YTcAdJPeQgTfqaBgRb4rbXMp3ZhkDXErezDnv0cINiqhutog24vQ6Z+fjHFEf/1x4Je5SeO8DR7y1XHNZ9uBlulHqlBrwAltSTxfACoANeaEcNr/rEIAcJm2T7srg8apHjMZPYMc0tJozm2bRB8nEj5E5nVP/sqUGu5jViJoTG6ZRB2MEpHlepffmbTs7nlaA2J3u1GZ3AAg4hALNHkFudUVnAckoLOb5bqJRn97A5LGJIBcBHMzxe/mVnE0UlfLKwizPdQm2vS3AOn/IY/BS3WUhlcHVxF2+0CrwS4+9vtrawHM3UOWvA8MtjFnEGckB2A8gt/qgy0AD/FMNSBioYNZQOsOGc0a+7uajZZAWKmCF3OK75F890xsfRzF7jxaTJpFKYyODKhEnOaVoHI1pwOI48oOaE+ktPeMYhW2nFLY3qLOV9qLIzrHy4XpaDowkUbHcI1eozNbhcUIKdDrF2nEbBn1tSkB9W/80llHcv16SAch7QatbOZpXgalEO5G61XkiqX18LQlBIKl841Ife7ic1z+g3PBrQBjs/qHs7vwqOHdU9+jpP6UHv5G50fzCqeZD6+iPJceK6V0jontSpltUe7SPgaKz3HDV8qCrwYY8IDdYBNP1i6qEbTtI0xTEtcOglwBukvJ9+8IGEIOXyhMY4rEyhkCunkH+3qjKpGENCA7i4mtOIGpEw7NVXEHATwMtvFjUmFT0uYvheL2gkn0DuEQ14+xwRymXIwRCAAgidMpONlRQwHABpQItBATZbpBqkCZKRqajBB5JyRgW8yon8drt4D1LbapPqrFNAGlBRfVBkwwFSsWngnzKh3LEXHlIcpGomRAwUAbY0rrpU0E3oe/bC0qjmn6QN1mL58UzjHCQEE4beDpfAhIGUQTZggx9EDR0FEjtMPXAIFLBO0QaUq7+tXbcyLburtNH/2BLcu+2Mu94i8gdjqvuXvuvaCbmuReTyK5F3LxclF9K8WRHdVwLv7rUhxR6S37yWeNdJypgzo+iz0Ws1nbjRpFK5A9VTxTf5LuEevqjLalox9FXrRx9tOqbyg0Zzu0O8Bzz4zZjyxoqi//Qeq0ljfeeOJ5F/9EP10CnAGwzW/TSPgQbg6WRaDY4nVe/nwK0t72C9M09gdp7Oyi4Es+g8pXMx5HJD6qf6WjaspFFIB8Xt9XM5hMkr9gp1IPnlajYsjChfckPK+9sVOTyfU0Na1frFghJeL8mhHlEw7ZTvgKOZfPsfYEU5kf7IFQQAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;anapie performs edge detection across a variety of DICOM images&quot;
        title=&quot;&quot;
        src=&quot;/static/anapie_edges-288b0cf181cfb13f426d023205c79dc5-17dec.png&quot;
        srcset=&quot;/static/anapie_edges-288b0cf181cfb13f426d023205c79dc5-ae2e5.png 160w,
/static/anapie_edges-288b0cf181cfb13f426d023205c79dc5-8227e.png 320w,
/static/anapie_edges-288b0cf181cfb13f426d023205c79dc5-17dec.png 640w,
/static/anapie_edges-288b0cf181cfb13f426d023205c79dc5-88536.png 960w,
/static/anapie_edges-288b0cf181cfb13f426d023205c79dc5-91c1d.png 1280w,
/static/anapie_edges-288b0cf181cfb13f426d023205c79dc5-d77ff.png 1590w&quot;
        sizes=&quot;(max-width: 640px) 100vw, 640px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;After increasing the threshold, &lt;span class=&quot;name&quot;&gt;Alexandru&lt;/span&gt; was able to render some visually striking images&lt;/div&gt;
&lt;p&gt;&lt;span class=&quot;name&quot;&gt;Alexandru&lt;/span&gt; concludes that:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Interesting results, however the issue here is that the filter will also detect the blood vessels in the lung. So some sort of 3-D surface detection that differentiates between spheres and tubes would be more suitable for this situation.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Meanwhile, &lt;span class=&quot;name&quot;&gt;Guido&lt;/span&gt; discusses resampling, focusing on the fundemental nature of the DICOM image:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A scan may have a pixel spacing of [2.5, 0.5, 0.5], which means that the distance between slices is 2.5 millimeters. For a different scan this may be [1.5, 0.725, 0.725], this can be problematic for automatic analysis (e.g. using ConvNets)! A common method of dealing with this is resampling the full dataset to a certain isotropic resolution. If we choose to resample everything to 1mm1mm1mm pixels we can use 3D convnets without worrying about learning zoom/slice thickness invariance.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Later in his EDA, &lt;span class=&quot;name&quot;&gt;Guido&lt;/span&gt; is able to do a 3D plot of the inner cavity by combining multiple DICOM images:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/gzuidhof_3d-230ba220859fc48e4fccd79488aac2f6-ee468.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 579px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 97.58203799654575%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAACjUlEQVQ4y62UWUtbQRTH/aL9FPpgRfBBVAR3NGrccEdEQdEHURtTa8yuadK01YQ02uw3+77+e87gXEiT2Dx04HBm5s79nXWmB8AHEu3/kp63ScdRrVZRq9XQaDTQzegIZEC5XEYqlSJJI51OI5/Pi733DLQF1ut1xGJpvL4qb8AUEomEEJ4nk0nVQKlUajLQBOTNSqUCrzeK8XEDpqZMcDp/4/LyCXq9BxbLLwFioISz5nU2m20GslfFYlF8YNnbc2B4+BZ9fTpsbT1gZOSLmGs0ZphMPng8QQGSEgqFRDpUIC8YlMvlhD44cGFg4AZDQ5+xv+/A3JwJvb2fsLRkxcqKlQzcYnT0DpGIIrwMh8MiOhXICwljrdFYBeTw0IWdHQcmJ+8JqMPMjEl4PD1twPKyRc0tC0fZETg/b8bp6Xdsbz/i5OQbVldtImSG7+46MDtrJLBdzWU8Hm8FSlgymcb6ug1XV884PnYR2I2FBbMAbmzYsbn5gImJeyrWT7UwwWBQFFUFcgNLoN8foxx+hcHgw/X1E87O3Fhbs6G//wY63TMWFy2UEgsUJamGy8CmKjNQhhwKJehHD2w2P7WKnyoahlZrJaAOR0dO8t5OIZvU9uFw2dOWtmFYJpMR2usNU3MnEAgoVMkE5esRg4N6GI0+KpSTvDSr3imKIpq8Ccjxyx7kQwxmq1JzMcbG7oShi4sfOD93q98DgYC4MW2B7WCsX16i1GtxCjMltN8fEfuxWEx42HJTeESjUQHk69UO+rdmWCQSEZei5XHgC84iD7NVTnYnOMPYOP/zz9dGPlMMlHAWCedIWMu8dfUeysEPBgt7w3lizxhUKBQ6vocfSYzdCN0mI3lpJGDHM38AEtm8upFukKAAAAAASUVORK5CYII=&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;3D Segment&quot;
        title=&quot;&quot;
        src=&quot;/static/gzuidhof_3d-230ba220859fc48e4fccd79488aac2f6-ee468.png&quot;
        srcset=&quot;/static/gzuidhof_3d-230ba220859fc48e4fccd79488aac2f6-d74a5.png 160w,
/static/gzuidhof_3d-230ba220859fc48e4fccd79488aac2f6-c2a87.png 320w,
/static/gzuidhof_3d-230ba220859fc48e4fccd79488aac2f6-ee468.png 579w&quot;
        sizes=&quot;(max-width: 579px) 100vw, 579px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;3D plot&lt;/div&gt;
&lt;p&gt;And another version, after removing the surrounding air to reduce memory:&lt;/p&gt;
&lt;p&gt;
  &lt;a
    class=&quot;gatsby-resp-image-link&quot;
    href=&quot;/static/gzuidhof_no_air_3d-e38d4de94f378e1a3a954af5fe0ae56e-ee468.png&quot;
    style=&quot;display: block&quot;
    target=&quot;_blank&quot;
    rel=&quot;noopener&quot;
  &gt;
  
  &lt;span
    class=&quot;gatsby-resp-image-wrapper&quot;
    style=&quot;position: relative; display: block; ; max-width: 579px; margin-left: auto; margin-right: auto;&quot;
  &gt;
    &lt;span
      class=&quot;gatsby-resp-image-background-image&quot;
      style=&quot;padding-bottom: 97.58203799654575%; position: relative; bottom: 0; left: 0; background-image: url(&apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAYAAACNiR0NAAAACXBIWXMAAAsSAAALEgHS3X78AAACPUlEQVQ4y62UW0sbURSF/aP9FeIlRsV4F0QfBB/qg6BPAUV9U5BmZhLbSBFpbIuS+FBCrpP7/b46a9szzBCnzUMPLPacw5nvrL3PZQrAB0sf/5em/nx4tn6/j8FggNFohEmaJ5CAbreLSqWCarUqajabMva3Bd4FDodDtNtt1Ot1AVKlUknE73K5bC/Q6XRcC7iAHOz1ejKRsEajAdMsIR7PoFgsCpAgAhWckX3OdwGdrghivL//hb29z1hfN3B+/gORyCsuLr4jkUjbQOU4k8lIOWwgO05YPJ7H9nYEm5thLC/rmJsLyTe1u3uHZDIvblUpstmsZGcD2VEwxqurnwIMBAyBzc9rWFnRsbpqYGsrjNvbZzt1JWbpCTw6esDOzh38fh3T0yHMzoYwMxPC0pIuLi8vn1y1ZI3HgM6U9/e/WLULizMCFxff0vb7NWxsGDg7i7lOQDqdlk21gTzATuDamiF6A34SZz6fZvVZSwPB4DdXDQl07TKBCkYFArpAFhY0K2rijE6Vw+PjBztlpkunY8eGoFqtJuBg8Ak3Ny+IxZK4vn7B4eFXccsd5+YcHERtd4VCQc6uC8j8lTtOIpirOuPp6aNsFHf55OTRHk+lUnJj3gV6wRiz2RI0LQFdf7UgpoybpikOx24KWz6ft6+XF9QZCcvlcnIpxh4HXnBKTeaqLLYXnDAuzn/++dqoZ4pABacUnJkwqrpN9B6qxgeDohvWic4IarVanu+hz1J0Elm3KWq5jFpAzzm/ATfmt7x59vcgAAAAAElFTkSuQmCC&apos;); background-size: cover; display: block;&quot;
    &gt;
      &lt;img
        class=&quot;gatsby-resp-image-image&quot;
        style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot;
        alt=&quot;3D Segment minus air&quot;
        title=&quot;&quot;
        src=&quot;/static/gzuidhof_no_air_3d-e38d4de94f378e1a3a954af5fe0ae56e-ee468.png&quot;
        srcset=&quot;/static/gzuidhof_no_air_3d-e38d4de94f378e1a3a954af5fe0ae56e-d74a5.png 160w,
/static/gzuidhof_no_air_3d-e38d4de94f378e1a3a954af5fe0ae56e-c2a87.png 320w,
/static/gzuidhof_no_air_3d-e38d4de94f378e1a3a954af5fe0ae56e-ee468.png 579w&quot;
        sizes=&quot;(max-width: 579px) 100vw, 579px&quot;
      /&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    &lt;/p&gt;
&lt;div class=&quot;caption&quot;&gt;3D plot without air&lt;/div&gt;
&lt;h3 id=&quot;takeaways-4&quot;&gt;&lt;a href=&quot;#takeaways-4&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Takeaways&lt;/h3&gt;
&lt;p&gt;This competition featured the most differences between kernels of any I saw. &lt;span class=&quot;name&quot;&gt;Guido&lt;/span&gt;, given his familiarity with medical image formats, was able to leverage that background to draw significantly more nuanced conclusions. That said, the other two authors&apos; lack of medical familiarity did not prevent them from drawing equally fascinating conclusions.&lt;/p&gt;
&lt;p&gt;&lt;a name=&quot;conclusions&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h1 id=&quot;conclusions&quot;&gt;&lt;a href=&quot;#conclusions&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Conclusions&lt;/h1&gt;
&lt;p&gt;It turns out that there are some strong patterns that guide approachs to different types of data.&lt;/p&gt;
&lt;p&gt;For &lt;strong&gt;Structured Data&lt;/strong&gt; competitions, data analyses tend to look for correlations between the target variable and other columns, and spend significant amounts of time visualizing correlations or ranking correlations. For smaller datasets there&apos;s only so many columns you can examine; analyses in the &lt;a href=&quot;https://www.kaggle.com/c/titanic&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Titanic competition&lt;/a&gt; tended to be identical both in which columns to examine and in what order. However, different coders used very different visualization methods, and it seems that there&apos;s more creativity in choosing which features to engineer.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Natural Language&lt;/strong&gt; datasets share similarities across EDAs in how the authors process and manipulate the text, but there&apos;s more variability in the features the authors choose to engineer, as well as differing conclusions drawn from those analyses.&lt;/p&gt;
&lt;p&gt;Finally, &lt;strong&gt;Image&lt;/strong&gt; competitions showed the most diversity in terms of analysis and feature engineering. The image competitions I saw were mostly aimed at advanced audiences, and were in fairly domain-specific areas, which may have resulted in the more advanced diversity.&lt;/p&gt;
&lt;p&gt;It makes sense that as datasets become more specialized or esoteric, the amount of introductory analysis and explanation decreases, while the amount of deep or specialized analysis increases, and indeed this is what I saw. While there are clear trends across different types of data, domain knowledge plays an important role. In the lung cancer and leaf competitions, bringing domain knowledge to bear resulted in deeper analyses. (Anecdotally, I&apos;ve seen this in my own studies; Jeremy Howard, in his &lt;a href=&quot;https://fast.ai&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;fast.ai&lt;/a&gt; course, discusses the Rossman dataset, and how the most successful models integrated third party datasets like temperature, store locations, and more, to make more accurate sales predictions.)&lt;/p&gt;
&lt;p&gt;There was no consistent process for when authors tackled feature engineering, with some choosing to dive right in as they were beginning their analyses, and others keeping it a discrete step after their initial analyses were complete.&lt;/p&gt;
&lt;p&gt;Finally, every notebook I saw was written with a clear audience in mind (beginner or advanced) and this affected the analysis and the writing. More popular competitions, or ones aimed at a more general audience, had EDAs that were exhaustive in their analyses. In these EDAs, I also saw a trend of interweaving supplementary prose or the use of narrative devices alongside the analysis, as tools to help beginners better understand the techniques. By comparison, notebooks aimed at domain experts tended to do away with superfluous framings, and many also skipped over rudimentary data analyses, instead diving straight into domain-specific techniques.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;em&gt;Special thanks to &lt;a href=&quot;http://michellelew.com/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Michelle Lew&lt;/a&gt;, &lt;a href=&quot;http://ari.zilnik.com/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Ari Zilnik&lt;/a&gt;, &lt;a href=&quot;http://seanmatthe.ws/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Sean Matthews&lt;/a&gt;, and &lt;a href=&quot;http://visiongrowth.org&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Bethany Basile&lt;/a&gt; for reviewing drafts of this article.&lt;/em&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Standing on the shoulders of giants]]></title><description><![CDATA[Before I started learning about AI, I thought that training a neural network meant training from scratch. Want to train a network to…]]></description><link>https://thekevinscott.com/shoulders-of-giants/</link><guid isPermaLink="false">https://thekevinscott.com/shoulders-of-giants/</guid><pubDate>Tue, 23 Jan 2018 17:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Before I started learning about AI, I thought that training a neural network meant training from scratch. Want to train a network to recognize dogs? Feed it 10,000 dogs and watch it go. Want to recognize images of malignant tumors in a CT scan? Collect a bunch of medical images and train away. I didn&apos;t realize you could take the models trained on one set of images and apply them to another, entirely unrelated set. Turns out this is exactly what you can do!&lt;/p&gt;
&lt;p&gt;I&apos;ve been working through the &lt;a href=&quot;http://fast.ai&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;fast.ai&lt;/a&gt; courses, and one of the very first assignments begins by leveraging a pre-trained model (specifically &lt;a href=&quot;https://www.kaggle.com/keras/vgg16&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;VGG16&lt;/a&gt;, trained to identify 1000 categories of images based on the &lt;a href=&quot;http://www.image-net.org&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;corpus of data from ImageNet&lt;/a&gt;). You consume the outputs of the VGG16 model, and use that to inform your custom model to predict whether something is a cat or a dog. So you&apos;re basically taking the predictions from an existing model, and layering another layer of predictions on top of that.&lt;/p&gt;
&lt;p&gt;It makes perfect sense that you&apos;d build models like this; why train from scratch if someone has already done the training work beforehand? At its lower levels, &lt;a href=&quot;https://youtu.be/6kwQEBMandw?t=9m25s&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;VGG16 is already capable of recognizing patterns like lines, circles, gradients&lt;/a&gt;, as well as hundreds of other features. These patterns appear in all images, and so retraining from scratch is redundant.&lt;/p&gt;
&lt;p&gt;I could see adapting this for speech recognition. Imagine you&apos;re training a model to teach native English speakers to speak Spanish. Instead of training your model from scratch, you could leverage a pre-trained model that already recognizes human voices. Maybe you also leverage a model that understands English and Spanish. Your final model might be a thin layer on top of both of these pre-existing models, that specifically learns how to interpret English accents mangling Spanish words.&lt;/p&gt;
&lt;p&gt;I wonder how this will affect design.&lt;/p&gt;
&lt;p&gt;There&apos;s been some work around &lt;a href=&quot;https://blog.floydhub.com/turning-design-mockups-into-code-with-deep-learning/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;turning design mockups into code with deep learning&lt;/a&gt;. Imagine starting with a hand-drawn sketch as your base. You click around the sketch, nudging, encouraging and discouraging the AI: &quot;No no, that button should open a new page&quot;, or &quot;that link should create a new widget&quot;. You could use pre-trained models to help you where appropriate. Building a &lt;a href=&quot;https://en.wikipedia.org/wiki/Create,_read,_update_and_delete&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;CRUD app&lt;/a&gt;? Grab a pre-built model off the shelf that knows how to create, delete, and update. How about Uber for dogs? Grab a pre-built Uber model, and train a new layer on top to recognize dogs instead of humans.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;This is the cool thing about neural networks: you don’t have to tell them what to find. They decide what they want to find in order to solve your problem. — &lt;a href=&quot;https://www.youtube.com/watch?v=6kwQEBMandw&amp;#x26;feature=youtu.be&amp;#x26;t=12m22s&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Jeremy Howard&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This layered approach to making neural nets smarter - by building on the shoulders of other, pre-trained nets - it blows my mind. It feels like programming from the future. In a future language we could use increasingly abstract language to describe the parameters of what the computer should achieve, and then let the computer figure it out, similar to how nowadays we write instructions that are then interpreted into 0&apos;s and 1&apos;s.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Noob's Guide to building a Deep Learning / Cryptocurrency PC (#4): AI]]></title><description><![CDATA[Among the buzzwords of this past year, two tower above the rest: deep learning and cryptocurrencies. It seems that everyone I know (in tech…]]></description><link>https://thekevinscott.com/deep-learning-cryptocurrency-pc-4-ai/</link><guid isPermaLink="false">https://thekevinscott.com/deep-learning-cryptocurrency-pc-4-ai/</guid><pubDate>Mon, 01 Jan 2018 09:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Among the buzzwords of this past year, two tower above the rest: deep learning and cryptocurrencies. It seems that everyone I know (in tech) wants to learn these things. And guess what — so do I! So much so that I&apos;m building my own computer in order to facilitate that learning.&lt;/p&gt;
&lt;p&gt;What follows are my notes-to-self as I build a computer to learn about deep learning and cryptocurrency mining. In the previous installments we discussed assembling the hardware, installing the OS, and setting up a mining operation. In this installment I&apos;ll talk about installing machine learning software and making sure it&apos;s working.&lt;/p&gt;
&lt;iframe style=&quot;height:400px;width:100%;max-width:800px;margin:30px auto;&quot; src=&quot;https://upscri.be/96fcab/?as_embed&quot;&gt;&lt;/iframe&gt;
&lt;hr /&gt;
&lt;p&gt;To recap, in case you&apos;re just getting started with this series: my goal in purchasing and building my own PC was to have hardware on hand to run machine learning algorithms on, and bring myself up to speed on the exciting advances happening in AI. With the mining operation up and running, it&apos;s time for some AI!&lt;/p&gt;
&lt;p&gt;The two packages we&apos;re going to install are &lt;a href=&quot;https://www.tensorflow.org/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;TensorFlow&lt;/a&gt; and &lt;a href=&quot;https://github.com/cdw/pytorch&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;PyTorch&lt;/a&gt;. I&apos;ve heard lots of buzz about these two frameworks and there&apos;s tons of good resources for each. This article will walk through basic installation details on Ubuntu for both, plus instructions on setting up Jupyter notebooks. If you want to just pick one, &lt;a href=&quot;https://awni.github.io/pytorch-tensorflow/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Awni Hannun provides a great overview of the differences&lt;/a&gt;.&lt;/p&gt;
&lt;h1 id=&quot;docker&quot;&gt;&lt;a href=&quot;#docker&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Docker&lt;/h1&gt;
&lt;p&gt;&lt;strong&gt;For both TensorFlow and PyTorch, we&apos;re going to install using Docker&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;Docker provides a virtualized environment that lets you isolate packages and libraries (or in our case, download pre-configured environments).&lt;/p&gt;
&lt;h2 id=&quot;why-docker&quot;&gt;&lt;a href=&quot;#why-docker&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Why Docker?&lt;/h2&gt;
&lt;p&gt;The TensorFlow &lt;a href=&quot;https://www.tensorflow.org/install/install_linux&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;docs offer four options for installing TensorFlow&lt;/a&gt;. My first instinct was to install directly using native &lt;code&gt;pip&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;I installed CUDA 9, the latest version, which as of this writing Tensorflow doesn&apos;t support, and got lost in dependency hell trying to downgrade / uninstall / reinstall CUDA. A friend recommended I leave all that nonsense alone and just install Docker.&lt;/p&gt;
&lt;p&gt;So that&apos;s my recommendation: &lt;strong&gt;install docker and avoid dependency hell&lt;/strong&gt;. &lt;/p&gt;
&lt;h2 id=&quot;step-by-step-docker-installation-instructions&quot;&gt;&lt;a href=&quot;#step-by-step-docker-installation-instructions&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Step-by-step Docker installation instructions&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;Install &lt;code&gt;docker&lt;/code&gt;. &lt;a href=&quot;https://www.digitalocean.com/community/tutorials/how-to-install-and-use-docker-on-ubuntu-16-04&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Instructions for installing Docker on Ubuntu are here&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;Make sure to follow the optional Step 2 instructions on adding yourself to the correct group so as to avoid needing &lt;code&gt;sudo&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Install &lt;code&gt;nvidia-docker&lt;/code&gt;. By default, &lt;code&gt;docker&lt;/code&gt; doesn&apos;t support leveraging the NVIDIA GPUs effectively, so to take advantage of that hardware &lt;a href=&quot;https://github.com/NVIDIA/nvidia-docker#xenial-x86_64&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;you&apos;ll need to install &lt;code&gt;nvidia-docker&lt;/code&gt;&lt;/a&gt;.&lt;/li&gt;
&lt;/ol&gt;
&lt;h1 id=&quot;tensorflow&quot;&gt;&lt;a href=&quot;#tensorflow&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;TensorFlow&lt;/h1&gt;
&lt;p&gt;&lt;a href=&quot;https://www.tensorflow.org/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;TensorFlow&lt;/a&gt; is software for machine learning released by the &lt;a href=&quot;https://research.google.com/teams/brain/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Google Brain&lt;/a&gt; team in 2015. It provides a set of tools for specifying training instructions, and then translating those instructions into commands that can be run quickly and take advantage of GPUs.&lt;/p&gt;
&lt;p&gt;It&apos;s a powerful piece of software and since it&apos;s release it&apos;s picked up a ton of developer mindshare.&lt;/p&gt;
&lt;h2 id=&quot;installation&quot;&gt;&lt;a href=&quot;#installation&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;Assuming you followed the Docker instructions above, you should have &lt;code&gt;nvidia-docker&lt;/code&gt; available and working. The next step is to &lt;a href=&quot;https://www.tensorflow.org/install/install_linux#gpu_support&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;install the correct Docker image&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We want the latest GPU version, so run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nvidia-docker run -it gcr.io/tensorflow/tensorflow:latest-gpu bash
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This command will find the Docker file (remotely or locally), spin it up and put you at a bash prompt. From there, you can &lt;a href=&quot;https://www.tensorflow.org/install/install_linux#ValidateYourInstallation&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;validate your installation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;validating-your-installation&quot;&gt;&lt;a href=&quot;#validating-your-installation&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Validating your installation&lt;/h2&gt;
&lt;p&gt;Start &lt;code&gt;python&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Paste this program, &lt;a href=&quot;https://www.tensorflow.org/install/install_linux#ValidateYourInstallation&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;provided by the TensorFlow docs&lt;/a&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# Python
import tensorflow as tf
hello = tf.constant(&apos;Hello, TensorFlow!&apos;)
sess = tf.Session()
print(sess.run(hello))
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If you see &quot;Hello, TensorFlow!&quot; you&apos;ll know it&apos;s installed correctly.&lt;/p&gt;
&lt;h2 id=&quot;jupyter&quot;&gt;&lt;a href=&quot;#jupyter&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Jupyter&lt;/h2&gt;
&lt;p&gt;So we&apos;ve got TensorFlow installed and working, but inputting python commands one line at a time is a terrible way to program. A much better approach to get started is to use a Jupyter notebook.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://jupyter.org/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;A Jupyter notebook&lt;/a&gt; is a web interface for documents containing code the evaluations of that code, displayed side by side on the page.&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/jupyter-sample-4f3cb5bf6172304d6ffa8f8ce4009593-2957c.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 59.6401028277635%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAMCAYAAABiDJ37AAAACXBIWXMAAAsSAAALEgHS3X78AAABO0lEQVQoz51Ti46CMBDk/38REwRjFKh9UV4KzjFr2uQuHjE2mWyhdHZndskGb6GUgvcebduiaRrZG2Nwv9+xLMsuHo8H5nkWhBCQ8XLXddBawzknYALGYRgEvPQfmHQcR4kkzbh5Pp+oqgplWeJ8PuN0OskzwaysZF3XVBX3vPMX5BJCrlgpZbM6SrbWynvGvu+lWiaYpgnvViKc5gXKKdxuN7S2hTJKLCAZ5XwKJkwVFnWBoihQVuXLw7D5GTx8578jpMTj8Yg8z3E4HHBtrzDOwHn3HaG2GtZpjJuP9Iw+7XX3HVKXueL8xebQfGZlJNgUvo/n8VueMfL8V1Ma08AaJw3xm3f0kBK6sJH3IQ3vHqgqEV70BXVdCyEJSNSP/UdEEVSUJHNcus07grMoc2he88fM8W/YA7/7AXovoWjiF5baAAAAAElFTkSuQmCC&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;jupyter sample&quot; title=&quot;&quot; src=&quot;/static/jupyter-sample-4f3cb5bf6172304d6ffa8f8ce4009593-17dec.png&quot; srcset=&quot;/static/jupyter-sample-4f3cb5bf6172304d6ffa8f8ce4009593-ae2e5.png 160w,
/static/jupyter-sample-4f3cb5bf6172304d6ffa8f8ce4009593-8227e.png 320w,
/static/jupyter-sample-4f3cb5bf6172304d6ffa8f8ce4009593-17dec.png 640w,
/static/jupyter-sample-4f3cb5bf6172304d6ffa8f8ce4009593-88536.png 960w,
/static/jupyter-sample-4f3cb5bf6172304d6ffa8f8ce4009593-2957c.png 1167w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;The TensorFlow Docker image &lt;a href=&quot;https://www.tensorflow.org/install/install_linux#gpu_support&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;supports Jupyter notebooks out of the box&lt;/a&gt;. You&apos;ll use a similar command to spin up the Docker image with a few tweaks (If the previous Docker image is still running, shut it down with &lt;code&gt;ctrl-c&lt;/code&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nvidia-docker run -it -p 8888:8888 gcr.io/tensorflow/tensorflow:latest-gpu
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;What this command does is tell docker to expose port &lt;code&gt;8888&lt;/code&gt; (in Docker) on port &lt;code&gt;8888&lt;/code&gt; (of your local machine). (Port &lt;code&gt;8888&lt;/code&gt; is the Jupyter notebook&apos;s default port, if you were wondering.)&lt;/p&gt;
&lt;p&gt;To make sure that things are working as expected, open up another terminal on your box and run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl http://localhost:8888
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If your machine is like mine, you won&apos;t see any output from this &lt;code&gt;curl&lt;/code&gt; command, but you &lt;em&gt;should&lt;/em&gt; see a request come in on the terminal running Docker, something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;[I 02:05:57.912 NotebookApp] 302 GET / (xxx.xx.x.x) 0.22ms
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You can access the Docker URL directly on your box. I use a laptop and prefer to access the PC remotely, so to do that, you&apos;ll need to be on the same wifi network as your Machine Learning PC and get it&apos;s IP.&lt;/p&gt;
&lt;p&gt;On your Machine Learning PC, type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ifconfig
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Look for an IP address that starts with &lt;code&gt;192.168.x.x&lt;/code&gt;. On your laptop, you&apos;ll take the URL provided by Docker and replace &lt;code&gt;localhost&lt;/code&gt; with this IP. So, if the Machine Learning box&apos;s IP is &lt;code&gt;192.168.1.1&lt;/code&gt;, you would type in your browser something like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;http://192.168.1.1:8888/?token=7f6b36f9d6b15272c76003b8c1cdfcdf306dc52ff310
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;At this URL, you should see the Jupyter notebook:&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/jupyter-overview-864633103aa5f3d908269ca2a788469a-c7069.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 29.783549783549784%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAGCAYAAADDl76dAAAACXBIWXMAAAsSAAALEgHS3X78AAAAgElEQVQY06XQSw7DIAwEUN//piBSjM0nfKchUg+QdPE2XoxmTGcSeO+x1vpbzhnEzOCgYFF8WDDGeBVWSrlRjBGHDxCRm6pi357YCzfnHKi1BnMEOCngVF/PTSnBWguqtcJ6RT4bYmnX5Ik5n9tNjTGg3jtirujX794E/exi+11fltbWpRztUscAAAAASUVORK5CYII=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;jupyter overview&quot; title=&quot;&quot; src=&quot;/static/jupyter-overview-864633103aa5f3d908269ca2a788469a-17dec.png&quot; srcset=&quot;/static/jupyter-overview-864633103aa5f3d908269ca2a788469a-ae2e5.png 160w,
/static/jupyter-overview-864633103aa5f3d908269ca2a788469a-8227e.png 320w,
/static/jupyter-overview-864633103aa5f3d908269ca2a788469a-17dec.png 640w,
/static/jupyter-overview-864633103aa5f3d908269ca2a788469a-88536.png 960w,
/static/jupyter-overview-864633103aa5f3d908269ca2a788469a-c7069.png 1155w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;Having a Jupyter notebook handy will make it much easier to run through the TensorFlow tutorials.&lt;/p&gt;
&lt;h1 id=&quot;pytorch&quot;&gt;&lt;a href=&quot;#pytorch&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pytorch&lt;/h1&gt;
&lt;p&gt;The other machine learning tool we&apos;re going to install is PyTorch.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/cdw/pytorch&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;PyTorch&lt;/a&gt; was released in 2016 by &lt;a href=&quot;https://twitter.com/fbOpenSource?ref_src=twsrc%5Etfw&amp;#x26;ref_url=http%3A%2F%2Fpytorch.org%2F&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Facebook&apos;s team&lt;/a&gt;. It&apos;s still fairly new and changing quickly, but it&apos;s already picked up a lot of steam in the community.&lt;/p&gt;
&lt;h2 id=&quot;installation-1&quot;&gt;&lt;a href=&quot;#installation-1&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installation&lt;/h2&gt;
&lt;p&gt;Let&apos;s install the appropriate pytorch docker image. Run:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nvidia-docker run --rm -ti --ipc=host -p 8888:8888 pytorch/pytorch:latest
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This puts you right at a bash prompt.&lt;/p&gt;
&lt;p&gt;I like learning via example, and &lt;a href=&quot;http://pytorch.org/tutorials/beginner/pytorch_with_examples.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;luckily the Pytorch docs provide plenty of examples to learn from&lt;/a&gt;. You can run through the tutorials by starting &lt;code&gt;python&lt;/code&gt; and copy pasting code, but a Jupyter notebook is so much better. So let&apos;s get that working.&lt;/p&gt;
&lt;h2 id=&quot;jupyter-1&quot;&gt;&lt;a href=&quot;#jupyter-1&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Jupyter&lt;/h2&gt;
&lt;p&gt;Jupyter doesn&apos;t come standard on the &lt;code&gt;pytorch&lt;/code&gt; docker image, &lt;a href=&quot;http://jupyter.org/install.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;but it&apos;s easy to install&lt;/a&gt;. In your docker container (that you started above), type:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;python3 -m pip install --upgrade pip
python3 -m pip install jupyter
jupyter notebook
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;When I ran &lt;code&gt;jupyter notebook&lt;/code&gt; for the first time, I got the following error:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;OSError: [Errno 99] Cannot assign requested address
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To fix this, I had to provide an explicit IP and allow root (&lt;a href=&quot;https://github.com/ipython/ipython/issues/6193#issuecomment-350613300&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;hat tip to this comment&lt;/a&gt;):&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jupyter notebook --allow-root --ip=0.0.0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;validating-the-jupyter-notebook&quot;&gt;&lt;a href=&quot;#validating-the-jupyter-notebook&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Validating the Jupyter notebook&lt;/h3&gt;
&lt;p&gt;From another terminal, run curl:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;curl http://localhost:8888
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And make sure you see logs appear in Docker. If that works, try accessing in the browser at &lt;code&gt;http://192.168.x.xx:8888&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&quot;saving-the-jupyter-notebook&quot;&gt;&lt;a href=&quot;#saving-the-jupyter-notebook&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Saving the Jupyter notebook&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;IMPORTANT:&lt;/strong&gt; If you exit docker now, you&apos;ll lose the installation of Jupyter you just performed. You need to commit those changes as (&lt;a href=&quot;https://www.techrepublic.com/article/how-to-commit-changes-to-a-docker-image/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;outlined in this article&lt;/a&gt;) if you want to avoid installing every time you spin up the container.&lt;/p&gt;
&lt;p&gt;First, in another terminal, get the name of the container:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker ps -l
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This should give you the most recently created container, which should be PyTorch. Then, commit with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;docker commit &amp;#x3C;CONTAINER_NAME&gt; pytorch
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Refer to our newly named container with:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;nvidia-docker run --rm -ti --ipc=host -p 8888:8888 pytorch
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And start up your notebook:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jupyter notebook --allow-root --ip=0.0.0.0
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;If that works, great! Try running through one or two of the tutorials to make sure everything&apos;s working.&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/pytorch-output-08924445659039f725b35f65f1e1cfe6-e3b9c.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 111.63194444444444%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAWCAYAAADAQbwGAAAACXBIWXMAAAsSAAALEgHS3X78AAABpUlEQVQ4y62VCXOCMBCF+f9/sOMB5Ui4IdwIoq+7sVo7tVSomXmDKPl4mz002lIhTVPkea6vSimUZXlTVVWYpmlWwzAgyQL9vFEUhd50hTE4jmP9Y9d1aJpGb5gTP9f3vZbRdT1t6lHVNTKCFwRnSNu2i8Vggy3z8lKJIIoQZQlKgrNyclkT/N7BnA6HwxcwoDAlAUUYws9iiDRElGfacUXQxcCQQLbjwHFdSN9HrnIdxjOgh0BBkJ1lYWeasD0PCSVpCewnMJQwxTvc2IOqSn2GnKjVQC4fkxxaJA67pLNrn0zGQyADZBRCBoHOtlKFrsvVQEUd40gBEfhIqLiDKKbvLqFzphWJPzczifoG5E7Z7/c6ZL5uNhtIKf/hkMLzhEBIzuIkRr0wITfg9Ybr0LJtvJEzzxXYbrf6JUvEM8Fg6vl8hiB3JtUgFzPfr9HxeLwAeblUKnx+/Ja16xswoHLxqEPY4UuA7JCzy2fxEuD1DF8CPJ1OiKg7fBoQz4z83zSOIwymDuMEmfl6JnI3LB1bDws7ufujYt1GOw0Intjtp/4CfgBjnqd781YQWAAAAABJRU5ErkJggg==&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;pytorch output&quot; title=&quot;&quot; src=&quot;/static/pytorch-output-08924445659039f725b35f65f1e1cfe6-17dec.png&quot; srcset=&quot;/static/pytorch-output-08924445659039f725b35f65f1e1cfe6-ae2e5.png 160w,
/static/pytorch-output-08924445659039f725b35f65f1e1cfe6-8227e.png 320w,
/static/pytorch-output-08924445659039f725b35f65f1e1cfe6-17dec.png 640w,
/static/pytorch-output-08924445659039f725b35f65f1e1cfe6-88536.png 960w,
/static/pytorch-output-08924445659039f725b35f65f1e1cfe6-e3b9c.png 1152w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;h1 id=&quot;next-steps&quot;&gt;&lt;a href=&quot;#next-steps&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Next steps&lt;/h1&gt;
&lt;p&gt;At this point, you should have both &lt;a href=&quot;https://github.com/cdw/pytorch&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;PyTorch&lt;/a&gt; and &lt;a href=&quot;https://www.tensorflow.org/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;TensorFlow&lt;/a&gt; at your disposal.&lt;/p&gt;
&lt;p&gt;If you&apos;ve made it this far in the series, congratulations! You built a computer, installed an operating system, began mining cryptocurrencies, and set yourself up to begin training computers to do your bidding. You deserve a pat on the back!&lt;/p&gt;
&lt;p&gt;Where to go from here, you may ask? First, I&apos;d encourage you to subscribe:&lt;/p&gt;
&lt;iframe style=&quot;height:400px;width:100%;max-width:800px;margin:30px auto;&quot; src=&quot;https://upscri.be/96fcab/?as_embed&quot;&gt;&lt;/iframe&gt;
&lt;p&gt;I&apos;m going to continue blogging my adventures learning this stuff, and I&apos;d love to share it with you.&lt;/p&gt;
&lt;p&gt;If you want an immediate next step, I&apos;d recommend &lt;a href=&quot;https://www.coursera.org/learn/machine-learning&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Andrew Ng&apos;s course&lt;/a&gt;. It&apos;s a deep and thorough introduction to the field.&lt;/p&gt;
&lt;p&gt;Finally, I&apos;ve been collecting various machine learning links and resources to work through once I have a base of knowledge. Some of these may come in handy for you! (I haven&apos;t gone through all of these so I can&apos;t vouch for them - feel free to recommend others in the comments).&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/7nrzhn/d%5C_results%5C_from%5C_best%5C_of%5C_machine%5C_learning%5C_2017/?st=JBZ1N05J&amp;#x26;sh=aa234160&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/MachineLearning/comments/7nrzhn/d_results_from_best_of_machine_learning_2017/?st=JBZ1N05J&amp;#x26;sh=aa234160&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.wildml.com/2017/12/ai-and-deep-learning-in-2017-a-year-in-review/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;http://www.wildml.com/2017/12/ai-and-deep-learning-in-2017-a-year-in-review/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://explosion.ai/blog/prodigy-annotation-tool-active-learning&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://explosion.ai/blog/prodigy-annotation-tool-active-learning&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.kaggle.com/2017/09/11/how-can-i-find-a-dataset-on-kaggle/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;http://blog.kaggle.com/2017/09/11/how-can-i-find-a-dataset-on-kaggle/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/learnmachinelearning/comments/6zvszj/another_keras_tutorial_for_neural_network/?st=J7JRX00A&amp;#x26;sh=90a37148&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/learnmachinelearning/comments/6zvszj/another&lt;em&gt;keras&lt;/em&gt;tutorial&lt;em&gt;for&lt;/em&gt;neural_network/?st=J7JRX00A&amp;#x26;sh=90a37148&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/MachineLearning/comments/70c5zd/n_google_launches_tensorboard_api_to_enhance/?st=J7MJ4JWJ&amp;#x26;sh=2ece7122&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/MachineLearning/comments/70c5zd/n&lt;em&gt;google&lt;/em&gt;launches&lt;em&gt;tensorboard&lt;/em&gt;api&lt;em&gt;to&lt;/em&gt;enhance/?st=J7MJ4JWJ&amp;#x26;sh=2ece7122&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://medium.com/@ageitgey/machine-learning-is-fun-80ea3ec3c471&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.wired.com/story/when-websites-design-themselves/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.wired.com/story/when-websites-design-themselves/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://chatbotsmagazine.com/contextual-chat-bots-with-tensorflow-4391749d0077&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/machine-learning-for-humans/supervised-learning-740383a2feab&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://medium.com/machine-learning-for-humans/supervised-learning-740383a2feab&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/intuitionmachine/the-brute-force-method-of-deep-learning-innovation-58b497323ae5&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://medium.com/intuitionmachine/the-brute-force-method-of-deep-learning-innovation-58b497323ae5&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://hackernoon.com/how-i-started-with-learning-ai-in-the-last-2-months-251d19b23597?source=userActivityShare-f31f03e60056-1506529741&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://hackernoon.com/how-i-started-with-learning-ai-in-the-last-2-months-251d19b23597?source=userActivityShare-f31f03e60056-1506529741&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/rhdeck/bostonai/blob/master/README.md&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://github.com/rhdeck/bostonai/blob/master/README.md&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://nicodjimenez.github.io/2017/10/08/tensorflow.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;http://nicodjimenez.github.io/2017/10/08/tensorflow.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/hackernews/comments/7dlltw/a_cookbook_for_machine_learning_vol_1/?st=JA5IEFE8&amp;#x26;sh=b5513326&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/hackernews/comments/7dlltw/a&lt;em&gt;cookbook&lt;/em&gt;for&lt;em&gt;machine&lt;/em&gt;learning&lt;em&gt;vol&lt;/em&gt;1/?st=JA5IEFE8&amp;#x26;sh=b5513326&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/learnmachinelearning/comments/7dcog4/neural_networks_for_beginners_popular_types_and/?st=JA2YU96R&amp;#x26;sh=fc6787ce&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/learnmachinelearning/comments/7dcog4/neural&lt;em&gt;networks&lt;/em&gt;for&lt;em&gt;beginners&lt;/em&gt;popular&lt;em&gt;types&lt;/em&gt;and/?st=JA2YU96R&amp;#x26;sh=fc6787ce&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/learnmachinelearning/comments/7centc/learning_machine_learning_01_machine_learning/?st=J9WVF138&amp;#x26;sh=9b166f71&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/learnmachinelearning/comments/7centc/learning&lt;em&gt;machine&lt;/em&gt;learning&lt;em&gt;01&lt;/em&gt;machine_learning/?st=J9WVF138&amp;#x26;sh=9b166f71&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/learnmachinelearning/comments/7c8ogk/simple_deep_learning_model_for_stock_price/?st=J9W5R9AZ&amp;#x26;sh=22315e0b&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/learnmachinelearning/comments/7c8ogk/simple&lt;em&gt;deep&lt;/em&gt;learning&lt;em&gt;model&lt;/em&gt;for&lt;em&gt;stock&lt;/em&gt;price/?st=J9W5R9AZ&amp;#x26;sh=22315e0b&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.kaggle.com/2017/11/27/introduction-to-neural-networks/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;http://blog.kaggle.com/2017/11/27/introduction-to-neural-networks/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/learnmachinelearning/comments/7g5zx9/predicting_cryptocurrency_prices_with_deep/?st=JAK71BXS&amp;#x26;sh=a283370f&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/learnmachinelearning/comments/7g5zx9/predicting&lt;em&gt;cryptocurrency&lt;/em&gt;prices&lt;em&gt;with&lt;/em&gt;deep/?st=JAK71BXS&amp;#x26;sh=a283370f&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/learnmachinelearning/comments/7he36r/what_is_nlp_get_started/?st=JARMLMP7&amp;#x26;sh=2886d0a9&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/learnmachinelearning/comments/7he36r/what&lt;em&gt;is&lt;/em&gt;nlp&lt;em&gt;get&lt;/em&gt;started/?st=JARMLMP7&amp;#x26;sh=2886d0a9&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/learnmachinelearning/comments/7h7grz/essential_guide_to_keep_up_with_aimlcv/?st=JARCN2DT&amp;#x26;sh=fe113479&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/learnmachinelearning/comments/7h7grz/essential&lt;em&gt;guide&lt;/em&gt;to&lt;em&gt;keep&lt;/em&gt;up&lt;em&gt;with&lt;/em&gt;aimlcv/?st=JARCN2DT&amp;#x26;sh=fe113479&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.kaggle.com/2017/12/06/introduction-to-neural-networks-2/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;http://blog.kaggle.com/2017/12/06/introduction-to-neural-networks-2/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/preview?imm_mid=0f9b7e&amp;#x26;cmp=em-data-na-na-newsltr_20171213&amp;#x26;slide=id.g183f28bdc3_0_90&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://docs.google.com/presentation/d/1kSuQyW5DTnkVaZEjGYCkfOxvzCqGEFzWBy4e9Uedd9k/preview?imm&lt;em&gt;mid=0f9b7e&amp;#x26;cmp=em-data-na-na-newsltr&lt;/em&gt;20171213&amp;#x26;slide=id.g183f28bdc3&lt;em&gt;0&lt;/em&gt;90&lt;/a&gt;&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Noob's Guide to building a Deep Learning / Cryptocurrency PC (#3): Mining]]></title><description><![CDATA[Among the buzzwords in the tech world of 2017, two tower above the rest:  deep
learning  and  cryptocurrencies . It seems that everyone I…]]></description><link>https://thekevinscott.com/deep-learning-cryptocurrency-pc-3-mining/</link><guid isPermaLink="false">https://thekevinscott.com/deep-learning-cryptocurrency-pc-3-mining/</guid><pubDate>Sun, 10 Dec 2017 09:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Among the buzzwords in the tech world of 2017, two tower above the rest: &lt;strong&gt;deep
learning&lt;/strong&gt; and &lt;strong&gt;cryptocurrencies&lt;/strong&gt;. It seems that everyone I know (in tech)
wants to learn these things. And guess what — so do I! So much so that I&apos;m
building my own computer in order to facilitate that learning.&lt;/p&gt;
&lt;p&gt;What follows are my notes-to-self as I build a computer to learn about deep
learning and cryptocurrency mining. In the previous installments we discussed
&lt;a href=&quot;https://medium.com/@thekevinscott/noobs-guide-to-custom-computer-for-cryptocurrency-and-deep-learning-7caa255adfaf&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;assembling the
hardware&lt;/a&gt;
and &lt;a href=&quot;https://medium.com/@thekevinscott/noobs-guide-to-building-a-deep-learning-cryptocurrency-pc-2-the-os-39dd20bd9b21&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;installing the
OS&lt;/a&gt;.
In this installment I&apos;ll talk about how to set up a cryptocurrency miner and
connect to a pool.&lt;/p&gt;
&lt;iframe style=&quot;height:400px;width:100%;max-width:800px;margin:30px auto;&quot; src=&quot;https://upscri.be/96fcab/?as_embed&quot;&gt;&lt;/iframe&gt;
&lt;hr /&gt;
&lt;p&gt;To recap, in case you&apos;re just getting started with this series: my goal in
purchasing and building my own PC was to have hardware on hand to run machine
learning algorithms on, and bring myself up to speed on the exciting advances
happening in AI. But in between running training algorithms, my computer (and
it&apos;s hungry hungry GPUs) will sit fallow. We can&apos;t have that!&lt;/p&gt;
&lt;p&gt;When I&apos;m not running the computer over training data, I want to have it mining.
Even if it&apos;s making only a a little profit, it&apos;s still better than nothing.&lt;/p&gt;
&lt;h1 id=&quot;cryptocurrencies&quot;&gt;&lt;a href=&quot;#cryptocurrencies&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cryptocurrencies&lt;/h1&gt;
&lt;p&gt;Your first instinct when getting into mining might be to try and mine bitcoin.
This would almost certainly be a mistake.&lt;/p&gt;
&lt;p&gt;Bitcoin today is mined primarly via &lt;a href=&quot;https://www.buybitcoinworldwide.com/mining/hardware/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;ASICS
hardware&lt;/a&gt;, equipment
specialized for mining bitcoins and other cryptocurrencies (but mostly
bitcoins). Unless your goal in life is to mine bitcoins — and I suppose there&apos;s
nothing wrong with that — ASICS hardware is not a good investment. And without
ASICS hardware, it&apos;s hard to compete with the other miners.&lt;/p&gt;
&lt;p&gt;There are cryptocurrencies especially &lt;a href=&quot;https://www.coindesk.com/scrypt-miners-cryptocurrency-arms-race/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;designed to prevent mining via
specialized hardware, called scrypt
coins&lt;/a&gt;:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;One of the biggest differences between scrypt and SHA-256 is that the former
relies heavily on computing resources aside from the processing unit itself,
particularly memory. Conversely, SHA-256 doesn&apos;t. This makes it difficult for
scrypt-based systems to scale up and use lots of computing power, because they
would have to use a proportional amount of memory, and that is expensive. —
&lt;a href=&quot;https://www.coindesk.com/scrypt-miners-cryptocurrency-arms-race/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Danny Bradbury,
Coindesk&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;While more specialized hardware is beginning to come to market, you&apos;re probably
safe picking one of these scrypt currencies to mine. Ethereum is a good choice,
so that&apos;s what I&apos;m going to start with.&lt;/p&gt;
&lt;h1 id=&quot;the-tools&quot;&gt;&lt;a href=&quot;#the-tools&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The tools&lt;/h1&gt;
&lt;p&gt;To get started mining, you need
&lt;a href=&quot;https://github.com/ethereum/go-ethereum&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;ethereum&lt;/a&gt;, a
&lt;a href=&quot;https://github.com/ethereum-mining/ethminer&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;miner&lt;/a&gt;, and a &lt;strong&gt;wallet&lt;/strong&gt; to send
the mined coins to.&lt;/p&gt;
&lt;p&gt;First, enable the ethereum repository:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo add-apt-repository -y ppa:ethereum/ethereum
sudo apt-get update
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, install ethereum:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install ethereum
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next, you need to install the miner, &lt;code&gt;ethminer&lt;/code&gt;. (There are other miners as
well, like qtMiner, cudaminer, eth-proxy). You can either install via &lt;code&gt;apt-get&lt;/code&gt;
or from source; because I&apos;m a masochist I chose the latter.&lt;/p&gt;
&lt;p&gt;Head on over to the &lt;a href=&quot;https://github.com/ethereum-mining/ethminer/releases&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;releases
page&lt;/a&gt; and download the
most recent release:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wget 
tar xvzf ethminer-0.12.0-Linux.tar.gz
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;And then try running &lt;code&gt;ethminer&lt;/code&gt;. You should see something like:&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/ethminer-03f58a707a22b7b5a3e37172ccc022e2-0bc2f.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 24.125000000000004%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAFCAIAAADKYVtkAAAACXBIWXMAAAsSAAALEgHS3X78AAAAqklEQVQY032QywrCMBBFK9gXtJoKXbhz6TOGvJrWNin1j9z4+960BVFQOITMDDP3zgS7o03ZENJmo/tCOyJtQuvoUoGY1uEZHxP7jBkzZnGQwV7MPIwoxRAxu5aelehy3r7L/3G6ItwmrEUbSK9Nxtt8HAEQLk8a+mAyMnrxFnxzJ2+FvGdqIMpBGS9RFuUPe794WrFVfcodFsbakMWISfZLOZlOMF/BK78ARMgsIzhd6EQAAAAASUVORK5CYII=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;ethminer&quot; title=&quot;&quot; src=&quot;/static/ethminer-03f58a707a22b7b5a3e37172ccc022e2-17dec.png&quot; srcset=&quot;/static/ethminer-03f58a707a22b7b5a3e37172ccc022e2-ae2e5.png 160w,
/static/ethminer-03f58a707a22b7b5a3e37172ccc022e2-8227e.png 320w,
/static/ethminer-03f58a707a22b7b5a3e37172ccc022e2-17dec.png 640w,
/static/ethminer-03f58a707a22b7b5a3e37172ccc022e2-0bc2f.png 800w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;This is good! It&apos;s working, it just needs to be configured with options.&lt;/p&gt;
&lt;p&gt;Finally, the &lt;strong&gt;wallet&lt;/strong&gt;. There&apos;s lots of wallets available, with Mist being the
officially supported version. You don&apos;t actually need your wallet to be local;
it can be hosted anywhere, including on an exchange like Coinbase.&lt;/p&gt;
&lt;h1 id=&quot;pools&quot;&gt;&lt;a href=&quot;#pools&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Pools&lt;/h1&gt;
&lt;p&gt;Mining cryptocurrencies is kind of like a bunch of people in a field of
haystacks looking for needles. Every so often somebody gets lucky and finds one,
shouts it out to the world, and makes a chunk of money, and then the process
repeats.&lt;/p&gt;
&lt;p&gt;This is all well and good for that lucky finder, but — especially nowadays, when
you&apos;re &lt;a href=&quot;https://qz.com/1055126/photos-china-has-one-of-worlds-largest-bitcoin-mines/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;competing against industrial-strength mining
operations&lt;/a&gt;
— the chances of you solving a particular cryptographic puzzle first are slim to
nil. If you&apos;re a small fry like me, you&apos;re better off joining a mining pool.&lt;/p&gt;
&lt;p&gt;A mining pool allows a group of miners&apos; computers to join forces and work on
earning cryptocurrency as a team. When a new coin is mined, the profits will be
shared with the contributors based on the amount of computing power they put in.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.buybitcoinworldwide.com/ethereum/mining-pools/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.buybitcoinworldwide.com/ethereum/mining-pools/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;ethermine&quot;&gt;&lt;a href=&quot;#ethermine&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;ethermine&lt;/h2&gt;
&lt;p&gt;The first pool I joined was &lt;a href=&quot;http://ethpool.org/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;ethpool&lt;/a&gt;, and I subsequently
switched to &lt;a href=&quot;https://ethermine.org/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;ethermine&lt;/a&gt; (which appears to be running the
same code? it&apos;s unclear) as their payout scheme was more predictable.&lt;/p&gt;
&lt;p&gt;To start up mining, I ran:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./ethminer --farm-recheck 200 --cuda-parallel-hash 8 --cuda-grid-size 1024 --cuda-streams 16 --cuda-block-size 128 -G -S us1.ethermine.org:4444 -FS eu1.ethermine.org:4444 -O &amp;#x3C;My_Ethereum_Address&gt;.&amp;#x3C;My_RigName&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Here&apos;s the definitions for each option:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;farm-recheck&lt;/code&gt; — &lt;em&gt;&lt;n&gt; Leave n ms between checks for changed work (default: 500).
When using stratum, use a high value (i.e. 2000) to get more stable hashrate
output&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cuda-parallel-hash&lt;/code&gt; —** &lt;em&gt;**Define how many hashes to calculate in a kernel, can
be scaled to achieve better performance. Default=4&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cuda-block-size&lt;/code&gt; — &lt;em&gt;Set the CUDA block work size. Default is 128&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cuda-grid-size&lt;/code&gt; — &lt;em&gt;Set the CUDA grid size. Default is 8192&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cuda-streams&lt;/code&gt;— &lt;em&gt;Set the number of CUDA streams. Default is 2&lt;/em&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;My understanding of &lt;code&gt;farm-recheck&lt;/code&gt; is, it&apos;s an for &lt;a href=&quot;https://forum.ethereum.org/discussion/5379/mining-parameters&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;option to set how often the
program checks&lt;/a&gt;
for new work to work through. The lower you set it, the lower the chances of
working on stale blocks, but set it too low and you might see instability in the
hashing output.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;The other options I&apos;m not 100% familiar with, and so I just went with the
defaults. Feel free to leave a comment if you have a plain english explanation
of them.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Finally, you&apos;ll pick the servers to connect to — I chose &lt;code&gt;us1&lt;/code&gt;and &lt;code&gt;eu1&lt;/code&gt; — and
finally put in your wallet address and a name to identify your mining computer.
You may need to open up the ports &lt;code&gt;4444&lt;/code&gt; on your machine to allow connections.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If you&apos;re having trouble with ethminer, there&apos;s an active *&lt;a href=&quot;https://gitter.im/ethereum-mining/ethminer&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Gitter
room&lt;/a&gt;&lt;/em&gt; as well.*&lt;/p&gt;
&lt;p&gt;Once you start mining, you can go to your miner page and check out your stats.
For instance, the &lt;a href=&quot;https://ethermine.org/miners/45d961bddef7bd389d76b22907eb4856a4383aa6&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;dashboard view
shows&lt;/a&gt;:&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/miner-dashboard-1984622f0be254d2d246574d9ca88202-0bc2f.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 181.99999999999997%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAkCAIAAAAGkY33AAAACXBIWXMAAAsSAAALEgHS3X78AAAD50lEQVRIx51Vy27bVhDl19gwRdKJE9mJ7Vji4/It8U2KIiVZb1dFmsiwGyeOky67KFAkDYoC3rRAN003bVdtvMmn9ZBUVFu1nTjA0cXh3DmcucO5I6q0Y1+KOyTUm1+QYMjx7lU+FH6KpOhENmVZIzKIQWRLJjWZEEmFEVCIYuR2jSh1mcCCrUx84m+9f7j+fo8ry9GGFm+a6argYb0tBVcF/C9yRdJtVQaYinNTUMdfWmffW+9eR+/epGevPPAktq0f/0h/+Yc/fs0fBsnpwP4hcUX7bc36PU4KvLWcA8Wi/Gb6ZH/89XSENSP7I8mKmqd/9X89U1+80Y5ao5+/av40rCrhNB3vt/emrfF+Ds9KqR2r0xgdpJMng+mLeHwY9Kcbaux1H/cePUepq07X6z02k8m6GsMNGO6/TCdHILzbo+7Kje1a+zxui4F/8ir99lRIHpaVaMtMN43klugvuJWVBvXRkl5X7f+bpGAg+oMde1cORxV7l4RD5M873cvFoteHE1t1Od5hqxlAuIIIDiuFLO+yYpDt5mBIA5yp2hSaQW9OKk6H0+sAYzdY02HsmDVd1qyXnDbt95h6WPI6nFYHWNNjTZ+pR4xoUaiE030k+ENWRASPkVsMaTJixMgpbQwZKWbFiNb7nBhUaxFfBxqC4fGGVyYehdxwAZSgJ1gxb8WibAi6LSq6qFmSVkN3g0tqTVQMTm2xpMkJPrCK2yJGs4IxlWzlSPOenmxm3yatqA7Iltm6b6Rrhg8LHvFdFwuGL8YpaUmKaaVDK+1sVbsluV2SWytaf0Uf0MourfXxCICvaD1a65WEMK+2P6CDw+XgaDk6Xg6fZQRonMwIjJn9KNsCgSV8uhw9X9GHFFtx0GifKS7Spv0DWJfC46Xw2VKuWWqczAgs+RszkouXgqcgOE4m5njvPrG3ZWtLtoGKEZh+6rpuzQ0NP6m4vhmkoulvYkupbyuZG3gZ3zkbV6ghSTJIySK5hvMBdYdEuDQcerPqznrzHLnGmE2Su3KUzS3eBbgc58nqRXKeQ5+lDf1nRp631wJoPtzQmmgs3LYb3OcC2/U2ehMrhsbciCFjJJMCD6wO9emD9pbgq4293/78u8DBN99Ra1KA9PBKtTFek0I0jOD2cCSMBxQSFowK7KIL4Zbten285UG9jZNTq7ynROOizzAYUEYQnBMvBYEdwxT/IbDjFYUb1q1aC8JMjJh4xnDNxR4IxHAt/NZnYu+C2PwgLiLPxWUlvhBZa87E0ieI4Z2Lw8XI0mVpXzzzTDxP+/LIV4jd4szzyBs3OvMHcXBd2ubFas/TnolJCDIXry5EztP+F+BLZ+Cptk9iAAAAAElFTkSuQmCC&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;miner dashboard&quot; title=&quot;&quot; src=&quot;/static/miner-dashboard-1984622f0be254d2d246574d9ca88202-17dec.png&quot; srcset=&quot;/static/miner-dashboard-1984622f0be254d2d246574d9ca88202-ae2e5.png 160w,
/static/miner-dashboard-1984622f0be254d2d246574d9ca88202-8227e.png 320w,
/static/miner-dashboard-1984622f0be254d2d246574d9ca88202-17dec.png 640w,
/static/miner-dashboard-1984622f0be254d2d246574d9ca88202-0bc2f.png 800w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;Which gives you a nice overview of your stats, and also a rough estimate of your payouts:&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/payouts-9845c07fd92d393c9f11900497d0bce8-0bc2f.png&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 156.125%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAfCAIAAABoLHqZAAAACXBIWXMAAAsSAAALEgHS3X78AAADoElEQVQ4y51VWW/TQBDOP+kBLbGdOCVt07SFJL6vpHZjJ3bipCktuQqlIEGLBA8IISEhXngCIXgAXhAvlOMH8u2uW662HNJkNZ6Zb3Zm99tJSih5p4lU37q0tiFK9dMCUvgVpaqpGYZqWJquq6ZBdUfXvZrru56uWcSiGbamq6qJFcGyYiXgBT1ctqIdT3rRW33eW33SWinozXk1yJbcXNkVSy4UsUwkS4UpCTgn+3NKENnq3aB84Jf2vDIsOTnIlNfPltQZPf9RUkW7bYRDMxo67R2rNTKi4bzW/FswfqLkz6nNjETrlAJejjKVOvmUAkH6XrwgNYQjIxEGvqg0ckbMm5uI4I1Nzt7mtQ6vd2BhxkzF56wt3ugxCxGjJ5Tr9MAkX7R6nNMXlIiz+1x1CP1IBoLc5OyrRMcK15GXVyICXql2c2Y3XRulnUG6OoIDOgchoYPjRMSFz+qARNZGvNpmPddFs/vDbn8lvBLSntVGztr4TzBOe9mJC1Z7yY6XrHbhSIp2XDBb83ooyj4kr4X4RMAiVjvOqw0CxnmKlTopPhE/W6GrGgFPLonearaynkVk4q1jBUliNbgqrV+R/S08I63R15sDub4l+9slt+fEY1AIdiMcgLC/kgSJwWRkOl5RDy6PyZwc0KKIflzCTwyDA52cQH3wDLTROgnD5PAnLwOjepwEKCWoJIWgtpgbR0rAehdZYOStbaIoIViYAVUZw8gJmy2uNp7ZeCwoyNJFFnBwNryfdm+kvb3Z8B6oRta1a2l3N71+ixDRGSbvedHuTO+8nrz14dz2swv+HcDOX3k6tft26ub76dHLydsfp3bfTV1/A316/AqRkJn4YdJzwetP7H+ZOPg6cedw8vbhxP4nojPL/meyfle+EPv+55n4UTIM5ow43X7wT8JVxwkYPeNh/nITvNSE/cQxgINcNKIUjhrcvqgEZ0wMzBakzqtNNu1w88k9A1aNyQBacTpg2zKl97LiQl+pdopWG0GYTXZ7bLfGWGvdayDfErWTnQFDXPY3ArHysMqUnmqjD6oCyfKiBDoMHHDIAxMv1TbQCUYiUzDPWQqUg8qxG4pnpwNvQs+ytwkHcwOAN4jekBEReBuwYyukRhiDoXnYE/BqrbtgRCgjAWshQtEt4i6v9RCKIsEFvC28GcAQAz0BoyoyQEEVs0XB5FSBxCfqz2tNpKOPpyXSJ4Rt2BUmZRdp2UW6c56CMVswMfAvecZ/wDcT4AMrl67w8gAAAABJRU5ErkJggg==&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;payouts&quot; title=&quot;&quot; src=&quot;/static/payouts-9845c07fd92d393c9f11900497d0bce8-17dec.png&quot; srcset=&quot;/static/payouts-9845c07fd92d393c9f11900497d0bce8-ae2e5.png 160w,
/static/payouts-9845c07fd92d393c9f11900497d0bce8-8227e.png 320w,
/static/payouts-9845c07fd92d393c9f11900497d0bce8-17dec.png 640w,
/static/payouts-9845c07fd92d393c9f11900497d0bce8-0bc2f.png 800w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;h2 id=&quot;tuning&quot;&gt;&lt;a href=&quot;#tuning&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Tuning&lt;/h2&gt;
&lt;p&gt;Once you&apos;ve got your rig mining, you may want to squeeze out every ounce of
processing power. If so, here&apos;s a few links to point you in the right direction!&lt;/p&gt;
&lt;h3 id=&quot;the-awesome-wiki-article-at-rethermining&quot;&gt;&lt;a href=&quot;#the-awesome-wiki-article-at-rethermining&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The awesome wiki article at &lt;code&gt;/r/EtherMining&lt;/code&gt;:&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/EtherMining/wiki/index&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/EtherMining/wiki/index&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;a-conversation-on-overclocking&quot;&gt;&lt;a href=&quot;#a-conversation-on-overclocking&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A conversation on overclocking:&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://bitcointalk.org/index.php?topic=1712831.0&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://bitcointalk.org/index.php?topic=1712831.0&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;a-few-articles-about-tweaking-miners&quot;&gt;&lt;a href=&quot;#a-few-articles-about-tweaking-miners&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;A few articles about tweaking miners:&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://robekworld.com/hash-rate-improvement-with-nvidia-asus-1060-1070-gpu-for-ether-like-mining-gpu-tweak-ii-e3cde220812f&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://robekworld.com/hash-rate-improvement-with-nvidia-asus-1060-1070-gpu-for-ether-like-mining-gpu-tweak-ii-e3cde220812f&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.legitreviews.com/geforce-gtx-1070-ethereum-mining-small-tweaks-great-hashrate-low-power_195451&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;http://www.legitreviews.com/geforce-gtx-1070-ethereum-mining-small-tweaks-great-hashrate-low-power_195451&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://cryptomining-blog.com/7341-how-to-squeeze-some-extra-performance-mining-ethereum-on-nvidia/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;http://cryptomining-blog.com/7341-how-to-squeeze-some-extra-performance-mining-ethereum-on-nvidia/&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;how-about-writing-your-own-miner&quot;&gt;&lt;a href=&quot;#how-about-writing-your-own-miner&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;How about writing your own miner?&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/ethereum/comments/7caqpb/a_tiny_miner_i_wrote_to_understand_how_mining/?sh=f25cfa84&amp;#x26;st=J9W5B865&amp;#x26;utm_content=title&amp;#x26;utm_medium=post_embed&amp;#x26;utm_name=ef770faa323446d0909650522f22e37a&amp;#x26;utm_source=embedly&amp;#x26;utm_term=7caqpb&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.reddit.com/r/ethereum/comments/7caqpb/a&lt;em&gt;tiny&lt;/em&gt;miner&lt;em&gt;i&lt;/em&gt;wrote&lt;em&gt;to&lt;/em&gt;understand&lt;em&gt;how&lt;/em&gt;mining/?sh=f25cfa84&amp;#x26;st=J9W5B865&amp;#x26;utm&lt;em&gt;content=title&amp;#x26;utm&lt;/em&gt;medium=post&lt;em&gt;embed&amp;#x26;utm&lt;/em&gt;name=ef770faa323446d0909650522f22e37a&amp;#x26;utm&lt;em&gt;source=embedly&amp;#x26;utm&lt;/em&gt;term=7caqpb&lt;/a&gt;&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;And that&apos;s what you need to get a mining rig set up! Piece of cake, right? The
good news is once it&apos;s set up you can just sort of let it run without touching
it. Just make sure nobody trips over the power cable.&lt;/p&gt;
&lt;p&gt;The final installment of this series will be about getting some basic AI
learning algorithms running on the hardware. If you want to hear about those,
drop your email below and I&apos;ll let you know when I publish it!&lt;/p&gt;
&lt;iframe style=&quot;height:400px;width:100%;max-width:800px;margin:30px auto;&quot; src=&quot;https://upscri.be/96fcab/?as_embed&quot;&gt;&lt;/iframe&gt;</content:encoded></item><item><title><![CDATA[Noob's Guide to building a Deep Learning / Cryptocurrency PC (#2): The OS]]></title><description><![CDATA[Among the buzzwords in the tech world of 2017, two tower above the rest:  deep
learning  and  cryptocurrencies . It seems that everyone I…]]></description><link>https://thekevinscott.com/deep-learning-cryptocurrency-pc-2-os/</link><guid isPermaLink="false">https://thekevinscott.com/deep-learning-cryptocurrency-pc-2-os/</guid><pubDate>Fri, 06 Oct 2017 09:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Among the buzzwords in the tech world of 2017, two tower above the rest: &lt;strong&gt;deep
learning&lt;/strong&gt; and &lt;strong&gt;cryptocurrencies&lt;/strong&gt;. It seems that everyone I know (in tech)
wants to learn these things. And guess what — so do I! So much so that I&apos;m
building my own computer in order to facilitate that learning.&lt;/p&gt;
&lt;p&gt;What follows are my notes-to-self as I build a computer to learn about deep
learning and cryptocurrency mining. &lt;a href=&quot;https://medium.com/@thekevinscott/noobs-guide-to-custom-computer-for-cryptocurrency-and-deep-learning-7caa255adfaf&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;In the previous installment we discussed
assembling the hardware.
&lt;/a&gt;In
this installment I&apos;ll talk about choosing and installing the OS, configuring it
and making sure the hardware is working, and some basic OS security.&lt;/p&gt;
&lt;iframe style=&quot;height:400px;width:100%;max-width:800px;margin:30px auto;&quot; src=&quot;https://upscri.be/96fcab/?as_embed&quot;&gt;&lt;/iframe&gt;
&lt;hr /&gt;
&lt;h1 id=&quot;the-operating-system&quot;&gt;&lt;a href=&quot;#the-operating-system&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The operating system&lt;/h1&gt;
&lt;p&gt;Last time we left off immediately after assembling our computer. Our computer
came without an operating system, so the next step is to choose and install one.&lt;/p&gt;
&lt;p&gt;I chose Ubuntu Desktop. Lots of the tutorials I see for deep learning are
written for Ubuntu, and I&apos;m comfortable with Linux. Windows also seems to have
plenty of support but I&apos;m not nearly as familiar with the MS ecosystem.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.quora.com/What-are-the-most-popular-linux-distros-for-deep-learning-research&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;I don&apos;t think
it&lt;/a&gt;
&lt;a href=&quot;https://bitcointalk.org/index.php?topic=166986.0&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;matters a ton which OS you
choose&lt;/a&gt;; &lt;a href=&quot;https://forums.servethehome.com/index.php?threads/best-os-and-software-for-machine-learning-and-deep-learning.15890/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;most of what you&apos;ll
be using it for is
platform-agnostic&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;The big thing to keep an eye out for is CUDA support. &lt;a href=&quot;http://nvidia.custhelp.com/app/answers/detail/a_id/2135/~/which-operating-systems-are-supported-by-cuda?&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Luckily, most of the
operating systems (Windows, Linux and
Mac)&lt;/a&gt;
are supported. So don&apos;t go choosing some crazy new-fangled OS nobody&apos;s heard of!&lt;/p&gt;
&lt;p&gt;So, the conclusion: Pick a Linux distro, Ubuntu unless you&apos;re familiar with
Linux and comfortable with the command line, or pick Windows and go find
yourself &lt;a href=&quot;https://www.lifewire.com/cryptocoin-mining-for-beginners-2483064&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;another
tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;installing&quot;&gt;&lt;a href=&quot;#installing&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Installing&lt;/h2&gt;
&lt;p&gt;Once you&apos;ve chosen your OS, the first step is to burn an image of the distro to
a USB stick. &lt;a href=&quot;https://tutorials.ubuntu.com/tutorial/tutorial-create-a-usb-stick-on-windows#0&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Ubuntu provides a very straightforward
tutorial&lt;/a&gt;.
Once you&apos;ve got that, you&apos;ll restart your computer and reboot from USB.
Instructions on doing this differ depending on the motherboard so read your
manual; for me, I had to restart holding down F10.&lt;/p&gt;
&lt;p&gt;You then will run through the OS installation, of which plenty of guides exist
on the internet.&lt;/p&gt;
&lt;p&gt;Now at some point, this being a computer you assembled from scratch, it&apos;s likely
you&apos;ll run into problems. For me, I had a hell of a time getting my display to
come on and stay on. I&apos;m still not 100% sure why. Assuming your hardware differs
from mine, your problems are likely to be unique to you. Don&apos;t panic. Google is
your friend, and it&apos;s likely that any problem you run into, others have run into
too.&lt;/p&gt;
&lt;p&gt;The problems I struggled with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;I had a hell of a time getting the display to work. Turning &lt;code&gt;acpi=off&lt;/code&gt; in the
grub bootloader, &lt;a href=&quot;https://askubuntu.com/questions/861743/installation-of-ubuntu-16-04-from-a-usb-drive-freezes&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;as described
here&lt;/a&gt;,
helped me (&lt;a href=&quot;https://www.howtogeek.com/196655/how-to-configure-the-grub2-boot-loaders-settings/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;here&apos;s how to persist settings in the grub
bootloader&lt;/a&gt;).
The computer may struggle to figure out which graphics card (the built-in one,
or one of the GPUs) to use for the monitor as well. &lt;a href=&quot;https://ubuntuforums.org/showthread.php?t=1613132&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Here&apos;s some more info on
&lt;/a&gt;&lt;code&gt;acpi&lt;/code&gt;&lt;a href=&quot;https://ubuntuforums.org/showthread.php?t=1613132&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;My ethernet didn&apos;t work out of the box. &lt;a href=&quot;http://www.ubuntugeek.com/ubuntu-networking-configuration-using-command-line.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;This guide does a good
rundown&lt;/a&gt;
of Ubuntu internet issues, and &lt;a href=&quot;https://ubuntuforums.org/showthread.php?t=25557&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;this guide by
dataw0lf&lt;/a&gt; was a godsend.&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.linuxandubuntu.com/home/how-to-install-latest-nvidia-drivers-in-linux&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;How to install nvidia
drivers&lt;/a&gt;
once you have internet.&lt;/li&gt;
&lt;li&gt;Wait, did I install a 32-bit or 64-bit distro? &lt;a href=&quot;https://unix.stackexchange.com/questions/12453/how-to-determine-linux-kernel-architecture&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Here&apos;s how to
tell.&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Just keep at it, and don&apos;t hesitate to ask the community if you&apos;re wrestling
with a particularly thorny issue. They&apos;re plenty friendly, so long as you&apos;ve
done your homework beforehand!&lt;/p&gt;
&lt;h1 id=&quot;system-diagnosis&quot;&gt;&lt;a href=&quot;#system-diagnosis&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System Diagnosis&lt;/h1&gt;
&lt;p&gt;Now we&apos;re booting into Linux and we&apos;ve got the basics installed. As my next
step, I want to check that the hardware is all running correctly and there&apos;s
nothing out of the ordinary. To check that, I learned about a few good tools on
Linux. You may have to install a few of these, if something is missing try
installing it with:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;sudo apt-get install xxxxx&lt;/code&gt;&lt;/p&gt;
&lt;h2 id=&quot;system-wide-commands&quot;&gt;&lt;a href=&quot;#system-wide-commands&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;System-wide commands&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;lshw&lt;/code&gt; is used to &lt;strong&gt;list hardware&lt;/strong&gt;. This will dump out a ton of information in
your system.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;inxi&lt;/code&gt; is another good one. Here&apos;s my &lt;code&gt;inxi -Fx&lt;/code&gt; output:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;inxi -Fx&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Let&apos;s step through component by component and run a sanity check to make sure
everything is working.&lt;/p&gt;
&lt;h2 id=&quot;cpu&quot;&gt;&lt;a href=&quot;#cpu&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CPU&lt;/h2&gt;
&lt;p&gt;There&apos;s a few commands you can use to get more information on your CPU:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;cat /proc/cpuinfo&lt;/code&gt;prints out information on your CPU. &lt;a href=&quot;https://unix.stackexchange.com/questions/146051/number-of-processors-in-proc-cpuinfo&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Here&apos;s a good Stack
Overflow
thread&lt;/a&gt;
going into more detail on what this output means.&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;cat /proc/cpuinfo&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;lshw&lt;/code&gt; will list out all hardware, and the CPU section has some relevant
information:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;lshw&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;code&gt;lscpu&lt;/code&gt; will give you some more CPU-specific information, including MHz and
cache information:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;lscpu&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;These commands are great if you&apos;re familiar with the ins and outs of hardware,
but I barely have a clue what I&apos;m looking at. I just want to know if the CPU is
working or not.&lt;/p&gt;
&lt;p&gt;For that, &lt;code&gt;top&lt;/code&gt; and &lt;code&gt;htop&lt;/code&gt; will do the trick.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;top&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*zlUXYjZbjuJFbzFwRIxDIQ.png&quot;&gt;
&lt;span class=&quot;figcaption_hack&quot;&gt;Output from &lt;code&gt;top&lt;/code&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;And to get more graphical, use &lt;code&gt;htop&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;Output from htop&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.deonsworld.co.za/2012/12/20/understanding-and-using-htop-monitor-system-resources/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;This
article&lt;/a&gt;
does a pretty deep dive into &lt;code&gt;htop&lt;/code&gt;. To ensure I&apos;m getting 100% throughput on
each of the cores, this article at
&lt;a href=&quot;https://peteris.rocks/blog/htop/#load-average&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;peteris.rocks&lt;/a&gt; does a good job
explaining how:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;If you run &lt;code&gt;cat /dev/urandom &gt; /dev/null&lt;/code&gt; which repeatedly generates random
bytes and writes them to a special file that is never read from, you will see
that there are now two running process.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Running this gets me to 100.0% on all cores. I&apos;m not 100% sure this is a valid
test of the CPU but it seems good enough for me.&lt;/p&gt;
&lt;h2 id=&quot;hard-drive&quot;&gt;&lt;a href=&quot;#hard-drive&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hard Drive&lt;/h2&gt;
&lt;p&gt;Running &lt;code&gt;lsblk&lt;/code&gt; prints information about hard drive partitions and other storage
devices. Running that gives me:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*7TFaMOHq7OohkB0X-ZW7WQ.png&quot;&gt;
&lt;span class=&quot;figcaption_hack&quot;&gt;lsblk&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Which is roughly the size I expect. &lt;code&gt;df&lt;/code&gt; is another one that gives you
information about hard drive space:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;df&lt;/span&gt;&lt;/p&gt;
&lt;h2 id=&quot;ram&quot;&gt;&lt;a href=&quot;#ram&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RAM&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;free -m&lt;/code&gt; will check the amount of RAM:&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*zlk3wpJnoECxLDDh01e_-A.png&quot;&gt;
&lt;span class=&quot;figcaption_hack&quot;&gt;free -m&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;That doesn&apos;t look so good — I expected 16 GBs! Let&apos;s check &lt;code&gt;lshw&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;lshw&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This tells me I installed one of the RAM chips wrong. Time to break out the
screwdriver again.&lt;/p&gt;
&lt;h2 id=&quot;gpus&quot;&gt;&lt;a href=&quot;#gpus&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GPUs&lt;/h2&gt;
&lt;p&gt;&lt;code&gt;lspci&lt;/code&gt; will give you information on PCI buses and devices in your system,
including your GPUs:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;lspci&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Another command you can use is &lt;code&gt;nvidia-smi&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;nvidia-smi&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;This gives you information like fan usage, temperature, memory-usage, and more
goodies.&lt;/p&gt;
&lt;h2 id=&quot;cooling&quot;&gt;&lt;a href=&quot;#cooling&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Cooling&lt;/h2&gt;
&lt;p&gt;Check CPU temperature with &lt;code&gt;sensors&lt;/code&gt; :&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;sensors&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;Between this and &lt;code&gt;nvidia-smi&lt;/code&gt; above you should be able to get a good idea of
whether your cooling supply is adequate or not.&lt;/p&gt;
&lt;h2 id=&quot;power&quot;&gt;&lt;a href=&quot;#power&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Power&lt;/h2&gt;
&lt;p&gt;Is the system getting enough power? Short of &lt;a href=&quot;https://askubuntu.com/questions/421955/software-to-find-desktop-power-usage&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;measuring the power between the
computer and the
electrical&lt;/a&gt;,
I don&apos;t think there&apos;s a 100% software solution to find this out.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;powertop&lt;/code&gt; is a utility that measures consumption. It seems like it&apos;s mostly
useful for laptops, but &lt;a href=&quot;http://fsckin.com/2007/10/21/intel-powertop-not-just-for-laptops/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;there&apos;s some good info for desktops as Wayne points out
here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Ultimately, making sure you have adequate power needs is something you should do
before assembling your system, either by checking
&lt;a href=&quot;https://pcpartpicker.com/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;pcpartpicker.com&lt;/a&gt; when choosing your parts or
&lt;a href=&quot;http://www.buildcomputers.net/power-consumption-of-pc-components.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;checking something like this
link&lt;/a&gt;
(thanks Sean!). And if you can afford it leave yourself plenty of breathing room
in the watts department.&lt;/p&gt;
&lt;h1 id=&quot;security&quot;&gt;&lt;a href=&quot;#security&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Security&lt;/h1&gt;
&lt;p&gt;Having satisfied my worrywart side that everything is running smoothly, the next
step is to make sure we&apos;ve configured our system following standard Linux
security procedures.&lt;/p&gt;
&lt;p&gt;I&apos;m going to be using this machine to practice deep learning (not too worried
about someone hacking this) and for mining cryptocurrencies (more concerned
about something hacking this!)&lt;/p&gt;
&lt;p&gt;A good place to start is the &lt;a href=&quot;https://wiki.ubuntu.com/BasicSecurity&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Basic Security guide hosted on Ubuntu
Wiki&lt;/a&gt;:&lt;/p&gt;
&lt;p&gt;I assume you&apos;re familiar with the general Linux security procedures — strong
passwords, limited root access, that sort of thing. If not, spend some time
c&lt;a href=&quot;https://ubuntuforums.org/showthread.php?t=510812&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;atching up on that&lt;/a&gt;.&lt;/p&gt;
&lt;h4 id=&quot;automatic-security-updates&quot;&gt;&lt;a href=&quot;#automatic-security-updates&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Automatic Security Updates&lt;/h4&gt;
&lt;p&gt;I&apos;m lazy as sin and if there&apos;s one thing I hate it&apos;s manual security updates.
Luckily Ubuntu provides an automatic update mechanism:&lt;/p&gt;
&lt;p&gt;I followed the “unattended-upgrades” package and it was a straightforward
process.&lt;/p&gt;
&lt;p&gt;This will likely cause issues if I&apos;m running deep learning simulations
overnight, but I can tackle that issue in the future. For now I&apos;m erring on the
side of caution.&lt;/p&gt;
&lt;h2 id=&quot;firewall&quot;&gt;&lt;a href=&quot;#firewall&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Firewall&lt;/h2&gt;
&lt;p&gt;A firewall will allow you control over which ports are accessible publicly.
Generally you want the most restrictive policy you can stomach.&lt;/p&gt;
&lt;p&gt;Here&apos;s the &lt;a href=&quot;https://wiki.ubuntu.com/BasicSecurity/Firewall&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Ubuntu wiki for
firewalls&lt;/a&gt; (&lt;em&gt;if you&apos;re noticing a trend, it&apos;s that the Ubuntu wiki has some pretty darn good information!&lt;/em&gt;):&lt;/p&gt;
&lt;p&gt;I&apos;m going to use &lt;code&gt;ufw&lt;/code&gt; because I&apos;m on the terminal. I went with the
recommendations the guide laid out — DHCP, web and mail access — but left out the torrent ports since I don&apos;t need them.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://ubuntuforums.org/showthread.php?t=510812&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;This is an absolutely massive security
guide&lt;/a&gt; by bodhi.zazen. It&apos;s well worth a read and implementation.&lt;/p&gt;
&lt;hr /&gt;
&lt;p&gt;If you want to hear about how I tackled the crypto mining and deep learning setups, drop your email below and I&apos;ll let you know when I publish those
sections.&lt;/p&gt;
&lt;iframe style=&quot;height:400px;width:100%;max-width:800px;margin:30px auto;&quot; src=&quot;https://upscri.be/96fcab/?as_embed&quot;&gt;&lt;/iframe&gt;
&lt;hr /&gt;</content:encoded></item><item><title><![CDATA[Arrays in React 16 and the necessity of keys]]></title><description><![CDATA[Over the weekend at  React Boston   I saw a great
talk  by  Ben
Ilegbodu  where he discussed changes in the
 upcoming Fiber release 
for…]]></description><link>https://thekevinscott.com/arrays-in-react-16/</link><guid isPermaLink="false">https://thekevinscott.com/arrays-in-react-16/</guid><pubDate>Tue, 26 Sep 2017 09:00:00 GMT</pubDate><content:encoded>&lt;p&gt;Over the weekend at &lt;a href=&quot;http://www.reactboston.com/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;React Boston&lt;/a&gt; &lt;a href=&quot;http://www.benmvp.com/slides/2017/reactboston/fiber.html#/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;I saw a great
talk&lt;/a&gt; by &lt;a href=&quot;https://medium.com/@benmvp&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Ben
Ilegbodu&lt;/a&gt; where he discussed changes in the
&lt;a href=&quot;https://github.com/acdlite/react-fiber-architecture&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;upcoming Fiber release&lt;/a&gt;
for React 16.&lt;/p&gt;
&lt;p&gt;A common complaint in React 15 and below has been the inability to directly
return an array of elements. React traditionally has required render functions
to return a single top-level parent element. This means that when returning
lists, you&apos;d have to enclose the list in a container element:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Valid React 15
const Page = () =&gt; (
  &amp;#x3C;div&gt;
    &amp;#x3C;a href=&quot;#one&quot;&gt;One&amp;#x3C;/a&gt;
    &amp;#x3C;a href=&quot;#two&quot;&gt;Two&amp;#x3C;/a&gt;
  &amp;#x3C;/div&gt;
);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This often leads to extraneous markup with &lt;code&gt;div&lt;/code&gt;s that pollute the HTML. In
React 16, you can return arrays of elements:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// Valid React 16, invalid React 15
const Page = () =&gt; ([
  &amp;#x3C;a key=&quot;one&quot; href=&quot;#one&quot;&gt;One&amp;#x3C;/a&gt;
  &amp;#x3C;a key=&quot;two&quot; href=&quot;#two&quot;&gt;Two&amp;#x3C;/a&gt;
]);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;You&apos;ll notice each element has a unique &lt;code&gt;key&lt;/code&gt;. From the React docs:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Keys help React identify which items have changed, are added, or are removed.
Keys should be given to the elements inside the array to give the elements a
stable identity — &lt;a href=&quot;https://facebook.github.io/react/docs/lists-and-keys.html#keys&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Lists and
Keys&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;In practice, unique keys might look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;// where href is guaranteed to be unique
const Header = ({ links }) =&gt; (
  &amp;#x3C;div&gt;
    {links.map(link =&gt; (
      &amp;#x3C;a key={link.href} href={link.href}&gt;{link.label}&amp;#x3C;/a&gt;
    ))}
  &amp;#x3C;/div&gt;
);
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@robinpokorny/index-as-a-key-is-an-anti-pattern-e0349aece318&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://medium.com/@robinpokorny/index-as-a-key-is-an-anti-pattern-e0349aece318&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Returning unique &lt;code&gt;key&lt;/code&gt;s from the render method helps React identify what needs
to be re-rendered. But it also adds some verbosity to the code that feels
redundant; for instance, we don&apos;t need to add keys when returning top-level
elements.&lt;/p&gt;
&lt;p&gt;In his talk, &lt;a href=&quot;https://medium.com/@benmvp&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Ben&lt;/a&gt; highlighted a library,
&lt;a href=&quot;https://github.com/gajus/react-aux&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;react-aux&lt;/a&gt;, that addresses this verbosity
problem and removes the need to provide explicit keys:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;const Root = () =&gt; {
  return &amp;#x3C;Aux&gt;
    &amp;#x3C;p&gt;Hello, World!&amp;#x3C;/p&gt;
    &amp;#x3C;p&gt;I am a demo for react-aux.&amp;#x3C;/p&gt;
  &amp;#x3C;/Aux&gt;;
};

// which is equivalent to the following:
const Root = () =&gt; {
  const Aux = (props) =&gt; props.children;

  return &amp;#x3C;Aux&gt;
    &amp;#x3C;p&gt;Hello, World!&amp;#x3C;/p&gt;
    &amp;#x3C;p&gt;I am a demo for react-aux.&amp;#x3C;/p&gt;
  &amp;#x3C;/Aux&gt;;
};
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@gajus&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Gajus Kuizinas&lt;/a&gt;&apos;s package leverages the fact that
you can omit unique keys for a list of elements by directly returning &lt;code&gt;children&lt;/code&gt;
from a container div.&lt;/p&gt;
&lt;p&gt;But that makes me question: **Why is it valid to return children without keys,
but invalid to return a top level array without keys? **I suspect the answer has
something to do with providing a top-level node for the children to live under.
But why do nested siblings in a regular &lt;code&gt;render&lt;/code&gt; function not require keys as
well?&lt;/p&gt;
&lt;p&gt;If you know the answer, please leave a comment! I&apos;m hoping to dig more into
React 16 and see if I can answer this myself.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;&lt;em&gt;Edit (9/29/2017):&lt;/em&gt; Looks like the team is thinking about addressing this in the
future:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;In the future, we&apos;ll likely add a special fragment syntax to JSX that doesn&apos;t
require keys. — &lt;a href=&quot;https://reactjs.org/blog/2017/09/26/react-v16.0.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Andrew
Clark&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;So there you have it!&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Noob's Guide to building a Deep Learning / Cryptocurrency PC (#1): The Hardware]]></title><description><![CDATA[A mong the buzzwords in the tech world of 2017, two tower above the rest:  deep
learning  and  cryptocurrencies . It seems that everyone…]]></description><link>https://thekevinscott.com/deep-learning-cryptocurrency-pc-1-hardware/</link><guid isPermaLink="false">https://thekevinscott.com/deep-learning-cryptocurrency-pc-1-hardware/</guid><pubDate>Mon, 25 Sep 2017 09:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;A&lt;/span&gt;mong the buzzwords in the tech world of 2017, two tower above the rest: &lt;strong&gt;deep
learning&lt;/strong&gt; and &lt;strong&gt;cryptocurrencies&lt;/strong&gt;. It seems that everyone wants to learn more
about these things. And guess what — so do I! So much so that I&apos;m building my
own computer in order to facilitate that learning.&lt;/p&gt;
&lt;p&gt;What follows are my notes-to-self as I build a computer to learn about deep
learning and cryptocurrency mining. In this installment we&apos;ll just discuss
building the hardware. If you&apos;d like to hear about configuring the OS, getting
started with crypto mining, or getting started with deep learning algorithms,
drop me your email below and I&apos;ll keep you in the loop.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Some quick definitions, for those unfamiliar:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;A &lt;strong&gt;cryptocurrency&lt;/strong&gt; … is a &lt;a href=&quot;https://en.wikipedia.org/wiki/Digital_asset&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;digital
asset&lt;/a&gt; designed to work as a
&lt;a href=&quot;https://en.wikipedia.org/wiki/Medium_of_exchange&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;medium of exchange&lt;/a&gt; using
&lt;a href=&quot;https://en.wikipedia.org/wiki/Cryptography&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;cryptography&lt;/a&gt; to secure the
transactions and to control the creation of additional units of the currency. —
&lt;a href=&quot;https://en.wikipedia.org/wiki/Cryptocurrency&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Machine learning&lt;/strong&gt; is the subfield of &lt;a href=&quot;https://en.wikipedia.org/wiki/Computer_science&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;computer
science&lt;/a&gt; that, according to
&lt;a href=&quot;https://en.wikipedia.org/wiki/Arthur_Samuel&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Arthur Samuel&lt;/a&gt;, gives “computers
the ability to learn without being explicitly programmed.” — also
&lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Deep learning&lt;/strong&gt; … is part of a broader family of &lt;a href=&quot;https://en.wikipedia.org/wiki/Machine_learning&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;machine
learning&lt;/a&gt; methods based on
&lt;a href=&quot;https://en.wikipedia.org/wiki/Learning_representation&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;learning data
representations&lt;/a&gt;, as
opposed to task-specific algorithms. —
&lt;a href=&quot;https://en.wikipedia.org/wiki/Deep_learning&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;hr&gt;
&lt;p&gt;&lt;span class=&quot;dropcap&quot;&gt;W&lt;/span&gt;hy build a PC to learn this stuff? It&apos;s important to note that you don&apos;t have
to. Your laptop is capable of running the same software, but the performance
you‘ll get out of a dedicated GPU is miles beyond what your laptop&apos;s CPU can
deliver. You&apos;ll spend more money replacing your worn-out laptop than you&apos;ll make
mining cryptocurrencies, and anything beyond basic deep learning training will
take forever.&lt;/p&gt;
&lt;h2 id=&quot;gpus&quot;&gt;&lt;a href=&quot;#gpus&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GPUs&lt;/h2&gt;
&lt;p&gt;GPUs are specialized chips for processing data in parallel. Originally developed
to power intensive graphics (like in video games), more recently their
architecture has been discovered to be a perfect fit for the short, repetitive
and parallelizable tasks at the heart of both machine learning and
cryptocurrency mining.&lt;/p&gt;
&lt;h2 id=&quot;the-cloud&quot;&gt;&lt;a href=&quot;#the-cloud&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The cloud&lt;/h2&gt;
&lt;p&gt;You can rent GPUs in the cloud, for instance, &lt;a href=&quot;https://aws.amazon.com/about-aws/whats-new/2016/09/introducing-amazon-ec2-p2-instances-the-largest-gpu-powered-virtual-machine-in-the-cloud/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;with
AWS&lt;/a&gt;.
Unfortunately they&apos;re expensive and it&apos;s a much better deal to run things
locally. (This will probably change in the future).&lt;/p&gt;
&lt;p&gt;So it makes economic and temporal sense to run these things locally.&lt;/p&gt;
&lt;h1 id=&quot;hardware&quot;&gt;&lt;a href=&quot;#hardware&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hardware&lt;/h1&gt;
&lt;p&gt;I haven&apos;t built a computer from scratch in over 20 years. I bought a Mac in 2004
and haven&apos;t looked back since. I was lucky enough to have a good friend with
some experience who was able to guide me in the right direction.&lt;/p&gt;
&lt;h2 id=&quot;picking-a-gpu&quot;&gt;&lt;a href=&quot;#picking-a-gpu&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Picking a GPU&lt;/h2&gt;
&lt;p&gt;The most important question: Which GPU to purchase?&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://timdettmers.com/2017/04/09/which-gpu-for-deep-learning/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Tim Dettmers has a fantastic in-depth
article&lt;/a&gt;
comparing a number of GPUs out on the market. Go read his article if you want a
truly exhaustive look at the costs and benefits of available GPUs.&lt;/p&gt;
&lt;p&gt;He writes:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;NVIDIA&apos;s standard libraries made it very easy to establish the first deep
learning libraries in CUDA, while there were no such powerful standard libraries
for AMD&apos;s OpenCL. Right now, there are just no good deep learning libraries for
AMD cards — so NVIDIA it is.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I&apos;d heard this sentiment from others. It seems that if you want to do machine
learning, you&apos;re best off going with NVIDIA.&lt;/p&gt;
&lt;p&gt;I ended up picking a pair of GTX 970s, which was primarily a budget decision
(this is a hobby, after all). There&apos;s lots available on eBay.&lt;/p&gt;
&lt;h2 id=&quot;the-rest-of-the-parts&quot;&gt;&lt;a href=&quot;#the-rest-of-the-parts&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The rest of the parts&lt;/h2&gt;
&lt;p&gt;A number of folks have written about their experiences building deep
learning-capable machines, and they were invaluable for helping me figure out
what parts to buy:&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/towards-data-science/building-your-own-deep-learning-box-47b918aea1eb&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://medium.com/towards-data-science/building-your-own-deep-learning-box-47b918aea1eb&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://medium.com/@acrosson/building-a-deep-learning-box-d17d97e2905c&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://medium.com/@acrosson/building-a-deep-learning-box-d17d97e2905c&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.oreilly.com/learning/build-a-super-fast-deep-learning-machine-for-under-1000&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;https://www.oreilly.com/learning/build-a-super-fast-deep-learning-machine-for-under-1000&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;As these articles point you, make sure to enter your components into
&lt;a href=&quot;https://pcpartpicker.com/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;pcpartpicker.com&lt;/a&gt; before purchasing, to ensure
components work together. I failed to do this, and as you&apos;ll read below, this
necessitated a trip back to the Amazon store a second time.&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/parts-84499e950f250d856a8fde2c3d7e1770-9f082.jpeg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwABAQEBAAAAAAAAAAAAAAAAAAQBA//EABQBAQAAAAAAAAAAAAAAAAAAAAP/2gAMAwEAAhADEAAAAXGuUFpYJP/EABoQAAIDAQEAAAAAAAAAAAAAAAECAxEiABL/2gAIAQEAAQUCM1czOxU5z5dSFEYr/8QAFhEBAQEAAAAAAAAAAAAAAAAAAQAh/9oACAEDAQE/AUbb/8QAFhEBAQEAAAAAAAAAAAAAAAAAAAEh/9oACAECAQE/AZWP/8QAGBABAQEBAQAAAAAAAAAAAAAAAQARIWH/2gAIAQEABj8CtNCL3IVuLl//xAAZEAADAQEBAAAAAAAAAAAAAAAAAREhQVH/2gAIAQEAAT8hixbLR3uOUbo65o00pOIXh3gkuRlT/9oADAMBAAIAAwAAABCc/wD/xAAYEQEBAAMAAAAAAAAAAAAAAAABABEhMf/aAAgBAwEBPxBjljTl/8QAFxEBAQEBAAAAAAAAAAAAAAAAAQARMf/aAAgBAgEBPxAwwZd9v//EABwQAQEAAgMBAQAAAAAAAAAAAAERACExQVFxgf/aAAgBAQABPxBJ6mxx8v5kcIEAgzfL7mwc1Pb3hMzYlh9mJRUhBhJ7KuVM4N+7z//Z&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;parts&quot; title=&quot;&quot; src=&quot;/static/parts-84499e950f250d856a8fde2c3d7e1770-08fa6.jpeg&quot; srcset=&quot;/static/parts-84499e950f250d856a8fde2c3d7e1770-f2c3a.jpeg 160w,
/static/parts-84499e950f250d856a8fde2c3d7e1770-3ed17.jpeg 320w,
/static/parts-84499e950f250d856a8fde2c3d7e1770-08fa6.jpeg 640w,
/static/parts-84499e950f250d856a8fde2c3d7e1770-c5f03.jpeg 960w,
/static/parts-84499e950f250d856a8fde2c3d7e1770-9f082.jpeg 1000w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;span class=&quot;figcaption_hack&quot;&gt;The parts!&lt;/span&gt;
&lt;h1 id=&quot;shopping-list&quot;&gt;&lt;a href=&quot;#shopping-list&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Shopping List&lt;/h1&gt;
&lt;p&gt;Here&apos;s what I bought (&lt;em&gt;affiliate links&lt;/em&gt;):&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Motherboard: &lt;a href=&quot;https://www.amazon.com/gp/product/B012N6ESTC/ref=as_li_tl?ie=UTF8&amp;#x26;camp=1789&amp;#x26;creative=9325&amp;#x26;creativeASIN=B012N6ESTC&amp;#x26;linkCode=as2&amp;#x26;tag=theoryincorpo-20&amp;#x26;linkId=d41ae2f81f2541aef2deccbb45e833bf&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Gigabyte
GA-Z170X&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CPU: &lt;a href=&quot;https://www.amazon.com/gp/product/B012M8M7TY/ref=as_li_tl?ie=UTF8&amp;#x26;camp=1789&amp;#x26;creative=9325&amp;#x26;creativeASIN=B012M8M7TY&amp;#x26;linkCode=as2&amp;#x26;tag=theoryincorpo-20&amp;#x26;linkId=9f1372b58ef093b59173144815d494fd&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Intel Core i5 6600K 3.50
GHz&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;RAM: &lt;a href=&quot;https://www.amazon.com/gp/product/B01HKF450S/ref=as_li_tl?ie=UTF8&amp;#x26;camp=1789&amp;#x26;creative=9325&amp;#x26;creativeASIN=B01HKF450S&amp;#x26;linkCode=as2&amp;#x26;tag=theoryincorpo-20&amp;#x26;linkId=68496b76cc73a6eaaee01e222fee703e&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Corsair Vengeance
16GB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PSU: &lt;a href=&quot;https://www.amazon.com/gp/product/B00K85X2A2/ref=as_li_tl?ie=UTF8&amp;#x26;camp=1789&amp;#x26;creative=9325&amp;#x26;creativeASIN=B00K85X2A2&amp;#x26;linkCode=as2&amp;#x26;tag=theoryincorpo-20&amp;#x26;linkId=32845692521e8b74f6bda127b2e82917&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;EVGA SuperNova
750W&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Hard Drive: &lt;a href=&quot;https://www.amazon.com/gp/product/B01LXS4TY6/ref=as_li_tl?ie=UTF8&amp;#x26;camp=1789&amp;#x26;creative=9325&amp;#x26;creativeASIN=B01LXS4TY6&amp;#x26;linkCode=as2&amp;#x26;tag=theoryincorpo-20&amp;#x26;linkId=ada0a1fc170f85869054605fbab24684&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Samsung 960
1TB&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;CPU Cooler: &lt;a href=&quot;https://www.amazon.com/gp/product/B005O65JXI/ref=as_li_tl?ie=UTF8&amp;#x26;camp=1789&amp;#x26;creative=9325&amp;#x26;creativeASIN=B005O65JXI&amp;#x26;linkCode=as2&amp;#x26;tag=theoryincorpo-20&amp;#x26;linkId=c0c8d938f6267fdd4e2f3047319003ae&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Cooler Master
Hyper&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Case (first attempt): &lt;a href=&quot;https://www.amazon.com/gp/product/B0716715R1/ref=as_li_tl?ie=UTF8&amp;#x26;camp=1789&amp;#x26;creative=9325&amp;#x26;creativeASIN=B0716715R1&amp;#x26;linkCode=as2&amp;#x26;tag=theoryincorpo-20&amp;#x26;linkId=5f5509b9f3f463d9abf46d3666410bfb&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;AeroCool
Aero300&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Case (second attempt): &lt;a href=&quot;https://www.amazon.com/gp/product/B01M3Y5FJ2/ref=as_li_tl?ie=UTF8&amp;#x26;camp=1789&amp;#x26;creative=9325&amp;#x26;creativeASIN=B01M3Y5FJ2&amp;#x26;linkCode=as2&amp;#x26;tag=theoryincorpo-20&amp;#x26;linkId=7d67eab5133134d5ed151de4dbd5f984&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Corsair Carbide Series
270R&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Wifi adapter: this &lt;a href=&quot;https://www.amazon.com/gp/product/B003MTTJOY/ref=as_li_tl?ie=UTF8&amp;#x26;camp=1789&amp;#x26;creative=9325&amp;#x26;creativeASIN=B003MTTJOY&amp;#x26;linkCode=as2&amp;#x26;tag=theoryincorpo-20&amp;#x26;linkId=2755d7e0d0a7f51bd3798ac05f5cdfa5&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;exceptionally tiny wifi USB
adapter&lt;/a&gt;
came in handy (and continues to) as I struggle with ethernet issues&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;psu&quot;&gt;&lt;a href=&quot;#psu&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;PSU&lt;/h2&gt;
&lt;p&gt;The PSU is the power supply that runs the whole rig.&lt;/p&gt;
&lt;p&gt;There&apos;s three types of PSUs: modular, non-modular and semi-modular. Modular PSUs
have cables you can disconnect, whereas non-modulars have cables that are
attached. Semi-modular PSUs usually have the CPU and motherboard cables attached
and the rest pluggable.&lt;/p&gt;
&lt;p&gt;I bought a modular 750W PSU. In my limited experience of one, modular PSUs need
some additional clearance behind them to accommodate their cables. The original
case I bought, AeroCool, lacked enough space behind the PSU to fit the cables,
necessitating a second trip to the Amazon store. A visit to &lt;a href=&quot;https://pcpartpicker.com/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;pcpartpicker.com&lt;/a&gt; would have alerted me beforehand. Lesson learned!&lt;/p&gt;
&lt;p&gt;To determine what kind of wattage you need, add up all your parts&apos; wattage
needs. Pay particular attention to the GPUs&apos; needs, and give yourself some extra
breathing room. I&apos;m not sure what happens if you run out of wattage but I would
guess it sucks.&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/psu-aa05b72d13584717dd005ed564a61d89-74a50.jpeg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAMBAgQF/8QAFAEBAAAAAAAAAAAAAAAAAAAAAv/aAAwDAQACEAMQAAAB5FnyFsEhf//EABkQAAMBAQEAAAAAAAAAAAAAAAECAxEAEv/aAAgBAQABBQLyOEyFSeqJnaQdVQma/wD/xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAwEBPwGH/8QAFREBAQAAAAAAAAAAAAAAAAAAEBH/2gAIAQIBAT8Bp//EABkQAAMBAQEAAAAAAAAAAAAAAAABERICIf/aAAgBAQAGPwLw1VBNdIhU6jNP/8QAHBABAAIBBQAAAAAAAAAAAAAAAQARMRAhQVFh/9oACAEBAAE/IVs0PYgyVZg1lSMqN+45sPGnn//aAAwDAQACAAMAAAAQHO//xAAXEQEBAQEAAAAAAAAAAAAAAAARAAEx/9oACAEDAQE/EF0sS//EABcRAQADAAAAAAAAAAAAAAAAAAARIVH/2gAIAQIBAT8QxKn/xAAcEAEBAAICAwAAAAAAAAAAAAABEQAhUXExQZH/2gAIAQEAAT8QnqBliDgJYVT2xHIso8dYkDttJ4wNKBbj39w+nzoz/9k=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;psu&quot; title=&quot;&quot; src=&quot;/static/psu-aa05b72d13584717dd005ed564a61d89-08fa6.jpeg&quot; srcset=&quot;/static/psu-aa05b72d13584717dd005ed564a61d89-f2c3a.jpeg 160w,
/static/psu-aa05b72d13584717dd005ed564a61d89-3ed17.jpeg 320w,
/static/psu-aa05b72d13584717dd005ed564a61d89-08fa6.jpeg 640w,
/static/psu-aa05b72d13584717dd005ed564a61d89-74a50.jpeg 800w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;First step out of the box is to make sure the PSU turns on and power is being
delivered. And in my case, all systems were go!&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=2h_NYl4DRF4&amp;#x26;index=1&amp;#x26;list=PLxvB6AORmso4SILfs3sj8vYCohM-RnwcD&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Here&apos;s a great video I watched about installing a
PSU&lt;/a&gt;,
and if you happen to buy an EVGA PSU, here&apos;s &lt;a href=&quot;https://www.youtube.com/watch?v=rucfmsGjPow&amp;#x26;list=PLxvB6AORmso4SILfs3sj8vYCohM-RnwcD&amp;#x26;index=2&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;EVGA&apos;s specific
tutorial&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;motherboard--cpu&quot;&gt;&lt;a href=&quot;#motherboard--cpu&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Motherboard &amp;#x26; CPU&lt;/h2&gt;
&lt;p&gt;For machine and deep learning applications, the CPU is less important than the
GPUs, who do most of the heavy lifting. You need a CPU that&apos;ll accommodate the
GPUs, and &lt;a href=&quot;https://www.quora.com/Which-hardware-components-CPU-RAM-GC-etc-are-needed-for-a-machine-learning-deep-learning-home-PC-computer-to-run-fast&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;it should have as many cores as the
GPUs&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For the motherboard, go with one that supports PCIe 3.0. If you&apos;re planning to
go up to 4 GPUs make sure your motherboard supports that (you&apos;ll also probably
want a stronger PSU and some serious cooling — I elected to use only 2 GPUs).&lt;/p&gt;
&lt;p&gt;Here&apos;s a photo of the motherboard:&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/motherboard-3efc575c4d190bff83986460e4fda2a2-74a50.jpeg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAMBAgQF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQD/2gAMAwEAAhADEAAAAefGhI1GBf/EABoQAAICAwAAAAAAAAAAAAAAAAECABITISL/2gAIAQEAAQUCYchdkFY1CS1Zkn//xAAVEQEBAAAAAAAAAAAAAAAAAAAAIf/aAAgBAwEBPwFH/8QAFREBAQAAAAAAAAAAAAAAAAAAACH/2gAIAQIBAT8BV//EABsQAAEEAwAAAAAAAAAAAAAAAAABAhEhMTJB/9oACAEBAAY/Am2ZUgqVNTp//8QAGxAAAwEAAwEAAAAAAAAAAAAAAAERIWGBkbH/2gAIAQEAAT8hQ6aauI5rcg/pfBk5gknMENfVLy12f//aAAwDAQACAAMAAAAQMP8A/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAERIf/aAAgBAwEBPxC3WQf/xAAXEQADAQAAAAAAAAAAAAAAAAAAAREh/9oACAECAQE/EJMEx//EABwQAQEAAgIDAAAAAAAAAAAAAAERADEhUXHB0f/aAAgBAQABPxCsSCNN7VzegQUjb9mV7KUtcZwUnoFANuTaV0tY9eecZCkJSfWf/9k=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;motherboard&quot; title=&quot;&quot; src=&quot;/static/motherboard-3efc575c4d190bff83986460e4fda2a2-08fa6.jpeg&quot; srcset=&quot;/static/motherboard-3efc575c4d190bff83986460e4fda2a2-f2c3a.jpeg 160w,
/static/motherboard-3efc575c4d190bff83986460e4fda2a2-3ed17.jpeg 320w,
/static/motherboard-3efc575c4d190bff83986460e4fda2a2-08fa6.jpeg 640w,
/static/motherboard-3efc575c4d190bff83986460e4fda2a2-74a50.jpeg 800w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;span class=&quot;figcaption_hack&quot;&gt;Ain&amp;apos;t it a beaut?&lt;/span&gt;
&lt;p&gt;The first step is to install the CPU. &lt;a href=&quot;https://www.youtube.com/watch?v=1w6UZNeGgXU&amp;#x26;index=3&amp;#x26;list=PLxvB6AORmso4SILfs3sj8vYCohM-RnwcD&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;I followed this video on installing a
CPU.&lt;/a&gt;
I was surprised by how easy it is; the thing just clicks into place!&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/cpu-e69dee241a4ed8b32d152114ef64743b-74a50.jpeg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMEAf/EABYBAQEBAAAAAAAAAAAAAAAAAAEAAv/aAAwDAQACEAMQAAABiRdNlWYT/8QAGBAAAwEBAAAAAAAAAAAAAAAAAQIRACL/2gAIAQEAAQUCZIkxMJ6WAarv/8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAwEBPwE//8QAFBEBAAAAAAAAAAAAAAAAAAAAEP/aAAgBAgEBPwE//8QAGxAAAQQDAAAAAAAAAAAAAAAAAQACETEQIWH/2gAIAQEABj8CZA2RlnArVSv/xAAbEAADAQADAQAAAAAAAAAAAAAAAREhQVGRof/aAAgBAQABPyFDFfUa4guBp2YDajdruDQ/of/aAAwDAQACAAMAAAAQBM//xAAWEQEBAQAAAAAAAAAAAAAAAAAAAYH/2gAIAQMBAT8QrX//xAAVEQEBAAAAAAAAAAAAAAAAAAAAgf/aAAgBAgEBPxBH/8QAHhABAAICAQUAAAAAAAAAAAAAAQARITFxQVFhgfD/2gAIAQEAAT8QBTZYFVxGsXgpzFDqgK3qpvm1hs8/doFaNjM9RmV0yx0J/9k=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;cpu&quot; title=&quot;&quot; src=&quot;/static/cpu-e69dee241a4ed8b32d152114ef64743b-08fa6.jpeg&quot; srcset=&quot;/static/cpu-e69dee241a4ed8b32d152114ef64743b-f2c3a.jpeg 160w,
/static/cpu-e69dee241a4ed8b32d152114ef64743b-3ed17.jpeg 320w,
/static/cpu-e69dee241a4ed8b32d152114ef64743b-08fa6.jpeg 640w,
/static/cpu-e69dee241a4ed8b32d152114ef64743b-74a50.jpeg 800w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;span class=&quot;figcaption_hack&quot;&gt;This time, with more CPU!&lt;/span&gt;
&lt;p&gt;&lt;em&gt;Side note:&lt;/em&gt; The eagle-eyed reader may observe me assembling this on a carpet.
Don&apos;t be me. Carpets cause static electricity and &lt;strong&gt;static electricity is bad
for electronics&lt;/strong&gt;. Soon after this photo was taken I quickly realized the error
of my ways and migrated to a non-carpeted floor and became obsessive about
touching metal objects for the remainder of the build out.&lt;/p&gt;
&lt;h2 id=&quot;thermal-paste&quot;&gt;&lt;a href=&quot;#thermal-paste&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Thermal Paste&lt;/h2&gt;
&lt;p&gt;Not having done this in over 20 years, this was a completely new thing to me.&lt;/p&gt;
&lt;p&gt;CPUs require a paste be applied in order to dispel heat. Here&apos;s a video on
applying &lt;a href=&quot;https://www.youtube.com/watch?v=-hNgFNH7zhQ&amp;#x26;list=PLxvB6AORmso4SILfs3sj8vYCohM-RnwcD&amp;#x26;index=5&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;thermal
paste&lt;/a&gt;.
The narrator&apos;s pasting technique is 🔥.&lt;/p&gt;
&lt;h2 id=&quot;cpu-cooler&quot;&gt;&lt;a href=&quot;#cpu-cooler&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;CPU Cooler&lt;/h2&gt;
&lt;p&gt;The CPU Cooler sits on top of the CPU and sucks the heat out to be dispelled via
a fan. It looks super cool, and it was fun to install too! &lt;a href=&quot;https://www.youtube.com/watch?v=XLlrqzwxJig&amp;#x26;index=4&amp;#x26;list=PLxvB6AORmso4SILfs3sj8vYCohM-RnwcD&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Here&apos;s the video I
followed to install
it&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;And here it is, looking so snazzy:&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/cooler-5d0a7e8c4282e0706c12c6041d276a08-9f082.jpeg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAQFAv/EABYBAQEBAAAAAAAAAAAAAAAAAAMAAf/aAAwDAQACEAMQAAAB0LrgtgnFv//EABsQAAICAwEAAAAAAAAAAAAAAAECERIAAwQy/9oACAEBAAEFArqEXoBFpzb5CQEeo//EABcRAAMBAAAAAAAAAAAAAAAAAAABEQL/2gAIAQMBAT8B03Sn/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAECEv/aAAgBAgEBPwGZTRk//8QAGxAAAwACAwAAAAAAAAAAAAAAAAERAiEQEjH/2gAIAQEABj8CqeuKdcdHpGqf/8QAGhAAAwEBAQEAAAAAAAAAAAAAAAEhEUFRcf/aAAgBAQABPyHhj1LRk1z5SaTGmTMhA1vZCyK9P//aAAwDAQACAAMAAAAQdx//xAAXEQEBAQEAAAAAAAAAAAAAAAABABEh/9oACAEDAQE/EBYIedL/xAAXEQEBAQEAAAAAAAAAAAAAAAABABEh/9oACAECAQE/ENAyd43/xAAfEAEBAAIABwEAAAAAAAAAAAABEQAhMUFRYXGBkbH/2gAIAQEAAT8QDTaTgHqmL6JdOseK/uBUgUXCGCOWV6AUQdk3v5mxLSLEvvrfuf/Z&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;cooler&quot; title=&quot;&quot; src=&quot;/static/cooler-5d0a7e8c4282e0706c12c6041d276a08-08fa6.jpeg&quot; srcset=&quot;/static/cooler-5d0a7e8c4282e0706c12c6041d276a08-f2c3a.jpeg 160w,
/static/cooler-5d0a7e8c4282e0706c12c6041d276a08-3ed17.jpeg 320w,
/static/cooler-5d0a7e8c4282e0706c12c6041d276a08-08fa6.jpeg 640w,
/static/cooler-5d0a7e8c4282e0706c12c6041d276a08-c5f03.jpeg 960w,
/static/cooler-5d0a7e8c4282e0706c12c6041d276a08-9f082.jpeg 1000w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;span class=&quot;figcaption_hack&quot;&gt;So cool, Cooler Master Hyper&lt;/span&gt;
&lt;h2 id=&quot;ram&quot;&gt;&lt;a href=&quot;#ram&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;RAM&lt;/h2&gt;
&lt;p&gt;Ram is a cinch to install. Here&apos;s a &lt;a href=&quot;https://www.youtube.com/watch?v=O5WMyYrEq1Y&amp;#x26;list=PLxvB6AORmso4SILfs3sj8vYCohM-RnwcD&amp;#x26;index=7&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;video that&apos;ll show you
how&lt;/a&gt;.&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/ram-5bfcc759675226bd077fa682032a3392-34d12.jpeg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 133.41677096370464%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAbABQDASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAMBAgQF/8QAFQEBAQAAAAAAAAAAAAAAAAAAAQD/2gAMAwEAAhADEAAAAcKGoKwE6o3uLhkif//EAB0QAAEEAgMAAAAAAAAAAAAAAAEAAhIyITEDERP/2gAIAQEAAQUCDQRLIiuRdJutnyzVMsWiL7f/xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAEDAQE/AR//xAAUEQEAAAAAAAAAAAAAAAAAAAAg/9oACAECAQE/AR//xAAeEAACAgEFAQAAAAAAAAAAAAAAARARIRIxMkJhkf/aAAgBAQAGPwJ26Zkyexxs0tG3wqFjtUf/xAAeEAACAgICAwAAAAAAAAAAAAAAAREhMXEQgUFRYf/aAAgBAQABPyGIVNqWOQUZTsVUk9hukezZA3DNuqo80Gvozdl1wQeGPQyn/9oADAMBAAIAAwAAABA/wkP/xAAVEQEBAAAAAAAAAAAAAAAAAAAQEf/aAAgBAwEBPxAh/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAEREP/aAAgBAgEBPxBMpc//xAAfEAEAAgMAAgMBAAAAAAAAAAABABEhMUFhkXGxwfD/2gAIAQEAAT8Q1bKbB57lHsVyXquTx/JTrBsNj4vsOOM9BiCgIa/ioQCUCEZeX53H1LsfuVkMl05TNiHeEW1jaLcNXuGhn//Z&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;ram&quot; title=&quot;&quot; src=&quot;/static/ram-5bfcc759675226bd077fa682032a3392-08fa6.jpeg&quot; srcset=&quot;/static/ram-5bfcc759675226bd077fa682032a3392-f2c3a.jpeg 160w,
/static/ram-5bfcc759675226bd077fa682032a3392-3ed17.jpeg 320w,
/static/ram-5bfcc759675226bd077fa682032a3392-08fa6.jpeg 640w,
/static/ram-5bfcc759675226bd077fa682032a3392-34d12.jpeg 799w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;h2 id=&quot;hard-drive&quot;&gt;&lt;a href=&quot;#hard-drive&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Hard Drive&lt;/h2&gt;
&lt;p&gt;I bought an M.2 hard drive, which my limited experience indicates is the easiest
hard drive to install (&lt;em&gt;note: I did not attempt to install other types of hard
drives&lt;/em&gt;). &lt;a href=&quot;https://www.youtube.com/watch?v=XmvNQvFxKcs&amp;#x26;index=10&amp;#x26;list=PLxvB6AORmso4SILfs3sj8vYCohM-RnwcD&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Here&apos;s a video demonstrating how to install
it&lt;/a&gt;.
It basically snaps right onto the motherboard and you&apos;re done.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Side note:&lt;/em&gt; I actually installed the GPUs before installing the hard drive, and
had to remove those GPUs to get it in as the M.2 sits underneath them (at least,
on this particular motherboard). So if you have an M.2, do this step before the
GPUs.&lt;/p&gt;
&lt;h2 id=&quot;gpus-1&quot;&gt;&lt;a href=&quot;#gpus-1&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;GPUs&lt;/h2&gt;
&lt;p&gt;Finally, here come the racehorses!&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=Yinrkn4TvnU&amp;#x26;list=PLxvB6AORmso4SILfs3sj8vYCohM-RnwcD&amp;#x26;index=8&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Here&apos;s a video on installing
GPUs&lt;/a&gt;.
It&apos;s pretty straightforward: you line the chips up with the PCI-e connectors,
pop one of the tabs, and push (softly — you don&apos;t want to force it) until the
tab clicks back into place.&lt;/p&gt;
&lt;p&gt;Here&apos;s a before shot of the empty PCI slots:&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/empty-pci-d91b28c709154c3ead991f8111186a4f-34d12.jpeg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 133.41677096370464%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAbABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAMEBQH/xAAVAQEBAAAAAAAAAAAAAAAAAAAAAf/aAAwDAQACEAMQAAABw+lcWGaKuxDBICf/xAAcEAACAQUBAAAAAAAAAAAAAAABAgMAERIhMRD/2gAIAQEAAQUC8ilSKMVGHykuXXq2xK7Is69Y7//EABYRAAMAAAAAAAAAAAAAAAAAAAAQEf/aAAgBAwEBPwEr/8QAFBEBAAAAAAAAAAAAAAAAAAAAIP/aAAgBAgEBPwEf/8QAGxAAAgIDAQAAAAAAAAAAAAAAARACIQAiMVH/2gAIAQEABj8CQjOFha9GX1H1U//EABoQAQADAQEBAAAAAAAAAAAAAAEAESExQYH/2gAIAQEAAT8hgLLg13QlB35OI9qjVkGMFkg9VuR/EI6VE02IPZ//2gAMAwEAAgADAAAAEAjDD//EABYRAQEBAAAAAAAAAAAAAAAAABEAEP/aAAgBAwEBPxCUGf/EABkRAQACAwAAAAAAAAAAAAAAAAEAECFRYf/aAAgBAgEBPxB5A3HNf//EACIQAQEAAQMCBwAAAAAAAAAAAAERACExQVGREGGBobHR8f/aAAgBAQABPxAdcTAFuwFykdUgZXrjYhs7qb+lwVkrejj92xZaSCm9fvw8vFEDdpC/MO+FZDPPAiCcY4K1w6Oh9s//2Q==&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;empty pci&quot; title=&quot;&quot; src=&quot;/static/empty-pci-d91b28c709154c3ead991f8111186a4f-08fa6.jpeg&quot; srcset=&quot;/static/empty-pci-d91b28c709154c3ead991f8111186a4f-f2c3a.jpeg 160w,
/static/empty-pci-d91b28c709154c3ead991f8111186a4f-3ed17.jpeg 320w,
/static/empty-pci-d91b28c709154c3ead991f8111186a4f-08fa6.jpeg 640w,
/static/empty-pci-d91b28c709154c3ead991f8111186a4f-34d12.jpeg 799w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;And with the GPUs installed:&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/gpu-a59db2372e0aabdf3529a85f7dffb48d-34d12.jpeg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 133.41677096370464%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAbABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAIEAwX/xAAVAQEBAAAAAAAAAAAAAAAAAAABAv/aAAwDAQACEAMQAAAB58e2Y6FAk6WrFOQlz//EABwQAAICAgMAAAAAAAAAAAAAAAECAAMQEhEhQv/aAAgBAQABBQKsBmir0jGtprvLBw4iuoHu1QMf/8QAFREBAQAAAAAAAAAAAAAAAAAAARD/2gAIAQMBAT8BiT//xAAVEQEBAAAAAAAAAAAAAAAAAAABEP/aAAgBAgEBPwGDP//EABwQAAICAgMAAAAAAAAAAAAAAAAhARARgTFBcf/aAAgBAQAGPwKVTQvK5hImu9GzOK//xAAcEAEAAwADAQEAAAAAAAAAAAABABEhMVFxEEH/2gAIAQEAAT8hJ64T9gNkeovaXyuBuMcLYAJ3oW7nOBwT7ojrvpLoUb+f/9oADAMBAAIAAwAAABAzyML/xAAYEQADAQEAAAAAAAAAAAAAAAAAATEQEf/aAAgBAwEBPxBzKM4f/8QAGBEAAwEBAAAAAAAAAAAAAAAAAAExEBH/2gAIAQIBAT8QVyCZ0//EAB0QAQACAgMBAQAAAAAAAAAAAAEAESFRMUFh4XH/2gAIAQEAAT8QRyloB79jfCWtzwFLNnk4FFAX38hrpNbjWJM2mAPPWOl4ACh7ioqlelztQqZT8YReSHnWIQV2DGoT/9k=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;gpu&quot; title=&quot;&quot; src=&quot;/static/gpu-a59db2372e0aabdf3529a85f7dffb48d-08fa6.jpeg&quot; srcset=&quot;/static/gpu-a59db2372e0aabdf3529a85f7dffb48d-f2c3a.jpeg 160w,
/static/gpu-a59db2372e0aabdf3529a85f7dffb48d-3ed17.jpeg 320w,
/static/gpu-a59db2372e0aabdf3529a85f7dffb48d-08fa6.jpeg 640w,
/static/gpu-a59db2372e0aabdf3529a85f7dffb48d-34d12.jpeg 799w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;h2 id=&quot;putting-it-in-the-case&quot;&gt;&lt;a href=&quot;#putting-it-in-the-case&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Putting it in the case&lt;/h2&gt;
&lt;p&gt;The last step is to get the motherboard into the case and seal it up.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=iTkGuioG5RU&amp;#x26;list=PLxvB6AORmso4SILfs3sj8vYCohM-RnwcD&amp;#x26;index=9&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Here&apos;s a video walking through how to install into a
case.&lt;/a&gt;
I suspect every case is different and you&apos;re better off searching for your
particular build, but c&apos;est la vie. You&apos;ll have to connect the case&apos;s cables to
the motherboard&apos;s, and for that you will need to refer to the respective manuals
for instructions.&lt;/p&gt;
&lt;hr&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/frankenstein-2ae844d6e1f9f9d34da71025629232c4-7346c.jpeg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 428px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 53.271028037383175%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAFwAAAwEAAAAAAAAAAAAAAAAAAAMFAv/EABQBAQAAAAAAAAAAAAAAAAAAAAD/2gAMAwEAAhADEAAAAcrptIhaD//EABoQAAIDAQEAAAAAAAAAAAAAAAECABITAxH/2gAIAQEAAQUCXLmXpcp7M0aZISEVZ//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8BP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8BP//EABwQAAEEAwEAAAAAAAAAAAAAAAIAAREhEBJhMf/aAAgBAQAGPwKSF546gAKu4sU76+qqX//EABsQAQADAQADAAAAAAAAAAAAAAEAESExQVFh/9oACAEBAAE/IcW/HQlNxfaHV3r2thsJ6xUBeGAUafGf/9oADAMBAAIAAwAAABATD//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQMBAT8QP//EABQRAQAAAAAAAAAAAAAAAAAAABD/2gAIAQIBAT8QP//EAB0QAQEAAwACAwAAAAAAAAAAAAERACExQWFRcaH/2gAIAQEAAT8QAFSuhJLPW/eC6h2Yath8fedLhRwfJTHaEQ71d4pISldiR/MdPRsTuf/Z&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;frankenstein&quot; title=&quot;&quot; src=&quot;/static/frankenstein-2ae844d6e1f9f9d34da71025629232c4-7346c.jpeg&quot; srcset=&quot;/static/frankenstein-2ae844d6e1f9f9d34da71025629232c4-5e5a8.jpeg 160w,
/static/frankenstein-2ae844d6e1f9f9d34da71025629232c4-292d6.jpeg 320w,
/static/frankenstein-2ae844d6e1f9f9d34da71025629232c4-7346c.jpeg 428w&quot; sizes=&quot;(max-width: 428px) 100vw, 428px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;With everything assembled, all that was left was to hit the power button on the
PSU. I felt a little like Dr. Frankenstein hovering over his monster. Would the
beast wake up?&lt;/p&gt;
&lt;p&gt;I flipped the PSU. The machine did not turn on. I spent five minutes freaking
out thinking I had fried some circuitry or installed something wrong.&lt;/p&gt;
&lt;p&gt;I then realized the case also has an on switch. So I turned that on.&lt;/p&gt;
&lt;p&gt;And the beast awoke!&lt;/p&gt;

  &lt;a class=&quot;gatsby-resp-image-link&quot; href=&quot;/static/final-2bf3b4286c52cd83ea5f9d9e4793333f-74a50.jpeg&quot; style=&quot;display: block&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;
  
  &lt;span class=&quot;gatsby-resp-image-wrapper&quot; style=&quot;position: relative; display: block; ; max-width: 640px; margin-left: auto; margin-right: auto;&quot;&gt;
    &lt;span class=&quot;gatsby-resp-image-background-image&quot; style=&quot;padding-bottom: 75%; position: relative; bottom: 0; left: 0; background-image: url(&amp;apos;data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAAPABQDASIAAhEBAxEB/8QAGAAAAwEBAAAAAAAAAAAAAAAAAAEEAgP/xAAWAQEBAQAAAAAAAAAAAAAAAAACAAH/2gAMAwEAAhADEAAAAU4aAupoy//EABoQAAMAAwEAAAAAAAAAAAAAAAACFAEEEhP/2gAIAQEAAQUCtcsYsY8GF1X5lXJ//8QAFhEBAQEAAAAAAAAAAAAAAAAAABEB/9oACAEDAQE/AYmv/8QAFxEAAwEAAAAAAAAAAAAAAAAAAAESA//aAAgBAgEBPwFSVmf/xAAcEAACAQUBAAAAAAAAAAAAAAAAAQIQERIhMUH/2gAIAQEABj8Cu4xOHlMpGmz/xAAZEAADAQEBAAAAAAAAAAAAAAAAAREhYXH/2gAIAQEAAT8hkqHhJvBwDrMrGHhOMS1F/9oADAMBAAIAAwAAABBjP//EABURAQEAAAAAAAAAAAAAAAAAAAEQ/9oACAEDAQE/EFT/AP/EABcRAQADAAAAAAAAAAAAAAAAAAABYaH/2gAIAQIBAT8QkUY//8QAHBAAAgEFAQAAAAAAAAAAAAAAAREAITFBUWHx/9oACAEBAAE/ELiQkJgaLvZaHqtp5seuAKBwrYD0zmBCE7U//9k=&amp;apos;); background-size: cover; display: block;&quot;&gt;
      &lt;img class=&quot;gatsby-resp-image-image&quot; style=&quot;width: 100%; height: 100%; margin: 0; vertical-align: middle; position: absolute; top: 0; left: 0; box-shadow: inset 0px 0px 0px 400px white;&quot; alt=&quot;final&quot; title=&quot;&quot; src=&quot;/static/final-2bf3b4286c52cd83ea5f9d9e4793333f-08fa6.jpeg&quot; srcset=&quot;/static/final-2bf3b4286c52cd83ea5f9d9e4793333f-f2c3a.jpeg 160w,
/static/final-2bf3b4286c52cd83ea5f9d9e4793333f-3ed17.jpeg 320w,
/static/final-2bf3b4286c52cd83ea5f9d9e4793333f-08fa6.jpeg 640w,
/static/final-2bf3b4286c52cd83ea5f9d9e4793333f-74a50.jpeg 800w&quot; sizes=&quot;(max-width: 640px) 100vw, 640px&quot;&gt;
    &lt;/span&gt;
  &lt;/span&gt;
  
  &lt;/a&gt;
    
&lt;p&gt;At this point I had a functioning machine, and it was into the land of software
(and a nice cold beer). I&apos;ll save that for next time.&lt;/p&gt;
&lt;p&gt;If you want to hear about my travails configuring the BIOS, installing Linux,
and actually tackling the crypto mining and deep learning setups, drop your
email below and I&apos;ll let you know when I publish those.&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Background Images in React Native]]></title><description><![CDATA[A  common
question 
amongst React Native developers is how to put a background image on a view. On the web, it’s a piece of cake: In React…]]></description><link>https://thekevinscott.com/background-images-in-react-native/</link><guid isPermaLink="false">https://thekevinscott.com/background-images-in-react-native/</guid><pubDate>Tue, 09 May 2017 09:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*lQUxDjLJOjiqJbd2Q_4xTA.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;A &lt;a href=&quot;http://stackoverflow.com/questions/29322973/whats-the-best-way-to-add-a-full-screen-background-image-in-react-native&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;common
question&lt;/a&gt;
amongst React Native developers is how to put a background image on a view.&lt;/p&gt;
&lt;p&gt;On the web, it’s a piece of cake:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;#x3C;div style={{ backgroundImage: &apos;url(/my-image.
)&apos; }}&gt;...&amp;#x3C;/div&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In React Native, there’s no &lt;code&gt;background-image&lt;/code&gt; tag; instead, the &lt;code&gt;&amp;#x3C;Image&gt;&lt;/code&gt;
component does the heavy lifting.&lt;/p&gt;
&lt;h3 id=&quot;layouts&quot;&gt;&lt;a href=&quot;#layouts&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Layouts&lt;/h3&gt;
&lt;p&gt;&lt;a href=&quot;https://s15.postimg.org/tw2qkvmcb/400px.png&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;OUR SAMPLE IMAGE&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;There’s &lt;a href=&quot;https://facebook.github.io/react-native/docs/image.html#resizemode&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;5
layouts&lt;/a&gt; to
be aware of that an image can take.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;center&lt;/code&gt; - Centers the image, without resizing it.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;repeat&lt;/code&gt; - Repeats the image, without resizing it.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;stretch&lt;/code&gt; - Stretches the image to fit its bounds, without preserving the
image’s aspect ratio.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;contain&lt;/code&gt; - Resizes the image to fit its bounds, while also preserving its
aspect ratio.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;cover&lt;/code&gt; - Resizes the image so its shorter side fits its bounds, while also
preserving its aspect ratio. In practice, this means that the longer side while
overlap the borders of its bounds.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Here’s examples of each in practice:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;center&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;contain&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;cover&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;repeat&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;stretch&lt;/span&gt;&lt;/p&gt;
&lt;h3 id=&quot;referencing-images&quot;&gt;&lt;a href=&quot;#referencing-images&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Referencing images&lt;/h3&gt;
&lt;p&gt;If you haven’t used &lt;code&gt;&amp;#x3C;Image /&gt;&lt;/code&gt; before, a quick note on assets. There’s two ways
of serving images, over the network and locally. Using local images will be
faster but result in a larger app binary, and can’t be updated on the fly.&lt;/p&gt;
&lt;p&gt;If you’re using remote images, keep in mind two things:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Use &lt;code&gt;https&lt;/code&gt; links instead of &lt;code&gt;http&lt;/code&gt;. &lt;a href=&quot;https://developer.apple.com/news/?id=12212016b&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Apple will block
non-&lt;/a&gt;&lt;code&gt;https&lt;/code&gt;&lt;a href=&quot;https://developer.apple.com/news/?id=12212016b&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;
links&lt;/a&gt;, and in my experience
this error will happen silently.&lt;/li&gt;
&lt;li&gt;For larger images, explore the caching policies &lt;a href=&quot;https://facebook.github.io/react-native/docs/images.html#cache-control-ios-only&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;detailed
here&lt;/a&gt;
to reduce network requests for your users.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If instead you decide to serve images locally, keep in mind images are served
relative from your app root folder. I usually put my local images into an assets
folder with other media, so from &lt;code&gt;index.ios.js&lt;/code&gt; I can call them with:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;require(&apos;./assets/my-image.png&apos;)&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;Finally, if you add a new image to your app and come across an error like this:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;Error Message&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;It probably means you need to restart your packager, so it can pick up the
imported image.&lt;/p&gt;
&lt;h3 id=&quot;examples&quot;&gt;&lt;a href=&quot;#examples&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Examples&lt;/h3&gt;
&lt;p&gt;Let’s show an example where we fetch an image from a public URL and position it
absolutely:&lt;/p&gt;
&lt;p&gt;Easy as that! The key is the use of &lt;code&gt;flex: 1&lt;/code&gt;, which will cause the &lt;code&gt;&amp;#x3C;Image /&gt;&lt;/code&gt;component to fill its container. You can read &lt;a href=&quot;https://facebook.github.io/react-native/docs/flexbox.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;more about Flexbox
here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;You can play around with &lt;code&gt;resizeMode&lt;/code&gt; to see the different layout options.&lt;/p&gt;
&lt;h3 id=&quot;with-text&quot;&gt;&lt;a href=&quot;#with-text&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;With Text&lt;/h3&gt;
&lt;p&gt;Usually a background image sits behind something else. There’s two ways to
achieve that: using the &lt;code&gt;&amp;#x3C;Image /&gt;&lt;/code&gt; as the view layer itself, or wrapping it in
another &lt;code&gt;&amp;#x3C;View /&gt;&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Here’s an example using the &lt;code&gt;&amp;#x3C;Image /&gt;&lt;/code&gt; as the wrapper component:&lt;/p&gt;
&lt;p&gt;And here’s an example wrapping the &lt;code&gt;&amp;#x3C;Image /&gt;&lt;/code&gt; in a container &lt;code&gt;&amp;#x3C;View /&gt;&lt;/code&gt;:&lt;/p&gt;
&lt;p&gt;I slightly prefer the latter approach, as I think it’s more flexible if you need
to make further adjustments or include other elements, but either approach
works.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/tag/react-native?source=post&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;React Native&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/tag/javascript?source=post&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;JavaScript&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/tag/image?source=post&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Image&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/tag/flexbox?source=post&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Flexbox&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By clapping more or less, you can signal to us which stories really stand out.&lt;/p&gt;
&lt;h3 id=&quot;kevin-scott&quot;&gt;&lt;a href=&quot;#kevin-scott&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href=&quot;https://medium.com/@thekevinscott&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Kevin Scott&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;React &amp;#x26; React Native // Chatbot Evangelist // Machine Learning //
Cryptocurrencies // Desingineer 🤖&lt;/p&gt;
&lt;h3 id=&quot;react-native-cafe&quot;&gt;&lt;a href=&quot;#react-native-cafe&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href=&quot;https://medium.com/reactnative?source=footer_card&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;React Native Cafe&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Articles about React Native&lt;/p&gt;</content:encoded></item><item><title><![CDATA[Tabbing Through Input Fields]]></title><description><![CDATA[
 Photo by  Galymzhan Abdugalimov On the web, it’s common to tab through forms, an intuitive and  UX-friendly
pattern . You get this out of…]]></description><link>https://thekevinscott.com/tabbing-through-input-fields/</link><guid isPermaLink="false">https://thekevinscott.com/tabbing-through-input-fields/</guid><pubDate>Fri, 05 May 2017 09:00:00 GMT</pubDate><content:encoded>&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*RUuUJLHaYhyCDJKHvWjGfw.jpeg&quot;&gt;
&lt;span class=&quot;figcaption_hack&quot;&gt;Photo by &lt;a href=&quot;https://unsplash.com/photos/ICW6QYOcdlg&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Galymzhan Abdugalimov&lt;/a&gt;&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://cdn-images-1.medium.com/max/800/1*lQUxDjLJOjiqJbd2Q_4xTA.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;On the web, it’s common to tab through forms, an intuitive and &lt;a href=&quot;https://www.nngroup.com/articles/web-form-design/&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;UX-friendly
pattern&lt;/a&gt;. You get this out of
the box with web forms, but when building apps with React Native, you need to
implement this functionality yourself. Fortunately, it’s a cinch to set up.&lt;/p&gt;
&lt;h3 id=&quot;native-form-ux-vs-web-form-ux&quot;&gt;&lt;a href=&quot;#native-form-ux-vs-web-form-ux&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Native Form UX vs. Web Form UX&lt;/h3&gt;
&lt;p&gt;First, let’s understand what native UX we’re trying to emulate on React Native.&lt;/p&gt;
&lt;p&gt;Here’s a video of navigation through the native iOS contacts app:&lt;/p&gt;
&lt;p&gt;And here’s a video of navigation through a Web form:&lt;/p&gt;
&lt;p&gt;In summary, the iOS web browser gives us next and previous buttons, but for a
native iOS app, these aren’t present, and &lt;a href=&quot;https://github.com/facebook/react-native/issues/641#issuecomment-94522058&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;React Native doesn’t support them
natively,
either&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I believe the reason for this discrepancy is that, natively, the “return” key
performs double duty, tabbing through the form and submitting once the form is
complete. On the web, the “return” key will submit the form by default,
necessitating the next/previous buttons.&lt;/p&gt;
&lt;p&gt;We’ll focus on emulating the native functionality, relying on the “return” key
to tab through the form and submit it when complete.&lt;/p&gt;
&lt;h3 id=&quot;keyboards-and-textinput-on-react-native&quot;&gt;&lt;a href=&quot;#keyboards-and-textinput-on-react-native&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Keyboards and TextInput on React Native&lt;/h3&gt;
&lt;p&gt;We’ll be using &lt;code&gt;TextInput&lt;/code&gt; and &lt;code&gt;View&lt;/code&gt; from the &lt;code&gt;react-native&lt;/code&gt; library, like so:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;import {
  TextInput,
  View,
} from &apos;react-native&apos;;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Each &lt;code&gt;TextInput&lt;/code&gt; &lt;a href=&quot;https://facebook.github.io/react-native/docs/textinput.html#keyboardtype&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;defines its own keyboard that appears when
focused&lt;/a&gt;.
This allows a particular input field to specify &lt;code&gt;numeric&lt;/code&gt;, &lt;code&gt;numpad&lt;/code&gt;, or a number
of different options.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;TextInput&lt;/code&gt;s are also responsible for determining which input to send focus to
next, and &lt;a href=&quot;https://facebook.github.io/react-native/docs/textinput.html#onsubmitediting&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;they provide a handy prop for implementing
this&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;capturing-the-field-reference&quot;&gt;&lt;a href=&quot;#capturing-the-field-reference&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Capturing the field reference&lt;/h3&gt;
&lt;p&gt;The first thing we’ll need is to capture the &lt;code&gt;ref&lt;/code&gt; of a particular input field.&lt;/p&gt;
&lt;p&gt;If you’re not familiar, &lt;a href=&quot;https://facebook.github.io/react/docs/refs-and-the-dom.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;a
&lt;/a&gt;&lt;code&gt;ref&lt;/code&gt;&lt;a href=&quot;https://facebook.github.io/react/docs/refs-and-the-dom.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt; is a
reference to the React
component&lt;/a&gt;. It’s
best practice to specify a callback function and capture the referenced
component from the arguments.&lt;/p&gt;
&lt;p&gt;In our example, we’re storing each &lt;code&gt;TextInput&lt;/code&gt;‘s ref on an internal &lt;code&gt;inputs&lt;/code&gt;
object we’ll define in the constructor. &lt;strong&gt;We specify a custom index we’ll use
later to focus on the input.&lt;/strong&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;#x3C;TextInput

  ref={ input =&gt; {

    this.inputs[&apos;one&apos;] = input;

  }}

  ...

/&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Since the ref is defined in the &lt;code&gt;render&lt;/code&gt; function, don’t store the reference
with &lt;code&gt;setState&lt;/code&gt;; &lt;a href=&quot;https://github.com/facebook/react/issues/5591&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;doing so will cause an infinite
loop&lt;/a&gt; andmany tears will be shed.&lt;/p&gt;
&lt;h3 id=&quot;triggering-focus&quot;&gt;&lt;a href=&quot;#triggering-focus&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Triggering focus&lt;/h3&gt;
&lt;p&gt;Next, we need to focus on the next element. We do that by hooking into the
&lt;code&gt;onSubmitEditing&lt;/code&gt; prop and supplying it with a custom focus function on the
component.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;onSubmitEditing={() =&gt; {

  // specify the key of the ref, as done in the previous section.

  this.focusNextField(&apos;next-field&apos;);

}}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Then, we set up the field. If we zoom out to the component level:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;class App extends React.Component {

  constructor(props) {

    super(props);

    this.focusNextField = this.focusNextField.bind(this);

    // to store our input refs

    this.inputs = {};

  }

  focusNextField(key) {

    this.inputs[key].focus();

  }

  ...

}
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Two things to point out:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;http://egorsmirnov.me/2015/08/16/react-and-es6-part3.html&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;We need to bind the focus
function&lt;/a&gt; to the
class so we have an accurate reference to &lt;code&gt;this&lt;/code&gt;. This is generally done in the
constructor.&lt;/li&gt;
&lt;li&gt;The focus action accepts a key indicating which input to focus on. That key
matches what we use in the &lt;code&gt;ref&lt;/code&gt; callback above.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;avoiding-the-disappearing-keyboard&quot;&gt;&lt;a href=&quot;#avoiding-the-disappearing-keyboard&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Avoiding the disappearing keyboard&lt;/h3&gt;
&lt;p&gt;Sometimes as we’re tabbing between fields, the keyboard will disappear and
reappear. We can avoid this by using a prop on &lt;code&gt;TextInput&lt;/code&gt; called
&lt;code&gt;blurOnSubmit&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;#x3C;TextInput

  blurOnSubmit={ false }

  ...

/&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This property forces the keyboard to remain visible. Since we’re immediately
tabbing to our next field, this behavior works nicely for us.&lt;/p&gt;
&lt;h3 id=&quot;return-key&quot;&gt;&lt;a href=&quot;#return-key&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Return key&lt;/h3&gt;
&lt;p&gt;Updating &lt;a href=&quot;https://facebook.github.io/react-native/docs/textinput.html#returnkeytype&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;the return
key&lt;/a&gt;
to match the correct action isn’t strictly necessary (and natively iOS doesn’t
change its appearance) but I think updating to the relevant return key type is a
nice touch:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;#x3C;TextInput

  returnKeyType={ &quot;next&quot; }

  ...

/&gt;

&amp;#x3C;TextInput

  returnKeyType={ &quot;done&quot; }

  ...

/&gt;
&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This indicates how to show a &lt;code&gt;done&lt;/code&gt; return key on the final input, and a
&lt;code&gt;next&lt;/code&gt;return key on the rest of em.&lt;/p&gt;
&lt;h3 id=&quot;putting-it-all-together&quot;&gt;&lt;a href=&quot;#putting-it-all-together&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Putting it all together&lt;/h3&gt;
&lt;p&gt;The final gist is here:&lt;/p&gt;
&lt;p&gt;You can see it in action on iOS and Android:&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;iOS&lt;/span&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class=&quot;figcaption_hack&quot;&gt;Android&lt;/span&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/tag/javascript?source=post&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;JavaScript&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/tag/react?source=post&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;React&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/tag/react-native?source=post&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;React Native&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/tag/keyboard?source=post&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Keyboard&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://medium.com/tag/es6?source=post&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;ES6&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;By clapping more or less, you can signal to us which stories really stand out.&lt;/p&gt;
&lt;h3 id=&quot;kevin-scott&quot;&gt;&lt;a href=&quot;#kevin-scott&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href=&quot;https://medium.com/@thekevinscott&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;Kevin Scott&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;React &amp;#x26; React Native // Chatbot Evangelist // Machine Learning //
Cryptocurrencies // Desingineer 🤖&lt;/p&gt;
&lt;h3 id=&quot;react-native-cafe&quot;&gt;&lt;a href=&quot;#react-native-cafe&quot; aria-hidden=&quot;true&quot; class=&quot;anchor&quot;&gt;&lt;svg aria-hidden=&quot;true&quot; height=&quot;16&quot; version=&quot;1.1&quot; viewBox=&quot;0 0 16 16&quot; width=&quot;16&quot;&gt;&lt;path fill-rule=&quot;evenodd&quot; d=&quot;M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z&quot;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;&lt;a href=&quot;https://medium.com/reactnative?source=footer_card&quot; target=&quot;_blank&quot; rel=&quot;nofollow noopener noreferrer&quot;&gt;React Native Cafe&lt;/a&gt;&lt;/h3&gt;
&lt;p&gt;Articles about React Native&lt;/p&gt;</content:encoded></item></channel></rss>